{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>CAVE is short for Connectome Annotation Versioning Engine. CAVE is a set of microservices that provide a framework for storing and versioning connectomics data and large sets of dynamic annotations, metadata, and segmentations. This repository supplies client-side code to easily interact with the microservices in CAVE.</p>"},{"location":"#documentation-layout","title":"Documentation Layout","text":"<p>To learn how to install <code>caveclient</code>, visit Installation.</p> <p>To see hands-on examples of using <code>caveclient</code> in a notebook, visit the Tutorials.</p> <p>To see API reference documentation for interacting with a <code>caveclient.CAVEclient</code> object (most common), visit the Client API.</p> <p>To see API reference documentation for interacting with the individual services, visit the Extended API.</p> <p>To see a glossary of terms used in the documentation, visit the Glossary (work in progress).</p> <p>For information about how to contribute to the documentation or the package, visit the Contributing page. Feedback on the documentation is welcome! Please open an issue or use the \"Edit this page\" button at the top right of any page to suggest changes.</p> <p>To read a full description of the Connectome Annotation Versioning Engine, including a description of the various services please read this paper.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#5200-april-8-2024","title":"5.20.0 (April 8, 2024)","text":"<ul> <li>Added generalized support for detecting server versions to provide timely exceptions to users</li> <li>Used new support to check that chunkegraph has updated version before using spatial bounds kwarg on client.chunkedgraph.level2_chunk_graph</li> <li>Added support for postign and getting segment properties files to client.state </li> </ul>"},{"location":"changelog/#5180","title":"5.18.0","text":"<ul> <li>Added serialization support for pandas.index</li> </ul>"},{"location":"changelog/#5173","title":"5.17.3","text":"<ul> <li>Minor documentation typo fix</li> </ul>"},{"location":"changelog/#5172","title":"5.17.2","text":"<ul> <li>Bug fixes related to table_manager interface</li> </ul>"},{"location":"changelog/#5171","title":"5.17.1","text":"<ul> <li>Bug fixes related to table_manager interface</li> </ul>"},{"location":"changelog/#5170","title":"5.17.0","text":"<ul> <li>Fix attrs in dataframe attributes of client.materialize results to remove numpy arrays to allow concatenation of dataframes</li> <li>Added getting multiple schemas in one call to improve initialization of table_manager interface of materialization</li> </ul>"},{"location":"changelog/#5161","title":"5.16.1","text":"<ul> <li>Bugfix on client.chunkedgrpah.level2_chunk_graph</li> </ul>"},{"location":"changelog/#5160","title":"5.16.0","text":"<ul> <li>Added bounding box query to client.chunkedgraph.level2_chunk_graph </li> <li>Fix default materialization version client when server not advertising correctly</li> </ul>"},{"location":"changelog/#5151-jan-18-2024","title":"5.15.1 (Jan 18, 2024)","text":"<ul> <li>minor improvements to release process</li> </ul>"},{"location":"changelog/#5150-jan-18-2024","title":"5.15.0 (Jan 18, 2024)","text":"<ul> <li>Improved documentation with types</li> <li>Improved testing on more python versions</li> <li>Bugfixes for pyton 3.12 compatability </li> </ul>"},{"location":"changelog/#5140-november-24-2023","title":"5.14.0 (November 24, 2023)","text":"<ul> <li>Made automatic detection of neuroglancer versioning when constructing link shortener links</li> </ul>"},{"location":"changelog/#5130-october-26-2023","title":"5.13.0 (October 26, 2023)","text":"<ul> <li>Add option to get expired versions to client.materialize.get_versions</li> </ul>"},{"location":"changelog/#5121-october-16-2023","title":"5.12.1 (October 16, 2023)","text":"<ul> <li>Bugfixes for client.chunkedgraph.get_latest_roots</li> </ul>"},{"location":"changelog/#5120-october-16-2023","title":"5.12.0 (October 16, 2023)","text":"<ul> <li>Improved logic for client.chunkedgraph.get_latest_roots to work forward or backwards in time</li> </ul>"},{"location":"changelog/#5110-september-19-2023","title":"5.11.0 (September 19, 2023)","text":"<ul> <li>Added filter_regex_dict options to client.materialize.query_table interface</li> </ul>"},{"location":"changelog/#5102-august-162023","title":"5.10.2 (August 16,2023)","text":"<ul> <li>Fixed pyarrow support for live_live query</li> </ul>"},{"location":"changelog/#5101-august-142023","title":"5.10.1  (August 14,2023)","text":"<ul> <li>Changed random_sample argument to be an integer number of annotations rather than a floating fraction of table</li> <li>Added option to live_query</li> </ul>"},{"location":"changelog/#590-august-14-2023","title":"5.9.0 (August 14, 2023)","text":"<ul> <li>Added support for native pyarrow deserialization, allowing upgrade to pyarrow version</li> </ul>"},{"location":"changelog/#580","title":"5.8.0","text":"<ul> <li>Allowed int64 root ids to serialize properly</li> <li>Added warning that client.materialize.tables interface is in beta</li> </ul>"},{"location":"changelog/#570","title":"5.7.0","text":"<ul> <li>Fix to ensure stop_layer is at least 1</li> <li>Added client.chunkedgraph.suggest_latest_roots</li> </ul>"},{"location":"changelog/#560","title":"5.6.0","text":"<ul> <li>Added views to client.materialize.tables interface</li> <li>Added optional argument to allow invalid root ids when querying live live, versus creating an exception</li> </ul>"},{"location":"changelog/#551","title":"5.5.1","text":"<ul> <li>documentation fixes on client.materialize.join_query</li> </ul>"},{"location":"changelog/#550","title":"5.5.0","text":"<ul> <li>added methods for different neuroglancer state formats to client.state.</li> </ul>"},{"location":"changelog/#543","title":"5.4.3","text":"<ul> <li>Added 'view' querying options to materialization</li> <li>Added client.materialize.tables interface</li> <li>Added client.materialize.get_tables_metadata to get all metadata in one call</li> </ul>"},{"location":"changelog/#520","title":"5.2.0","text":"<ul> <li>Added local caching of datastack names &gt; server_address to simplify initialization of clients  with servers other than global.daf-apis.com.</li> </ul> <p>Cache is saved on a local file ~/.cloudvolume/secrets/cave_datastack_to_server_map.json</p> <p>Cache will populate the first time caveclient.CAVEclient('my_datastack', server_address=\"https://my_server.com\") is called.  Subsequent calls can then just be caveclient.CAVEclient('my_datastack').</p>"},{"location":"changelog/#510","title":"5.1.0","text":"<ul> <li>Added get_oldest_timestamp call to chunkedgraph</li> </ul>"},{"location":"changelog/#501","title":"5.0.1","text":"<ul> <li>Fixed bug with desired_resolution being set at the client level   was being ignored in &gt;5.0.0</li> </ul>"},{"location":"changelog/#500","title":"5.0.0","text":"<ul> <li>Added support for the new CAVE Materialization 3.0 API   Includes support for the new materialization API, which allows for   server side conversion of the units of position, and ensures that   all positions are returned with the same units, even after joins.</li> <li>Added support for querying databases that were materialized without merging   tables together. This will allow for faster materializations.</li> <li>Removed support for LiveLive query from the Materialization 2.0 API client.   Note.. &lt;5.0.0 clients interacting with MaterializationEngine &gt;4.7.0 servers will   use live live query but will doubly convert the units of position if you ask   for a desired resolution, as the old client will also do a conversion server side.</li> <li>Fixed interaction with api version querying of servers from individual   clients to work with verify=False. (useful for testing)</li> <li>Stored infromation from client about mapping between dataframe and table names   and original column names.</li> <li>Added support for suffixes and select columns to be passed by dictionary rather than list   making the selection an application of suffixes more explicit when there are collisions   between column names in joined tables.</li> </ul>"},{"location":"changelog/#older-upgrade-notes","title":"Older Upgrade Notes","text":"<p>Change all select_column calls to pass dictionaries rather than lists. Change all suffix calls to pass dictionaries rather than lists. Advocate for your server administrator to upgrade to MaterializationEngine 4.7.0 or later, so you can use the new MaterializationEngine 3.0 API and client.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs to our issues page.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug, in the form of a minimal reproducible example.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p><code>caveclient</code> could always use more documentation, whether as part of the official <code>caveclient</code> docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to create an issue on GitHub.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that while contributions are welcome, developer/maintainer time is limited.</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started","text":"<p>Ready to contribute? Here's how to set up <code>caveclient</code> for local development.</p> <ul> <li>Fork the repo on GitHub.</li> <li>Clone your fork locally</li> </ul> <pre><code>git clone git@github.com:your_name_here/CAVEclient.git\n</code></pre> <ul> <li>Ensure pip is installed.</li> <li>Create a virtual environment (here we use venv):</li> </ul> <pre><code>python3 -m venv .venv\n</code></pre> <ul> <li>Start your virtualenv:</li> </ul> <pre><code>source .venv/bin/activate\n</code></pre> <ul> <li>Create a branch for local development:</li> </ul> <pre><code>git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <ul> <li>Make your changes locally</li> <li>Install development requirements:</li> </ul> <pre><code>pip install -r test_requirements.txt\npip install -e .\n</code></pre> <ul> <li>When you're done making changes, check that your changes pass the   tests by running pytest:</li> </ul> <pre><code>pytest tests\n</code></pre> <p>Note that once you submit your pull request, GitHub Actions will run the tests also,   including on multiple operating systems and Python versions. Your pull request will   have to pass on all of these before it can be merged.</p> <ul> <li>Ensure your contribution meets style guidelines. First, install ruff:</li> </ul> <pre><code>pip install ruff\n</code></pre> <ul> <li>Fix linting and formatting. From the root of the repository, run the following commands:</li> </ul> <pre><code>ruff check . --extend-select I --fix\nruff format .\n</code></pre> <ul> <li>Commit your changes and push your branch to GitHub:</li> </ul> <pre><code>git add .\ngit commit -m \"Your detailed description of your changes.\"\ngit push origin name-of-your-bugfix-or-feature\n</code></pre> <ul> <li>Submit a pull request through the GitHub website.</li> </ul>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ul> <li>The pull request should include tests if adding a new feature.</li> <li>The docs should be updated with whatever changes you have made. Put   your new functionality into a function with a docstring, and make sure the new   functionality is documented after building the documentation.</li> </ul>"},{"location":"contributing/#documentation-style","title":"Documentation style","text":"<p>We use mkdocs to build the documentation. In particular, we use the mkdocs-material theme, and a variety of other extensions.</p> <p>Note</p> <p>More information codifying our documentation style and principles coming soon. For now, just try to follow the style of the existing documentation.</p>"},{"location":"glossary/","title":"Glossary","text":"<p>Warning</p> <p>This glossary is a work in progress; for now we are documenting the commonly used  terms that we need to define. Please feel free to contribute definitions or  additional terms.</p> <ul> <li>Datastack</li> <li>Voxel resolution</li> <li>Segmentation resolution</li> <li>MIP</li> <li>Segmentation</li> <li>View</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install <code>caveclient</code>, run this command in your terminal:</p> <pre><code>pip install caveclient\n</code></pre> <p>This is the preferred method to install <code>caveclient</code>, as it will always install the most recent stable release.</p> <p>You can also specify a particular version, e.g.</p> <pre><code>pip install caveclient==5.0.0\n</code></pre> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for <code>caveclient</code> can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>git clone git://github.com/CAVEconnectome/CAVEclient\n</code></pre> <p>Or download the tarball:</p> <pre><code>curl -OJL https://github.com/CAVEconnectome/CAVEclient/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>pip install .\n</code></pre> <p>Or in editable mode, it can be installed with:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"client_api/","title":"Overview","text":"<p>The most common method of interacting with the CAVE Framework is by instantiating a client (<code>caveclient.CAVEclient</code>) and then using that client to interact with various services. Under the hood, the CAVEclient is a collection of individual clients, which can be accessed via properties. For example, to access the materialization client, you can use <code>client.materialize</code>, which (up to the exact version) will actually return a caveclient.materializationengine.MaterializationClientV3 object.</p> <p>These pages describe the functionality of each of the individual clients, assuming that you are using the most up-to-date version of each. For more detailed information on all versions of all clients available, visit the extended API documentation.</p>"},{"location":"client_api/annotation/","title":"client.annotation","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the annotation service. If something seems wrong with the documentation here, try checking the version of the annotation engine returned by your client: <pre><code>type(client.annotation)\n</code></pre> Extended documentation for all versions of the annotation client can be found here.</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.create_table","title":"<code>create_table(table_name, schema_name, description, voxel_resolution, reference_table=None, track_target_id_updates=None, flat_segmentation_source=None, user_id=None, aligned_volume_name=None, write_permission='PRIVATE', read_permission='PUBLIC', notice_text=None)</code>","text":"<p>Creates a new data table based on an existing schema</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the new table. Cannot be the same as an existing table</p> required <code>schema_name</code> <code>str</code> <p>Name of the schema for the new table.</p> required <code>description</code> <code>str</code> <p>Human readable description for what is in the table. Should include information about who generated the table What data it covers, and how it should be interpreted. And who should you talk to if you want to use it. An Example: a manual synapse table to detect chandelier synapses on 81 PyC cells with complete AISs [created by Agnes - agnesb@alleninstitute.org, uploaded by Forrest]</p> required <code>voxel_resolution</code> <code>List[float]</code> <p>voxel resolution points will be uploaded in, typically nm, i.e [1,1,1] means nanometers [4,4,40] would be 4nm, 4nm, 40nm voxels</p> required <code>reference_table</code> <code>str</code> <p>If the schema you are using is a reference schema Meaning it is an annotation of another annotation. Then you need to specify what the target table those annotations are in.</p> <code>None</code> <code>track_target_id_updates</code> <code>bool</code> <p>Indicates whether to automatically update reference table's foreign key if target annotation table row is updated.</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>the source to a flat segmentation that corresponds to this table i.e. precomputed:\\gs:\\mybucket      his_tables_annotation</p> <code>None</code> <code>user_id</code> <code>int</code> <p>If you are uploading this schema on someone else's behalf and you want to link this table with their ID, you can specify it here Otherwise, the table will be created with your userID in the user_id column.</p> <code>None</code> <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table (DEFAULT) GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable</p> <code>'PRIVATE'</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data (DEFAULT)</p> <code>'PUBLIC'</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None, no text. If you want to remove text, send empty string.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p> <p>Examples:</p> <p>Basic annotation table:</p> <pre><code>description = \"Some description about the table\"\nvoxel_res = [4,4,40]\nclient.create_table(\"some_synapse_table\", \"synapse\", description, voxel_res)\n</code></pre>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.delete_annotation","title":"<code>delete_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Delete one or more annotations in a table. Annotations that are deleted are recorded as 'non-valid' but are not physically removed from the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>annotation_ids</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.delete_table","title":"<code>delete_table(table_name, aligned_volume_name=None)</code>","text":"<p>Marks a table for deletion requires super admin privileges</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.get_annotation","title":"<code>get_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Retrieve an annotation or annotations by id(s) and table name.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table</p> required <code>annotation_ids</code> <code>int or iterable</code> <p>ID or IDS of the annotation to retreive</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>Annotation data</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.get_annotation_count","title":"<code>get_annotation_count(table_name, aligned_volume_name=None)</code>","text":"<p>Get number of annotations in a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>number of annotations</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.get_table_metadata","title":"<code>get_table_metadata(table_name, aligned_volume_name=None)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>metadata about table</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.get_tables","title":"<code>get_tables(aligned_volume_name=None)</code>","text":"<p>Gets a list of table names for a aligned_volume_name</p> <p>Parameters:</p> Name Type Description Default <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.post_annotation","title":"<code>post_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations refer to 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.post_annotation_df","title":"<code>post_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations see 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.process_position_columns","title":"<code>process_position_columns(df, position_columns)</code>  <code>staticmethod</code>","text":"<p>Process a dataframe into a list of dictionaries</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to process</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>See <code>.post_annotation_df</code></p> required <p>Returns:</p> Type Description <code>dict</code> <p>Annotations ready for posting</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.stage_annotations","title":"<code>stage_annotations(table_name=None, schema_name=None, update=False, id_field=False, table_resolution=None, annotation_resolution=None)</code>","text":"<p>Get a StagedAnnotations object to help produce correctly formatted annotations for a given table or schema. StagedAnnotation objects can be uploaded directly with <code>upload_staged_annotations</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name to stage annotations for, by default None.</p> <code>None</code> <code>schema_name</code> <code>str</code> <p>Schema name to use to make annotations. Only needed if the table_name is not set, by default None</p> <code>None</code> <code>update</code> <code>bool</code> <p>Set to True if individual annotations are going to be updated, by default False.</p> <code>False</code> <code>id_field</code> <code>bool</code> <p>Set to True if id fields are to be specified. Not needed if update is True, which always needs id fields. Optional, by default False</p> <code>False</code> <code>table_resolution</code> <code>list - like or None</code> <p>Voxel resolution of spatial points in the table in nanometers. This is found automatically from the info service if a table name is provided, by default None. If annotation_resolution is also set, this allows points to be scaled correctly for the table.</p> <code>None</code> <code>annotation_resolution</code> <code>list - like</code> <p>Voxel resolution of spatial points provided by the user when creating annotations. If the table resolution is also available (manually or from the info service), annotations are correctly rescaled for the volume. By default, None.</p> <code>None</code>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.update_annotation","title":"<code>update_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Update one or more new annotations to a table in the AnnotationEngine. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.update_annotation_df","title":"<code>update_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Update one or more annotations to a table in the AnnotationEngine using a dataframe as format. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Iterable[str] or Mapping[str, str] or None</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.update_metadata","title":"<code>update_metadata(table_name, description=None, flat_segmentation_source=None, read_permission=None, write_permission=None, user_id=None, notice_text=None, aligned_volume_name=None)</code>","text":"<p>Update the metadata on an existing table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> required <code>description</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data Defaults to None (will not update).</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable Defaults to None (will not update).</p> <code>None</code> <code>user_id</code> <code>int</code> <p>Note, if you use this you will not be able to update the metadata on this table any longer and depending on permissions may not be able to read or write to it Defaults to None. (will not update)</p> <code>None</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None. (will not update)</p> <code>None</code> <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code>"},{"location":"client_api/annotation/#caveclient.annotationengine.AnnotationClientV2.upload_staged_annotations","title":"<code>upload_staged_annotations(staged_annos, aligned_volume_name=None)</code>","text":"<p>Upload annotations directly from an Annotation Guide object. This method uses the options specified in the object, including table name and if the annotation is an update or not.</p> <p>Parameters:</p> Name Type Description Default <code>staged_annos</code> <code>AnnotationGuide</code> <p>AnnotationGuide object with a specified table name and a collection of annotations already filled in.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>List or dict</code> <p>If new annotations are posted, a list of ids. If annotations are being updated, a dictionary with the mapping from old ids to new ids.</p>"},{"location":"client_api/auth/","title":"client.auth","text":""},{"location":"client_api/auth/#caveclient.auth.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"client_api/auth/#caveclient.auth.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"client_api/auth/#caveclient.auth.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"client_api/chunkedgraph/","title":"client.chunkedgraph","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the chunkedgraph service. If something seems wrong with the documentation here, try checking the version of the chunkedgraph returned by your client: <pre><code>type(client.chunkedgraph)\n</code></pre> Extended documentation for all versions of the chunkedgraph client can be found here.</p> <p>ChunkedGraph Client for the v1 API</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.segmentation_info","title":"<code>segmentation_info</code>  <code>property</code>","text":"<p>Complete segmentation metadata</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.base_resolution","title":"<code>base_resolution</code>  <code>property</code>","text":"<p>MIP 0 resolution for voxels assumed by the ChunkedGraph</p> <p>Returns:</p> Type Description <code>list</code> <p>3-long list of x/y/z voxel dimensions in nm</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_roots","title":"<code>get_roots(supervoxel_ids, timestamp=None, stop_layer=None)</code>","text":"<p>Get the root ID for a list of supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_ids</code> <code>list or np.array of int</code> <p>Supervoxel IDs to look up.</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <code>stop_layer</code> <code>int or None</code> <p>If True, looks up IDs only up to a given stop layer. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.uint64</code> <p>Root IDs containing each supervoxel.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_root_id","title":"<code>get_root_id(supervoxel_id, timestamp=None, level2=False)</code>","text":"<p>Get the root ID for a specified supervoxel.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_id</code> <code>int</code> <p>Supervoxel id value</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <p>Returns:</p> Type Description <code>int64</code> <p>Root ID containing the supervoxel.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_merge_log","title":"<code>get_merge_log(root_id)</code>","text":"<p>Get the merge log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of merge events in the history of the object.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_change_log","title":"<code>get_change_log(root_id, filtered=True)</code>","text":"<p>Get the change log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query object <code>root_id</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary summarizing split and merge events in the object history, containing the following keys:</p> <ul> <li>\"n_merges\": int<ul> <li>Number of merges</li> </ul> </li> <li>\"n_splits\": int<ul> <li>Number of splits</li> </ul> </li> <li>\"operations_ids\": list of int<ul> <li>Identifiers for each operation</li> </ul> </li> <li>\"past_ids\": list of int<ul> <li>Previous root ids for this object</li> </ul> </li> <li>\"user_info\": dict of dict<ul> <li>Dictionary keyed by user (string) to a dictionary specifying how many   merges and splits that user performed on this object</li> </ul> </li> </ul>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_user_operations","title":"<code>get_user_operations(user_id, timestamp_start, include_undo=True, timestamp_end=None)</code>","text":"<p>Get operation details for a user ID. Currently, this is only available to admins.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>User ID to query (use 0 for all users (admin only)).</p> required <code>timestamp_start</code> <code>datetime</code> <p>Timestamp to start filter (UTC).</p> required <code>include_undo</code> <code>bool</code> <p>Whether to include undos. Defaults to True.</p> <code>True</code> <code>timestamp_end</code> <code>datetime</code> <p>Timestamp to end filter (UTC). Defaults to now.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame including the following columns:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": datetime.datetime<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> </ul>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_tabular_change_log","title":"<code>get_tabular_change_log(root_ids, filtered=True)</code>","text":"<p>Get a detailed changelog for neurons.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>list of int</code> <p>Object root IDs to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query objects in <code>root_ids</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict of pd.DataFrame</code> <p>The keys are the root IDs, and the values are DataFrames with the following columns and datatypes:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": int<ul> <li>Timestamp of the operation, provided in milliseconds. To convert to datetime, use <code>datetime.datetime.utcfromtimestamp(timestamp/1000)</code>.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> <li>\"before_root_ids: list of int<ul> <li>Root IDs of objects that existed before the operation.</li> </ul> </li> <li>\"after_root_ids: list of int<ul> <li>Root IDs of objects created by the operation. Note that this only records the root id that was kept as part of the query object, so there will only be one in this list.</li> </ul> </li> <li>\"is_merge\": bool<ul> <li>Whether the operation was a merge.</li> </ul> </li> <li>\"user_name\": str<ul> <li>Name of the user who performed the operation.</li> </ul> </li> <li>\"user_affiliation\": str<ul> <li>Affiliation of the user who performed the operation.</li> </ul> </li> </ul>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_leaves","title":"<code>get_leaves(root_id, bounds=None, stop_layer=None)</code>","text":"<p>Get all supervoxels for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>If specified, returns supervoxels within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code>. If None, finds all supervoxels.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>If specified, returns chunkedgraph nodes at layer <code>stop_layer</code> default will be <code>stop_layer=1</code> (supervoxels).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Array of supervoxel IDs (or node ids if <code>stop_layer&gt;1</code>).</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.do_merge","title":"<code>do_merge(supervoxels, coords, resolution=(4, 4, 40))</code>","text":"<p>Perform a merge on the chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxels</code> <code>iterable</code> <p>An N-long list of supervoxels to merge.</p> required <code>coords</code> <code>array</code> <p>An Nx3 array of coordinates of the supervoxels in units of <code>resolution</code>.</p> required <code>resolution</code> <code>tuple</code> <p>What to multiply <code>coords</code> by to get nanometers. Defaults to (4,4,40).</p> <code>(4, 4, 40)</code>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.undo_operation","title":"<code>undo_operation(operation_id)</code>","text":"<p>Undo an operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation_id</code> <code>int</code> <p>Operation ID to undo.</p> required <p>Returns:</p> Type Description <code>dict</code>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.execute_split","title":"<code>execute_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None)</code>","text":"<p>Execute a multicut split based on points or supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>operation_id</code> <code>int</code> <p>Unique ID of the split operation</p> <code>new_root_ids</code> <code>list of int</code> <p>List of new root IDs resulting from the split operation.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.preview_split","title":"<code>preview_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None, return_additional_ccs=False)</code>","text":"<p>Get supervoxel connected components from a preview multicut split.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>return_additional_ccs</code> <code>bool</code> <p>If True, returns any additional connected components beyond the ones with source and sink points. In most situations, this can be ignored. By default, False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>source_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most source points.</p> <code>sink_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most sink points.</p> <code>successful_split</code> <code>bool</code> <p>True if the split worked.</p> <code>other_connected_components (optional) : list of lists of int</code> <p>List of lists of supervoxel IDs for any other resulting connected components. Only returned if <code>return_additional_ccs</code> is True.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_children","title":"<code>get_children(node_id)</code>","text":"<p>Get the children of a node in the chunked graph hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node ID to query.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>IDs of child nodes.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_contact_sites","title":"<code>get_contact_sites(root_id, bounds, calc_partners=False)</code>","text":"<p>Get contacts for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>Bounds within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code> for which to find contacts. Running this query without bounds is too slow.</p> required <code>calc_partners</code> <code>bool</code> <p>If True, get partner root IDs. By default, False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict relating ids to contacts</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.find_path","title":"<code>find_path(root_id, src_pt, dst_pt, precision_mode=False)</code>","text":"<p>Find a path between two locations on a root ID using the level 2 chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>src_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the source point.</p> required <code>dst_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the destination point.</p> required <code>precision_mode</code> <code>bool</code> <p>Whether to perform the search in precision mode. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>centroids_list</code> <code>array</code> <p>Array of centroids along the path.</p> <code>l2_path</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs along the path.</p> <code>failed_l2_ids</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs that failed to find a path.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_subgraph","title":"<code>get_subgraph(root_id, bounds)</code>","text":"<p>Get subgraph of root id within a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root (or any node ID) of chunked graph to query.</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Node IDs in the subgraph.</p> <code>np.array of np.double</code> <p>Affinities of edges in the subgraph.</p> <code>np.array of np.int32</code> <p>Areas of nodes in the subgraph.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.level2_chunk_graph","title":"<code>level2_chunk_graph(root_id, bounds=None)</code>","text":"<p>Get graph of level 2 chunks, the smallest agglomeration level above supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root id of object</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates (use <code>client.chunkedgraph.base_resolution</code> to view this default resolution for your chunkedgraph client). Note that the result will include any level 2 nodes which have chunk boundaries within some part of this bounding box, meaning that the representative point for a given level 2 node could still be slightly outside of these bounds. If None, returns all level 2 chunks for the root ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>list of list</code> <p>Edge list for level 2 chunked graph. Each element of the list is an edge, and each edge is a list of two node IDs (source and target).</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.remesh_level2_chunks","title":"<code>remesh_level2_chunks(chunk_ids)</code>","text":"<p>Submit specific level 2 chunks to be remeshed in case of a problem.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_ids</code> <code>list</code> <p>List of level 2 chunk IDs.</p> required"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_operation_details","title":"<code>get_operation_details(operation_ids)</code>","text":"<p>Get the details of a list of operations.</p> <p>Parameters:</p> Name Type Description Default <code>operation_ids</code> <code>Iterable[int]</code> <p>List/array of operation IDs.</p> required <p>Returns:</p> Type Description <code>dict of str to dict</code> <p>A dict of dicts of operation info, keys are operation IDs (as strings), values are a dictionary of operation info for the operation. These dictionaries contain the following keys:</p> <ul> <li>\"added_edges\"/\"removed_edges\": list of list of int<ul> <li>List of edges added (if a merge) or removed (if a split) by this operation. Each edge is a list of two supervoxel IDs (source and target).</li> </ul> </li> <li>\"roots\": list of int<ul> <li>List of root IDs that were created by this operation.</li> </ul> </li> <li>\"sink_coords\": list of list of int<ul> <li>List of sink coordinates for this operation. The sink is one of the points placed by the user when specifying the operation. Each sink coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"source_coords\": list of list of int<ul> <li>List of source coordinates for this operation. The source is one of the points placed by the user when specifying the operation. Each source coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"timestamp\": str<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user\": str<ul> <li>User ID number who performed the operation (as a string).</li> </ul> </li> </ul>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_lineage_graph","title":"<code>get_lineage_graph(root_id, timestamp_past=None, timestamp_future=None, as_nx_graph=False, exclude_links_to_future=False, exclude_links_to_past=False)</code>","text":"<p>Returns the lineage graph for a root ID, optionally cut off in the past or the future.</p> <p>Each change in the chunked graph creates a new root ID for the object after that change. This function returns a graph of all root IDs for a given object, tracing the history of the object in terms of merges and splits.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the lineage graph backwards in time. By default, None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Cutoff for the lineage graph going forwards in time. By default, None.</p> <code>None</code> <code>as_nx_graph</code> <p>If True, a NetworkX graph is returned.</p> <code>False</code> <code>exclude_links_to_future</code> <p>If True, links from nodes before <code>timestamp_future</code> to after <code>timestamp_future</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <code>exclude_links_to_past</code> <p>If True, links from nodes before <code>timestamp_past</code> to after <code>timestamp_past</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary describing the lineage graph and operations for the root ID. Not returned if <code>as_nx_graph</code> is True. The dictionary contains the following keys:</p> <ul> <li>\"directed\" : bool<ul> <li>Whether the graph is directed.</li> </ul> </li> <li>\"graph\" : dict<ul> <li>Dictionary of graph attributes.</li> </ul> </li> <li>\"links\" : list of dict<ul> <li>Each element of the list is a dictionary describing an edge in the lineage graph as \"source\" and \"target\" keys.</li> </ul> </li> <li>\"multigraph\" : bool<ul> <li>Whether the graph is a multigraph.</li> </ul> </li> <li>\"nodes\" : list of dict<ul> <li>Each element of the list is a dictionary describing a node in the lineage graph, usually with \"id\", \"timestamp\", and \"operation_id\" keys.</li> </ul> </li> </ul> <code>DiGraph</code> <p>NetworkX directed graph of the lineage graph. Only returned if <code>as_nx_graph</code> is True.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_latest_roots","title":"<code>get_latest_roots(root_id, timestamp=None, timestamp_future=None)</code>","text":"<p>Returns root IDs that are related to the given <code>root_id</code> at a given timestamp. Can be used to find the \"latest\" root IDs associated with an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp</code> <code>datetime or None</code> <p>Timestamp of where to query IDs from. If None then will assume you want till now.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>DEPRECATED name, use <code>timestamp</code> instead. Timestamp to suggest IDs from (note can be in the past relative to the root). By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_original_roots","title":"<code>get_original_roots(root_id, timestamp_past=None)</code>","text":"<p>Returns root IDs that are the latest successors of a given root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the search going backwards in time. By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.is_latest_roots","title":"<code>is_latest_roots(root_ids, timestamp=None)</code>","text":"<p>Check whether these root IDs are still a root at this timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>array-like of int</code> <p>Root IDs to check.</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs are valid root IDs in the chunked graph. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid root IDs.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.suggest_latest_roots","title":"<code>suggest_latest_roots(root_id, timestamp=None, stop_layer=None, return_all=False, return_fraction_overlap=False)</code>","text":"<p>Suggest latest roots for a given root id, based on overlap of component chunk IDs. Note that edits change chunk IDs, and so this effectively measures the fraction of unchanged chunks at a given chunk layer, which sets the size scale of chunks. Higher layers are coarser.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID of the potentially outdated object.</p> required <code>timestamp</code> <code>datetime</code> <p>Datetime at which \"latest\" roots are being computed, by default None. If None, the current time is used. Note that this has to be a timestamp after the creation of the <code>root_id</code>.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>Chunk level at which to compute overlap, by default None. No value will take the 4th from the top layer, which emphasizes speed and works well for larger objects. Lower values are slower but more fine-grained. Values under 2 (i.e. supervoxels) are not recommended except in extremely fine grained scenarios.</p> <code>None</code> <code>return_all</code> <code>bool</code> <p>If True, return all current IDs sorted from most overlap to least, by default False. If False, only the top is returned.</p> <code>False</code> <code>return_fraction_overlap</code> <code>bool</code> <p>If True, return all fractions sorted by most overlap to least, by default False. If False, only the top value is returned.</p> <code>False</code>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.is_valid_nodes","title":"<code>is_valid_nodes(node_ids, start_timestamp=None, end_timestamp=None)</code>","text":"<p>Check whether nodes are valid for given timestamp range.</p> <p>Valid is defined as existing in the chunked graph. This makes no statement about these IDs being roots, supervoxel or anything in-between. It also does not take into account whether a root ID has since been edited.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>array-like of int</code> <p>Node IDs to check.</p> required <code>start_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid after this timestamp. Defaults to None (assumes now).</p> <code>None</code> <code>end_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid before this timestamp. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid IDs.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_root_timestamps","title":"<code>get_root_timestamps(root_ids)</code>","text":"<p>Retrieves timestamps when roots where created.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <p>Iterable of root IDs to query.</p> required <p>Returns:</p> Type Description <code>np.array of datetime.datetime</code> <p>Array of timestamps when <code>root_ids</code> were created.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_past_ids","title":"<code>get_past_ids(root_ids, timestamp_past=None, timestamp_future=None)</code>","text":"<p>For a set of root IDs, get the list of IDs at a past or future time point that could contain parts of the same object.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>Iterable of int</code> <p>Iterable of root IDs to query.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Time of a point in the past for which to look up root ids. Default is None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Time of a point in the future for which to look up root ids. Not implemented on the server currently. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict with keys \"future_id_map\" and \"past_id_map\". Each is a dict whose keys are the supplied <code>root_ids</code> and whose values are the list of related root IDs at <code>timestamp_past</code>/<code>timestamp_future</code>.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_delta_roots","title":"<code>get_delta_roots(timestamp_past, timestamp_future=datetime.datetime.now(datetime.timezone.utc))</code>","text":"<p>Get the list of roots that have changed between <code>timetamp_past</code> and <code>timestamp_future</code>.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp_past</code> <code>datetime</code> <p>Past timepoint to query</p> required <code>timestamp_future</code> <code>datetime</code> <p>Future timepoint to query. Defaults to <code>datetime.datetime.now(datetime.timezone.utc)</code>.</p> <code>now(utc)</code> <p>Returns:</p> Name Type Description <code>old_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that have expired in that interval.</p> <code>new_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that are new in that interval.</p>"},{"location":"client_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_oldest_timestamp","title":"<code>get_oldest_timestamp()</code>","text":"<p>Get the oldest timestamp in the database.</p> <p>Returns:</p> Type Description <code>datetime</code> <p>Oldest timestamp in the database.</p>"},{"location":"client_api/client/","title":"CAVEclient","text":"<p>A manager for all clients sharing common datastack and authentication information.</p> <p>This client wraps all the other clients and keeps track of the things that need to be consistent across them. To instantiate a client:</p> <pre><code>client = CAVEclient(datastack_name='my_datastack',\n                         server_address='www.myserver.com',\n                         auth_token_file='~/.mysecrets/secrets.json')\n</code></pre> <p>Then</p> <ul> <li><code>client.annotation</code> is an <code>AnnotationClient</code> (see client.annotation)</li> <li><code>client.auth</code> is an <code>AuthClient</code> (see client.auth)</li> <li><code>client.chunkedgraph</code> is a <code>ChunkedGraphClient</code> (see client.chunkedgraph)</li> <li><code>client.info</code> is an <code>InfoServiceClient</code> (see client.info)</li> <li><code>client.l2cache</code> is an <code>L2CacheClient</code> (see client.l2cache)</li> <li><code>client.materialize</code> is a <code>MaterializationClient</code> (see client.materialize)</li> <li><code>client.schema</code> is a <code>SchemaClient</code> (see client.schema)</li> <li><code>client.state</code> is a neuroglancer <code>JSONService</code> (see client.state)</li> </ul> <p>All subclients are loaded lazily and share the same datastack name, server address, and auth tokens where used.</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>Datastack name for the services. Almost all services need this and will not work if it is not passed.</p> <code>None</code> <code>server_address</code> <code>str or None</code> <p>URL of the framework server. If None, chooses the default server global.daf-apis.com. Optional, defaults to None.</p> <code>None</code> <code>auth_token_file</code> <code>str or None</code> <p>Path to a json file containing the auth token. If None, uses the default location. See Auth client documentation. Optional, defaults to None.</p> <code>default_token_file</code> <code>auth_token_key</code> <code>str</code> <p>Dictionary key for the token in the the JSON file. Optional, default is 'token'.</p> <code>'token'</code> <code>auth_token</code> <code>str or None</code> <p>Direct entry of an auth token. If None, uses the file arguments to find the token. Optional, default is None.</p> <code>None</code> <code>max_retries</code> <code>int or None</code> <p>Sets the default number of retries on failed requests. Optional, by default 2.</p> <code>DEFAULT_RETRIES</code> <code>pool_maxsize</code> <code>int or None</code> <p>Sets the max number of threads in a requests pool, although this value will be exceeded if pool_block is set to False. Optional, uses requests defaults if None.</p> <code>None</code> <code>pool_block</code> <p>If True, prevents the number of threads in a requests pool from exceeding the max size. Optional, uses requests defaults (False) if None.</p> <code>None</code> <code>desired_resolution</code> <code>Iterable[float] or None</code> <p>If given, should be a list or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <code>info_cache</code> <p>Pre-computed info cache, bypassing the lookup of datastack info from the info service. Should only be used in cases where this information is cached and thus repetitive lookups can be avoided.</p> <code>None</code>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.annotation","title":"<code>annotation: AnnotationClientV2</code>  <code>property</code>","text":"<p>A client for the annotation service. See client.annotation for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.auth","title":"<code>auth: AuthClient</code>  <code>property</code>","text":"<p>A client for the auth service. See client.auth for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.chunkedgraph","title":"<code>chunkedgraph: ChunkedGraphClientV1</code>  <code>property</code>","text":"<p>A client for the chunkedgraph service. See client.chunkedgraph for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.datastack_name","title":"<code>datastack_name: str</code>  <code>property</code>","text":"<p>The name of the datastack for the client.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.info","title":"<code>info: InfoServiceClientV2</code>  <code>property</code>","text":"<p>A client for the info service. See client.info for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.l2cache","title":"<code>l2cache: L2CacheClientLegacy</code>  <code>property</code>","text":"<p>A client for the L2 cache service. See client.l2cache for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.materialize","title":"<code>materialize: MaterializationClientType</code>  <code>property</code>","text":"<p>A client for the materialization service. See client.materialize for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.schema","title":"<code>schema: SchemaClientLegacy</code>  <code>property</code>","text":"<p>A client for the EM Annotation Schemas service. See client.schema for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.server_address","title":"<code>server_address</code>  <code>property</code>","text":"<p>The server address for the client.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.state","title":"<code>state: JSONServiceV1</code>  <code>property</code>","text":"<p>A client for the neuroglancer state service. See client.state for more information.</p>"},{"location":"client_api/client/#caveclient.frameworkclient.CAVEclientFull.change_auth","title":"<code>change_auth(auth_token_file=None, auth_token_key=None, auth_token=None)</code>","text":"<p>Change the authentication token and reset services.</p> <p>Parameters:</p> Name Type Description Default <code>auth_token_file</code> <code>str</code> <p>New auth token json file path, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token_key</code> <code>str</code> <p>New dictionary key under which the token is stored in the json file, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token</code> <code>str</code> <p>Direct entry of a new token, by default None.</p> <code>None</code>"},{"location":"client_api/info/","title":"client.info","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the info service. If something seems wrong with the documentation here, try checking the version of the L2 cache returned by your client: <pre><code>type(client.info)\n</code></pre> Extended documentation for all versions of the info service client can be found here.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.annotation_endpoint","title":"<code>annotation_endpoint(datastack_name=None, use_stored=True)</code>","text":"<p>AnnotationEngine endpoint for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Location of the AnnotationEngine</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.get_aligned_volume_info","title":"<code>get_aligned_volume_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a aligned_volume</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack_name to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that dataset, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the aligned_volume</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.get_datastack_info","title":"<code>get_datastack_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that datastack, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the datastack</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.get_datastacks","title":"<code>get_datastacks()</code>","text":"<p>Query which datastacks are available at the info service</p> <p>Returns:</p> Type Description <code>list</code> <p>List of datastack names</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.get_datastacks_by_aligned_volume","title":"<code>get_datastacks_by_aligned_volume(aligned_volume=None)</code>","text":"<p>Lookup what datastacks are associated with this aligned volume</p> <p>Args:     aligned_volume (str, optional): aligned volume to lookup. Defaults to None.</p> <p>Raises:     ValueError: if no aligned volume is specified</p> <p>Returns:     list: a list of datastack string</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.image_cloudvolume","title":"<code>image_cloudvolume(**kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the image source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.image_source","title":"<code>image_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the imagery for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the flat segmentation</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.refresh_stored_data","title":"<code>refresh_stored_data()</code>","text":"<p>Reload the stored info values from the server.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.segmentation_cloudvolume","title":"<code>segmentation_cloudvolume(use_client_secret=True, **kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the segmentation source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.segmentation_source","title":"<code>segmentation_source(datastack_name=None, format_for='raw', use_stored=True)</code>","text":"<p>Cloud path to the chunkgraph-backed Graphene segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"graphene://https://\" type path is used If 'neuroglancer', a \"graphene://https://\" type path is used, as needed by Neuroglancer.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the Graphene segmentation</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.synapse_segmentation_source","title":"<code>synapse_segmentation_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the synapse segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the dataset to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the synapse segmentation</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.viewer_resolution","title":"<code>viewer_resolution(datastack_name=None, use_stored=True)</code>","text":"<p>Get the viewer resolution metadata for this datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <p>If None use the default one configured in the client</p> <code>None</code> <code>use_stored</code> <p>Use the cached value, if False go get a new value from server</p> <code>True</code> <p>Returns:</p> Type Description <code>array</code> <p>Voxel resolution as a len(3) np.array</p>"},{"location":"client_api/info/#caveclient.infoservice.InfoServiceClientV2.viewer_site","title":"<code>viewer_site(datastack_name=None, use_stored=True)</code>","text":"<p>Get the base Neuroglancer URL for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Base URL for the Neuroglancer viewer</p>"},{"location":"client_api/l2cache/","title":"client.l2cache","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the L2 cache. If something seems wrong with the documentation here, try checking the version of the L2 cache returned by your client: <pre><code>type(client.l2cache)\n</code></pre> Extended documentation for all versions of the L2 cache client can be found here.</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.cache_metadata","title":"<code>cache_metadata()</code>","text":"<p>Retrieves the meta data for the cache</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are attribute names, values are datatypes</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.get_l2data","title":"<code>get_l2data(l2_ids, attributes=None)</code>","text":"<p>Gets the attributed statistics data for L2 ids.</p> <p>Parameters:</p> Name Type Description Default <code>l2_ids</code> <code>list or ndarray</code> <p>a list of level 2 ids</p> required <code>attributes</code> <code>list</code> <p>a list of attributes to retrieve. Defaults to None which will return all that are available. Available stats are ['area_nm2', 'chunk_intersect_count', 'max_dt_nm', 'mean_dt_nm', 'pca', 'pca_val', 'rep_coord_nm', 'size_nm3']. See docs for more description.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>keys are l2 ids, values are data</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.has_cache","title":"<code>has_cache(datastack_name=None)</code>","text":"<p>Checks if the l2 cache is available for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>The name of the datastack to check, by default None (if None, uses the client's datastack)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the l2 cache is available, False otherwise</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.table_mapping","title":"<code>table_mapping()</code>","text":"<p>Retrieves table mappings for l2 cache.</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are pcg table names, values are dicts with fields <code>l2cache_id</code> and <code>cv_path</code>.</p>"},{"location":"client_api/materialize/","title":"client.materialize","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the materialization engine. If something seems wrong with the documentation here, try checking the version of the materialization client returned by your client: <pre><code>type(client.materialize)\n</code></pre> Extended documentation for all versions of the annotation client can be found here.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_table_metadata","title":"<code>get_table_metadata(table_name, datastack_name=None, version=None, log_warning=True)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack_name. If None, uses the one specified in the client.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version to get. If None, uses the one specified in the client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to print out warnings to the logger. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata dictionary for table</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_tables","title":"<code>get_tables(datastack_name=None, version=None)</code>","text":"<p>Gets a list of table names for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <code>version</code> <code>int or None</code> <p>the version to query, else get the tables in the most recent version</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_tables_metadata","title":"<code>get_tables_metadata(datastack_name=None, version=None, log_warning=True)</code>","text":"<p>Get metadata about tables</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack_name. If None, uses the one specified in the client.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version to get. If None, uses the one specified in the client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to print out warnings to the logger. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata dictionary for table</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_timestamp","title":"<code>get_timestamp(version=None, datastack_name=None)</code>","text":"<p>Get datetime.datetime timestamp for a materialization version.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>datetime</code> <p>Datetime when the materialization version was frozen.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_unique_string_values","title":"<code>get_unique_string_values(table, datastack_name=None)</code>","text":"<p>Get unique string values for a table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>datastack_name</code> <code>Optional[str]</code> <p>Datastack to query. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str]</code> <p>A dictionary of column names and their unique values</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_version_metadata","title":"<code>get_version_metadata(version=None, datastack_name=None)</code>","text":"<p>Get metadata about a version</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of metadata about the version</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_versions","title":"<code>get_versions(datastack_name=None, expired=False)</code>","text":"<p>Get the versions available</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of versions available</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_versions_metadata","title":"<code>get_versions_metadata(datastack_name=None, expired=False)</code>","text":"<p>Get the metadata for all the versions that are presently available and valid</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of metadata dictionaries</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_view_metadata","title":"<code>get_view_metadata(view_name, materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get metadata for a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>Name of view to query.</p> required <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata of view</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_view_schema","title":"<code>get_view_schema(view_name, materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get schema for a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>Name of view to query.</p> required <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Schema of view.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_view_schemas","title":"<code>get_view_schemas(materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get schema for a view</p> <p>Parameters:</p> Name Type Description Default <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Schema of view.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.get_views","title":"<code>get_views(version=None, datastack_name=None)</code>","text":"<p>Get all available views for a version</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int</code> <p>Version to query. If None, uses the one specified in the client.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of views</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.ingest_annotation_table","title":"<code>ingest_annotation_table(table_name, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookup and root ID lookup of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.join_query","title":"<code>join_query(tables, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, suffixes=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, metadata=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list of lists with length 2 or 'str'</code> <p>list of two lists: first entries are table names, second entries are the columns used for the join.</p> required <code>filter_in_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names, inner layer: keys are column names. Values are bounding boxes as [[min_x, min_y,min_z],[max_x, max_y, max_z]], expressed in units of the voxel_resolution of this dataset. Defaults to None.</p> <code>None</code> <code>filter_regex_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names. inner layer: keys are column names, values are regex strings. Defaults to None</p> <code>None</code> <code>select_columns</code> <code>dict of lists of str</code> <p>keys are table names,values are the list of columns from that table. Defaults to None, which will select all tables.  Will be passed to server as select_column_maps. Passing a list will be passed as select_columns which is deprecated.</p> <code>None</code> <code>offset</code> <code>int</code> <p>result offset to use. Defaults to None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>maximum results to return (server will set upper limit, see get_server_config)</p> <code>None</code> <code>suffixes</code> <code>dict</code> <p>suffixes to use for duplicate columns, keys are table names, values are the suffix</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>datastack to query. If None defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>whether to return as a dataframe default True, if False, data is returned as json (slower)</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>whether to break position columns into x,y,z columns default False, if False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>version to query. If None defaults to one specified in client.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>toggle to return metadata If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to. Defaults to None will use defaults.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>if given, will do a tablesample of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a pandas dataframe of results of query</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.live_live_query","title":"<code>live_live_query(table, timestamp, joins=None, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, metadata=True, suffixes=None, desired_resolution=None, allow_missing_lookups=False, allow_invalid_root_ids=False, random_sample=None)</code>","text":"<p>Beta method for querying cave annotation tables with root IDs and annotations at a particular timestamp.  Note: this method requires more explicit mapping of filters and selection to table as its designed to test a more general endpoint that should eventually support complex joins.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Principle table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to query</p> required <code>joins</code> <p>List of joins, where each join is a list of [table1,column1, table2, column2]</p> <code>None</code> <code>filter_in_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to accept.</p> <code>None</code> <code>filter_out_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to reject.</p> <code>None</code> <code>filter_equal_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values to equate.</p> <code>None</code> <code>filter_spatial_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values of 2x3 list of bounds.</p> <code>None</code> <code>filter_regex_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values of regex strings.</p> <code>None</code> <code>select_columns</code> <p>A dictionary with tables as keys, values are lists of columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Value to offset query by.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Limit of query.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. Defaults to set by client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe.</p> <code>True</code> <code>suffixes</code> <code>dict</code> <p>What suffixes to use on joins, keys are table_names, values are suffixes.</p> <code>None</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to.</p> <code>None</code> <code>allow_missing_lookups</code> <code>bool</code> <p>If there are annotations without supervoxels and root IDs yet, allow results.</p> <code>False</code> <code>allow_invalid_root_ids</code> <code>bool</code> <p>If True, ignore root ids not valid at the given timestamp, otherwise raise an error.</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a table sample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <p>Results of query</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from caveclient import CAVEclient\n&gt;&gt;&gt; client = CAVEclient('minnie65_public_v117')\n&gt;&gt;&gt; live_live_query(\"table_name\", datetime.datetime.now(datetime.timezone.utc),\n&gt;&gt;&gt;    joins=[[table_name, table_column, joined_table, joined_column],\n&gt;&gt;&gt;             [joined_table, joincol2, third_table, joincol_third]]\n&gt;&gt;&gt;    suffixes={\n&gt;&gt;&gt;        \"table_name\":\"suffix1\",\n&gt;&gt;&gt;        \"joined_table\":\"suffix2\",\n&gt;&gt;&gt;        \"third_table\":\"suffix3\"\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    select_columns= {\n&gt;&gt;&gt;        \"table_name\":[ \"column\",\"names\"],\n&gt;&gt;&gt;        \"joined_table\":[\"joined_colum\"]\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_in_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[included,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_out_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[excluded,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_equal_dict\"={\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":value\n&gt;&gt;&gt;        },\n&gt;&gt;&gt;    filter_spatial_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": [[min_x, min_y, min_z], [max_x, max_y, max_z]]\n&gt;&gt;&gt;    }\n&gt;&gt;&gt;    filter_regex_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": \"regex_string\"\n&gt;&gt;&gt;     }\n</code></pre>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.live_query","title":"<code>live_query(table, timestamp, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, post_filter=True, metadata=True, merge_reference=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Time to materialize (in utc). Pass datetime.datetime.now(datetime.timezone.utc) for present time.</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries.</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries.</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry.</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]].</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings.</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Offset in query result.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config).</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. If None, defaults to one specified in client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns. If False data is returned as one column with [x,y,z] array (slower).</p> <code>False</code> <code>post_filter</code> <code>bool</code> <p>Whether to filter down the result based upon the filters specified. If False, it will return the query with present root_ids in the root_id columns, but the rows will reflect the filters translated into their past IDs. So if, for example, a cell had a false merger split off since the last materialization, those annotations on that incorrect portion of the cell will be included if this is False, but will be filtered down if this is True.</p> <code>True</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that table.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>Desired resolution you want all spatial points returned in. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.lookup_supervoxel_ids","title":"<code>lookup_supervoxel_ids(table_name, annotation_ids=None, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookups of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>annotation_ids</code> <code>list</code> <p>List of annotation ids to lookup. Default is None, which will trigger lookup of entire table.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.map_filters","title":"<code>map_filters(filters, timestamp, timestamp_past)</code>","text":"<p>Translate a list of filter dictionaries from a point in the future to a point in the past</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[dict]</code> <p>filter dictionaries with root_ids</p> required <code>timestamp</code> <code>datetime</code> <p>timestamp to query</p> required <code>timestamp_past</code> <code>datetime</code> <p>timestamp to query from</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>filter dictionaries with past root_ids</p> <code>dict</code> <p>mapping of future root_ids to past root_ids</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.most_recent_version","title":"<code>most_recent_version(datastack_name=None)</code>","text":"<p>Get the most recent version of materialization for this datastack name</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Most recent version of materialization for this datastack name</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.query_table","title":"<code>query_table(table, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, timestamp=None, metadata=True, merge_reference=True, desired_resolution=None, get_counts=False, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]], by default None</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings, by default None</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select, by default None</p> <code>None</code> <code>offset</code> <code>int</code> <p>Result offset to use, by default None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config), by default None</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return as a dataframe, by default True. If False, data is returned as json (slower).</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns, by default False. If False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>Version to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query, by default None. If passsed will do a live query. Error if also passing a materialization version</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata (default True), by default True. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table, by default True. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that</p> <code>True</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>Desired resolution you want all spatial points returned in, by default None. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata</p> <code>None</code> <code>get_counts</code> <code>bool</code> <p>Whether to get counts of the query, by default False</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.query_view","title":"<code>query_view(view_name, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, metadata=True, merge_reference=True, desired_resolution=None, get_counts=False, random_sample=None)</code>","text":"<p>Generic query on a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>View to query</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]], by default None</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings, by default None</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select, by default None</p> <code>None</code> <code>offset</code> <code>int</code> <p>Result offset to use, by default None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config), by default None</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return as a dataframe, by default True. If False, data is returned as json (slower).</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns, by default False. If False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>Version to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata (default True), by default True. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table, by default True. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that</p> <code>True</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>Desired resolution you want all spatial points returned in, by default None. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata</p> <code>None</code> <code>get_counts</code> <code>bool</code> <p>Whether to get counts of the query, by default False</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/materialize/#caveclient.materializationengine.MaterializationClientV3.synapse_query","title":"<code>synapse_query(pre_ids=None, post_ids=None, bounding_box=None, bounding_box_column='post_pt_position', timestamp=None, remove_autapses=True, include_zeros=True, limit=None, offset=None, split_positions=False, desired_resolution=None, materialization_version=None, synapse_table=None, datastack_name=None, metadata=True)</code>","text":"<p>Convenience method for querying synapses.</p> <p>Will use the synapse table specified in the info service by default. It will also remove autapses by default. NOTE: This is not designed to allow querying of the entire synapse table. A query with no filters will return only a limited number of rows (configured by the server) and will do so in a non-deterministic fashion. Please contact your dataset administrator if you want access to the entire table.</p> <p>Parameters:</p> Name Type Description Default <code>pre_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Pre-synaptic cell(s) to query.</p> <code>None</code> <code>post_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Post-synaptic cell(s) to query.</p> <code>None</code> <code>bounding_box</code> <code>Optional[Union[list, ndarray]]</code> <p>[[min_x, min_y, min_z],[max_x, max_y, max_z]] bounding box to filter synapse locations. Expressed in units of the voxel_resolution of this dataset.</p> <code>None</code> <code>bounding_box_column</code> <code>str</code> <p>Which synapse location column to filter by.</p> <code>'post_pt_position'</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query. If passed recalculate query at timestamp, do not pass with materialization_version.</p> <code>None</code> <code>remove_autapses</code> <code>bool</code> <p>Whether to remove autapses from query results.</p> <code>True</code> <code>include_zeros</code> <code>bool</code> <p>Whether to include synapses to/from id=0 (out of segmentation).</p> <code>True</code> <code>limit</code> <code>int</code> <p>Number of synapses to limit. Server-side limit still applies.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of synapses to offset query.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>List or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <code>materialization_version</code> <code>int</code> <p>Version to query. If passed, do not pass timestamp. Defaults to <code>self.materialization_version</code> if not specified.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe in the df.attr dictionary.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Results of query.</p>"},{"location":"client_api/schema/","title":"client.schema","text":""},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.get_schemas","title":"<code>get_schemas()</code>","text":"<p>Get the available schema types</p> <p>Returns:</p> Type Description <code>list</code> <p>List of schema types available on the Schema service.</p>"},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition","title":"<code>schema_definition(schema_type)</code>","text":"<p>Get the definition of a specified schema_type</p> <p>Parameters:</p> Name Type Description Default <code>schema_type</code> <code>str</code> <p>Name of a schema_type</p> required <p>Returns:</p> Type Description <code>json</code> <p>Schema definition</p>"},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition_all","title":"<code>schema_definition_all()</code>","text":"<p>Get the definition of all schema_types</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"client_api/schema/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition_multi","title":"<code>schema_definition_multi(schema_types)</code>","text":"<p>Get the definition of multiple schema_types</p> <p>Parameters:</p> Name Type Description Default <code>schema_types</code> <code>list</code> <p>List of schema names</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"client_api/state/","title":"client.state","text":"<p>Note</p> <p>The functionality described here will be accurate if the datastack you are using is using the most up-to-date version of the JSON  state service. If something seems wrong with the documentation here, try checking the version of the JSON state service returned by your client: <pre><code>type(client.state)\n</code></pre> Extended documentation for all versions of the state client can be found here.</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.state_service_endpoint","title":"<code>state_service_endpoint</code>  <code>property</code>","text":"<p>Endpoint URL for posting JSON state</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.build_neuroglancer_url","title":"<code>build_neuroglancer_url(state_id, ngl_url=None, target_site=None, static_url=False, format_propeties=False)</code>","text":"<p>Build a URL for a Neuroglancer deployment that will automatically retrieve specified state. If the datastack is specified, this is prepopulated from the info file field \"viewer_site\". If no ngl_url is specified in either the function or the client, a fallback neuroglancer deployment is used.</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>State id to retrieve</p> required <code>ngl_url</code> <code>str</code> <p>Base url of a neuroglancer deployment. If None, defaults to the value for the datastack or the client. As a fallback, a default deployment is used.</p> <code>None</code> <code>target_site</code> <code>seunglab or cave - explorer or mainline or None</code> <p>Set this to 'seunglab' for a seunglab deployment, or either 'cave-explorer'/'mainline' for a google main branch deployment. If None, checks the info field of the neuroglancer endpoint to determine which to use. Default is None.</p> <code>None</code> <code>static_url</code> <code>bool</code> <p>If True, treats \"state_id\" as a static URL directly to the JSON and does not use the state service.</p> <code>False</code> <code>format_propeties</code> <code>bool</code> <p>If True, formats the url as a segment_properties info file</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The full URL requested</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.get_neuroglancer_info","title":"<code>get_neuroglancer_info(ngl_url=None)</code>","text":"<p>Get the info field from a Neuroglancer deployment</p> <p>Parameters:</p> Name Type Description Default <code>ngl_url</code> <code>str(optional)</code> <p>URL to a Neuroglancer deployment. If None, defaults to the value for the datastack or the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON-formatted info field from the Neuroglancer deployment</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.get_property_json","title":"<code>get_property_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.get_state_json","title":"<code>get_state_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.save_state_json_local","title":"<code>save_state_json_local(json_state, filename, overwrite=False)</code>","text":"<p>Save a Neuroglancer JSON state to a JSON file locally.</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>filename</code> <code>str</code> <p>Filename to save the state to</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the file if it exists. Default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.upload_property_json","title":"<code>upload_property_json(property_json, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>propery_json</code> <code>dict</code> <p>Dict representation of a neuroglancer segment properties json</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"client_api/state/#caveclient.jsonservice.JSONServiceV1.upload_state_json","title":"<code>upload_state_json(json_state, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"extended_api/","title":"Extended API documentation","text":"<p>This page contains extended documentation for the entire CAVEclient API. This includes versions of the API that may not be the latest version, but may still be in use by your particular datastack.</p>"},{"location":"extended_api/annotationengine/","title":"annotationengine","text":""},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2","title":"<code>AnnotationClientV2(server_address, auth_header, api_version, endpoints, server_name, aligned_volume_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, schema_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.create_table","title":"<code>create_table(table_name, schema_name, description, voxel_resolution, reference_table=None, track_target_id_updates=None, flat_segmentation_source=None, user_id=None, aligned_volume_name=None, write_permission='PRIVATE', read_permission='PUBLIC', notice_text=None)</code>","text":"<p>Creates a new data table based on an existing schema</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the new table. Cannot be the same as an existing table</p> required <code>schema_name</code> <code>str</code> <p>Name of the schema for the new table.</p> required <code>description</code> <code>str</code> <p>Human readable description for what is in the table. Should include information about who generated the table What data it covers, and how it should be interpreted. And who should you talk to if you want to use it. An Example: a manual synapse table to detect chandelier synapses on 81 PyC cells with complete AISs [created by Agnes - agnesb@alleninstitute.org, uploaded by Forrest]</p> required <code>voxel_resolution</code> <code>List[float]</code> <p>voxel resolution points will be uploaded in, typically nm, i.e [1,1,1] means nanometers [4,4,40] would be 4nm, 4nm, 40nm voxels</p> required <code>reference_table</code> <code>str</code> <p>If the schema you are using is a reference schema Meaning it is an annotation of another annotation. Then you need to specify what the target table those annotations are in.</p> <code>None</code> <code>track_target_id_updates</code> <code>bool</code> <p>Indicates whether to automatically update reference table's foreign key if target annotation table row is updated.</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>the source to a flat segmentation that corresponds to this table i.e. precomputed:\\gs:\\mybucket      his_tables_annotation</p> <code>None</code> <code>user_id</code> <code>int</code> <p>If you are uploading this schema on someone else's behalf and you want to link this table with their ID, you can specify it here Otherwise, the table will be created with your userID in the user_id column.</p> <code>None</code> <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table (DEFAULT) GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable</p> <code>'PRIVATE'</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data (DEFAULT)</p> <code>'PUBLIC'</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None, no text. If you want to remove text, send empty string.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p> <p>Examples:</p> <p>Basic annotation table:</p> <pre><code>description = \"Some description about the table\"\nvoxel_res = [4,4,40]\nclient.create_table(\"some_synapse_table\", \"synapse\", description, voxel_res)\n</code></pre>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.delete_annotation","title":"<code>delete_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Delete one or more annotations in a table. Annotations that are deleted are recorded as 'non-valid' but are not physically removed from the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>annotation_ids</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.delete_table","title":"<code>delete_table(table_name, aligned_volume_name=None)</code>","text":"<p>Marks a table for deletion requires super admin privileges</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.get_annotation","title":"<code>get_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Retrieve an annotation or annotations by id(s) and table name.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table</p> required <code>annotation_ids</code> <code>int or iterable</code> <p>ID or IDS of the annotation to retreive</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>Annotation data</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.get_annotation_count","title":"<code>get_annotation_count(table_name, aligned_volume_name=None)</code>","text":"<p>Get number of annotations in a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>number of annotations</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.get_table_metadata","title":"<code>get_table_metadata(table_name, aligned_volume_name=None)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>metadata about table</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.get_tables","title":"<code>get_tables(aligned_volume_name=None)</code>","text":"<p>Gets a list of table names for a aligned_volume_name</p> <p>Parameters:</p> Name Type Description Default <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.post_annotation","title":"<code>post_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations refer to 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.post_annotation_df","title":"<code>post_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations see 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.process_position_columns","title":"<code>process_position_columns(df, position_columns)</code>  <code>staticmethod</code>","text":"<p>Process a dataframe into a list of dictionaries</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to process</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>See <code>.post_annotation_df</code></p> required <p>Returns:</p> Type Description <code>dict</code> <p>Annotations ready for posting</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.stage_annotations","title":"<code>stage_annotations(table_name=None, schema_name=None, update=False, id_field=False, table_resolution=None, annotation_resolution=None)</code>","text":"<p>Get a StagedAnnotations object to help produce correctly formatted annotations for a given table or schema. StagedAnnotation objects can be uploaded directly with <code>upload_staged_annotations</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name to stage annotations for, by default None.</p> <code>None</code> <code>schema_name</code> <code>str</code> <p>Schema name to use to make annotations. Only needed if the table_name is not set, by default None</p> <code>None</code> <code>update</code> <code>bool</code> <p>Set to True if individual annotations are going to be updated, by default False.</p> <code>False</code> <code>id_field</code> <code>bool</code> <p>Set to True if id fields are to be specified. Not needed if update is True, which always needs id fields. Optional, by default False</p> <code>False</code> <code>table_resolution</code> <code>list - like or None</code> <p>Voxel resolution of spatial points in the table in nanometers. This is found automatically from the info service if a table name is provided, by default None. If annotation_resolution is also set, this allows points to be scaled correctly for the table.</p> <code>None</code> <code>annotation_resolution</code> <code>list - like</code> <p>Voxel resolution of spatial points provided by the user when creating annotations. If the table resolution is also available (manually or from the info service), annotations are correctly rescaled for the volume. By default, None.</p> <code>None</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.update_annotation","title":"<code>update_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Update one or more new annotations to a table in the AnnotationEngine. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.update_annotation_df","title":"<code>update_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Update one or more annotations to a table in the AnnotationEngine using a dataframe as format. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Iterable[str] or Mapping[str, str] or None</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.update_metadata","title":"<code>update_metadata(table_name, description=None, flat_segmentation_source=None, read_permission=None, write_permission=None, user_id=None, notice_text=None, aligned_volume_name=None)</code>","text":"<p>Update the metadata on an existing table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> required <code>description</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data Defaults to None (will not update).</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable Defaults to None (will not update).</p> <code>None</code> <code>user_id</code> <code>int</code> <p>Note, if you use this you will not be able to update the metadata on this table any longer and depending on permissions may not be able to read or write to it Defaults to None. (will not update)</p> <code>None</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None. (will not update)</p> <code>None</code> <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClientV2.upload_staged_annotations","title":"<code>upload_staged_annotations(staged_annos, aligned_volume_name=None)</code>","text":"<p>Upload annotations directly from an Annotation Guide object. This method uses the options specified in the object, including table name and if the annotation is an update or not.</p> <p>Parameters:</p> Name Type Description Default <code>staged_annos</code> <code>AnnotationGuide</code> <p>AnnotationGuide object with a specified table name and a collection of annotations already filled in.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>List or dict</code> <p>If new annotations are posted, a list of ids. If annotations are being updated, a dictionary with the mapping from old ids to new ids.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.AnnotationClient","title":"<code>AnnotationClient(server_address, dataset_name=None, aligned_volume_name=None, auth_client=None, api_version='latest', verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>Factory for returning AnnotationClient</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>server_address to use to connect to (i.e. https://minniev1.microns-daf.com)</p> required <code>dataset_name</code> <code>str</code> <p>Name of the datastack.</p> <code>None</code> <code>auth_client</code> <code>AuthClient or None</code> <p>Authentication client to use to connect to server. If None, do not use authentication.</p> <code>None</code> <code>api_version</code> <code>str or int (default: latest)</code> <p>What version of the api to use, 0: Legacy client (i.e www.dynamicannotationframework.com) 2: new api version, (i.e. minniev1.microns-daf.com) 'latest': default to the most recent (current 2)</p> <code>'latest'</code> <code>verify</code> <code>str (default : True)</code> <p>whether to verify https</p> <code>True</code> <code>max_retries</code> <code>Int or None</code> <p>Set the number of retries per request, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_block</code> <code>Bool or None</code> <p>If True, restricts pool of threads to max size, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_maxsize</code> <code>Int or None</code> <p>Sets the max number of threads in the pool, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>over_client</code> <p>client to overwrite configuration with</p> <code>None</code> <p>Returns:</p> Type Description <code>ClientBaseWithDatastack</code> <p>List of datastack names for available datastacks on the annotation engine</p>"},{"location":"extended_api/annotationengine/#caveclient.annotationengine.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/auth/","title":"auth","text":""},{"location":"extended_api/auth/#caveclient.auth.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/auth/#caveclient.auth.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/auth/#caveclient.auth.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/base/","title":"base","text":""},{"location":"extended_api/base/#caveclient.base.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/base/#caveclient.base.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/base/#caveclient.base.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/base/#caveclient.base.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/base/#caveclient.base.parametrized","title":"<code>parametrized(dec)</code>","text":"<p>This decorator allows you to easily create decorators that take arguments</p>"},{"location":"extended_api/base/#caveclient.base.patch_session","title":"<code>patch_session(session, max_retries=None, pool_block=None, pool_maxsize=None)</code>","text":"<p>Patch session to configure retry and poolsize options</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>requests session</code> <p>Session to modify</p> required <code>max_retries</code> <code>Int or None</code> <p>Set the number of retries per request, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_block</code> <code>Bool or None</code> <p>If True, restricts pool of threads to max size, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_maxsize</code> <code>Int or None</code> <p>Sets the max number of threads in the pool, by default None. If None, defaults to requests package default.</p> <code>None</code>"},{"location":"extended_api/chunkedgraph/","title":"chunkedgraph","text":"<p>PyChunkedgraph service python interface</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1","title":"<code>ChunkedGraphClientV1(server_address, auth_header, api_version, endpoints, server_key=SERVER_KEY, timestamp=None, table_name=None, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p> <p>ChunkedGraph Client for the v1 API</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.base_resolution","title":"<code>base_resolution</code>  <code>property</code>","text":"<p>MIP 0 resolution for voxels assumed by the ChunkedGraph</p> <p>Returns:</p> Type Description <code>list</code> <p>3-long list of x/y/z voxel dimensions in nm</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.segmentation_info","title":"<code>segmentation_info</code>  <code>property</code>","text":"<p>Complete segmentation metadata</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.do_merge","title":"<code>do_merge(supervoxels, coords, resolution=(4, 4, 40))</code>","text":"<p>Perform a merge on the chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxels</code> <code>iterable</code> <p>An N-long list of supervoxels to merge.</p> required <code>coords</code> <code>array</code> <p>An Nx3 array of coordinates of the supervoxels in units of <code>resolution</code>.</p> required <code>resolution</code> <code>tuple</code> <p>What to multiply <code>coords</code> by to get nanometers. Defaults to (4,4,40).</p> <code>(4, 4, 40)</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.execute_split","title":"<code>execute_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None)</code>","text":"<p>Execute a multicut split based on points or supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>operation_id</code> <code>int</code> <p>Unique ID of the split operation</p> <code>new_root_ids</code> <code>list of int</code> <p>List of new root IDs resulting from the split operation.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.find_path","title":"<code>find_path(root_id, src_pt, dst_pt, precision_mode=False)</code>","text":"<p>Find a path between two locations on a root ID using the level 2 chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>src_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the source point.</p> required <code>dst_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the destination point.</p> required <code>precision_mode</code> <code>bool</code> <p>Whether to perform the search in precision mode. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>centroids_list</code> <code>array</code> <p>Array of centroids along the path.</p> <code>l2_path</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs along the path.</p> <code>failed_l2_ids</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs that failed to find a path.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_change_log","title":"<code>get_change_log(root_id, filtered=True)</code>","text":"<p>Get the change log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query object <code>root_id</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary summarizing split and merge events in the object history, containing the following keys:</p> <ul> <li>\"n_merges\": int<ul> <li>Number of merges</li> </ul> </li> <li>\"n_splits\": int<ul> <li>Number of splits</li> </ul> </li> <li>\"operations_ids\": list of int<ul> <li>Identifiers for each operation</li> </ul> </li> <li>\"past_ids\": list of int<ul> <li>Previous root ids for this object</li> </ul> </li> <li>\"user_info\": dict of dict<ul> <li>Dictionary keyed by user (string) to a dictionary specifying how many   merges and splits that user performed on this object</li> </ul> </li> </ul>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_children","title":"<code>get_children(node_id)</code>","text":"<p>Get the children of a node in the chunked graph hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node ID to query.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>IDs of child nodes.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_contact_sites","title":"<code>get_contact_sites(root_id, bounds, calc_partners=False)</code>","text":"<p>Get contacts for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>Bounds within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code> for which to find contacts. Running this query without bounds is too slow.</p> required <code>calc_partners</code> <code>bool</code> <p>If True, get partner root IDs. By default, False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict relating ids to contacts</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_delta_roots","title":"<code>get_delta_roots(timestamp_past, timestamp_future=datetime.datetime.now(datetime.timezone.utc))</code>","text":"<p>Get the list of roots that have changed between <code>timetamp_past</code> and <code>timestamp_future</code>.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp_past</code> <code>datetime</code> <p>Past timepoint to query</p> required <code>timestamp_future</code> <code>datetime</code> <p>Future timepoint to query. Defaults to <code>datetime.datetime.now(datetime.timezone.utc)</code>.</p> <code>now(utc)</code> <p>Returns:</p> Name Type Description <code>old_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that have expired in that interval.</p> <code>new_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that are new in that interval.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_latest_roots","title":"<code>get_latest_roots(root_id, timestamp=None, timestamp_future=None)</code>","text":"<p>Returns root IDs that are related to the given <code>root_id</code> at a given timestamp. Can be used to find the \"latest\" root IDs associated with an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp</code> <code>datetime or None</code> <p>Timestamp of where to query IDs from. If None then will assume you want till now.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>DEPRECATED name, use <code>timestamp</code> instead. Timestamp to suggest IDs from (note can be in the past relative to the root). By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_leaves","title":"<code>get_leaves(root_id, bounds=None, stop_layer=None)</code>","text":"<p>Get all supervoxels for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>If specified, returns supervoxels within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code>. If None, finds all supervoxels.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>If specified, returns chunkedgraph nodes at layer <code>stop_layer</code> default will be <code>stop_layer=1</code> (supervoxels).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Array of supervoxel IDs (or node ids if <code>stop_layer&gt;1</code>).</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_lineage_graph","title":"<code>get_lineage_graph(root_id, timestamp_past=None, timestamp_future=None, as_nx_graph=False, exclude_links_to_future=False, exclude_links_to_past=False)</code>","text":"<p>Returns the lineage graph for a root ID, optionally cut off in the past or the future.</p> <p>Each change in the chunked graph creates a new root ID for the object after that change. This function returns a graph of all root IDs for a given object, tracing the history of the object in terms of merges and splits.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the lineage graph backwards in time. By default, None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Cutoff for the lineage graph going forwards in time. By default, None.</p> <code>None</code> <code>as_nx_graph</code> <p>If True, a NetworkX graph is returned.</p> <code>False</code> <code>exclude_links_to_future</code> <p>If True, links from nodes before <code>timestamp_future</code> to after <code>timestamp_future</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <code>exclude_links_to_past</code> <p>If True, links from nodes before <code>timestamp_past</code> to after <code>timestamp_past</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary describing the lineage graph and operations for the root ID. Not returned if <code>as_nx_graph</code> is True. The dictionary contains the following keys:</p> <ul> <li>\"directed\" : bool<ul> <li>Whether the graph is directed.</li> </ul> </li> <li>\"graph\" : dict<ul> <li>Dictionary of graph attributes.</li> </ul> </li> <li>\"links\" : list of dict<ul> <li>Each element of the list is a dictionary describing an edge in the lineage graph as \"source\" and \"target\" keys.</li> </ul> </li> <li>\"multigraph\" : bool<ul> <li>Whether the graph is a multigraph.</li> </ul> </li> <li>\"nodes\" : list of dict<ul> <li>Each element of the list is a dictionary describing a node in the lineage graph, usually with \"id\", \"timestamp\", and \"operation_id\" keys.</li> </ul> </li> </ul> <code>DiGraph</code> <p>NetworkX directed graph of the lineage graph. Only returned if <code>as_nx_graph</code> is True.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_merge_log","title":"<code>get_merge_log(root_id)</code>","text":"<p>Get the merge log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of merge events in the history of the object.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_oldest_timestamp","title":"<code>get_oldest_timestamp()</code>","text":"<p>Get the oldest timestamp in the database.</p> <p>Returns:</p> Type Description <code>datetime</code> <p>Oldest timestamp in the database.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_operation_details","title":"<code>get_operation_details(operation_ids)</code>","text":"<p>Get the details of a list of operations.</p> <p>Parameters:</p> Name Type Description Default <code>operation_ids</code> <code>Iterable[int]</code> <p>List/array of operation IDs.</p> required <p>Returns:</p> Type Description <code>dict of str to dict</code> <p>A dict of dicts of operation info, keys are operation IDs (as strings), values are a dictionary of operation info for the operation. These dictionaries contain the following keys:</p> <ul> <li>\"added_edges\"/\"removed_edges\": list of list of int<ul> <li>List of edges added (if a merge) or removed (if a split) by this operation. Each edge is a list of two supervoxel IDs (source and target).</li> </ul> </li> <li>\"roots\": list of int<ul> <li>List of root IDs that were created by this operation.</li> </ul> </li> <li>\"sink_coords\": list of list of int<ul> <li>List of sink coordinates for this operation. The sink is one of the points placed by the user when specifying the operation. Each sink coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"source_coords\": list of list of int<ul> <li>List of source coordinates for this operation. The source is one of the points placed by the user when specifying the operation. Each source coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"timestamp\": str<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user\": str<ul> <li>User ID number who performed the operation (as a string).</li> </ul> </li> </ul>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_original_roots","title":"<code>get_original_roots(root_id, timestamp_past=None)</code>","text":"<p>Returns root IDs that are the latest successors of a given root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the search going backwards in time. By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_past_ids","title":"<code>get_past_ids(root_ids, timestamp_past=None, timestamp_future=None)</code>","text":"<p>For a set of root IDs, get the list of IDs at a past or future time point that could contain parts of the same object.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>Iterable of int</code> <p>Iterable of root IDs to query.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Time of a point in the past for which to look up root ids. Default is None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Time of a point in the future for which to look up root ids. Not implemented on the server currently. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict with keys \"future_id_map\" and \"past_id_map\". Each is a dict whose keys are the supplied <code>root_ids</code> and whose values are the list of related root IDs at <code>timestamp_past</code>/<code>timestamp_future</code>.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_root_id","title":"<code>get_root_id(supervoxel_id, timestamp=None, level2=False)</code>","text":"<p>Get the root ID for a specified supervoxel.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_id</code> <code>int</code> <p>Supervoxel id value</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <p>Returns:</p> Type Description <code>int64</code> <p>Root ID containing the supervoxel.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_root_timestamps","title":"<code>get_root_timestamps(root_ids)</code>","text":"<p>Retrieves timestamps when roots where created.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <p>Iterable of root IDs to query.</p> required <p>Returns:</p> Type Description <code>np.array of datetime.datetime</code> <p>Array of timestamps when <code>root_ids</code> were created.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_roots","title":"<code>get_roots(supervoxel_ids, timestamp=None, stop_layer=None)</code>","text":"<p>Get the root ID for a list of supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_ids</code> <code>list or np.array of int</code> <p>Supervoxel IDs to look up.</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <code>stop_layer</code> <code>int or None</code> <p>If True, looks up IDs only up to a given stop layer. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.uint64</code> <p>Root IDs containing each supervoxel.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_subgraph","title":"<code>get_subgraph(root_id, bounds)</code>","text":"<p>Get subgraph of root id within a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root (or any node ID) of chunked graph to query.</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Node IDs in the subgraph.</p> <code>np.array of np.double</code> <p>Affinities of edges in the subgraph.</p> <code>np.array of np.int32</code> <p>Areas of nodes in the subgraph.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_tabular_change_log","title":"<code>get_tabular_change_log(root_ids, filtered=True)</code>","text":"<p>Get a detailed changelog for neurons.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>list of int</code> <p>Object root IDs to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query objects in <code>root_ids</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict of pd.DataFrame</code> <p>The keys are the root IDs, and the values are DataFrames with the following columns and datatypes:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": int<ul> <li>Timestamp of the operation, provided in milliseconds. To convert to datetime, use <code>datetime.datetime.utcfromtimestamp(timestamp/1000)</code>.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> <li>\"before_root_ids: list of int<ul> <li>Root IDs of objects that existed before the operation.</li> </ul> </li> <li>\"after_root_ids: list of int<ul> <li>Root IDs of objects created by the operation. Note that this only records the root id that was kept as part of the query object, so there will only be one in this list.</li> </ul> </li> <li>\"is_merge\": bool<ul> <li>Whether the operation was a merge.</li> </ul> </li> <li>\"user_name\": str<ul> <li>Name of the user who performed the operation.</li> </ul> </li> <li>\"user_affiliation\": str<ul> <li>Affiliation of the user who performed the operation.</li> </ul> </li> </ul>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.get_user_operations","title":"<code>get_user_operations(user_id, timestamp_start, include_undo=True, timestamp_end=None)</code>","text":"<p>Get operation details for a user ID. Currently, this is only available to admins.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>User ID to query (use 0 for all users (admin only)).</p> required <code>timestamp_start</code> <code>datetime</code> <p>Timestamp to start filter (UTC).</p> required <code>include_undo</code> <code>bool</code> <p>Whether to include undos. Defaults to True.</p> <code>True</code> <code>timestamp_end</code> <code>datetime</code> <p>Timestamp to end filter (UTC). Defaults to now.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame including the following columns:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": datetime.datetime<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> </ul>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.is_latest_roots","title":"<code>is_latest_roots(root_ids, timestamp=None)</code>","text":"<p>Check whether these root IDs are still a root at this timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>array-like of int</code> <p>Root IDs to check.</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs are valid root IDs in the chunked graph. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid root IDs.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.is_valid_nodes","title":"<code>is_valid_nodes(node_ids, start_timestamp=None, end_timestamp=None)</code>","text":"<p>Check whether nodes are valid for given timestamp range.</p> <p>Valid is defined as existing in the chunked graph. This makes no statement about these IDs being roots, supervoxel or anything in-between. It also does not take into account whether a root ID has since been edited.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>array-like of int</code> <p>Node IDs to check.</p> required <code>start_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid after this timestamp. Defaults to None (assumes now).</p> <code>None</code> <code>end_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid before this timestamp. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid IDs.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.level2_chunk_graph","title":"<code>level2_chunk_graph(root_id, bounds=None)</code>","text":"<p>Get graph of level 2 chunks, the smallest agglomeration level above supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root id of object</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates (use <code>client.chunkedgraph.base_resolution</code> to view this default resolution for your chunkedgraph client). Note that the result will include any level 2 nodes which have chunk boundaries within some part of this bounding box, meaning that the representative point for a given level 2 node could still be slightly outside of these bounds. If None, returns all level 2 chunks for the root ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>list of list</code> <p>Edge list for level 2 chunked graph. Each element of the list is an edge, and each edge is a list of two node IDs (source and target).</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.preview_split","title":"<code>preview_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None, return_additional_ccs=False)</code>","text":"<p>Get supervoxel connected components from a preview multicut split.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>return_additional_ccs</code> <code>bool</code> <p>If True, returns any additional connected components beyond the ones with source and sink points. In most situations, this can be ignored. By default, False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>source_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most source points.</p> <code>sink_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most sink points.</p> <code>successful_split</code> <code>bool</code> <p>True if the split worked.</p> <code>other_connected_components (optional) : list of lists of int</code> <p>List of lists of supervoxel IDs for any other resulting connected components. Only returned if <code>return_additional_ccs</code> is True.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.remesh_level2_chunks","title":"<code>remesh_level2_chunks(chunk_ids)</code>","text":"<p>Submit specific level 2 chunks to be remeshed in case of a problem.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_ids</code> <code>list</code> <p>List of level 2 chunk IDs.</p> required"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.suggest_latest_roots","title":"<code>suggest_latest_roots(root_id, timestamp=None, stop_layer=None, return_all=False, return_fraction_overlap=False)</code>","text":"<p>Suggest latest roots for a given root id, based on overlap of component chunk IDs. Note that edits change chunk IDs, and so this effectively measures the fraction of unchanged chunks at a given chunk layer, which sets the size scale of chunks. Higher layers are coarser.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID of the potentially outdated object.</p> required <code>timestamp</code> <code>datetime</code> <p>Datetime at which \"latest\" roots are being computed, by default None. If None, the current time is used. Note that this has to be a timestamp after the creation of the <code>root_id</code>.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>Chunk level at which to compute overlap, by default None. No value will take the 4th from the top layer, which emphasizes speed and works well for larger objects. Lower values are slower but more fine-grained. Values under 2 (i.e. supervoxels) are not recommended except in extremely fine grained scenarios.</p> <code>None</code> <code>return_all</code> <code>bool</code> <p>If True, return all current IDs sorted from most overlap to least, by default False. If False, only the top is returned.</p> <code>False</code> <code>return_fraction_overlap</code> <code>bool</code> <p>If True, return all fractions sorted by most overlap to least, by default False. If False, only the top value is returned.</p> <code>False</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ChunkedGraphClientV1.undo_operation","title":"<code>undo_operation(operation_id)</code>","text":"<p>Undo an operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation_id</code> <code>int</code> <p>Operation ID to undo.</p> required <p>Returns:</p> Type Description <code>dict</code>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/chunkedgraph/#caveclient.chunkedgraph.package_split_data","title":"<code>package_split_data(root_id, source_points, sink_points, source_supervoxels, sink_supervoxels)</code>","text":"<p>Create the data for preview or executed split operations</p>"},{"location":"extended_api/datastack_lookup/","title":"datastack_lookup","text":""},{"location":"extended_api/datastack_lookup/#caveclient.datastack_lookup.reset_server_address_cache","title":"<code>reset_server_address_cache(datastack, filename=None)</code>","text":"<p>Remove one or more datastacks from the datastack-to-server cache.</p> <p>Parameters:</p> Name Type Description Default <code>datastack</code> <code>str or list of str</code> <p>Datastack names to remove from the cache, by default None</p> required <code>filename</code> <code>str</code> <p>Name of the cache file, by default None</p> <code>None</code>"},{"location":"extended_api/emannotationschemas/","title":"emannotationschemas","text":""},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy","title":"<code>SchemaClientLegacy(server_address, auth_header, api_version, endpoints, server_name, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.get_schemas","title":"<code>get_schemas()</code>","text":"<p>Get the available schema types</p> <p>Returns:</p> Type Description <code>list</code> <p>List of schema types available on the Schema service.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition","title":"<code>schema_definition(schema_type)</code>","text":"<p>Get the definition of a specified schema_type</p> <p>Parameters:</p> Name Type Description Default <code>schema_type</code> <code>str</code> <p>Name of a schema_type</p> required <p>Returns:</p> Type Description <code>json</code> <p>Schema definition</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition_all","title":"<code>schema_definition_all()</code>","text":"<p>Get the definition of all schema_types</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.SchemaClientLegacy.schema_definition_multi","title":"<code>schema_definition_multi(schema_types)</code>","text":"<p>Get the definition of multiple schema_types</p> <p>Parameters:</p> Name Type Description Default <code>schema_types</code> <code>list</code> <p>List of schema names</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"extended_api/emannotationschemas/#caveclient.emannotationschemas.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/framework/","title":"framework","text":""},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2","title":"<code>AnnotationClientV2(server_address, auth_header, api_version, endpoints, server_name, aligned_volume_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, schema_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.create_table","title":"<code>create_table(table_name, schema_name, description, voxel_resolution, reference_table=None, track_target_id_updates=None, flat_segmentation_source=None, user_id=None, aligned_volume_name=None, write_permission='PRIVATE', read_permission='PUBLIC', notice_text=None)</code>","text":"<p>Creates a new data table based on an existing schema</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the new table. Cannot be the same as an existing table</p> required <code>schema_name</code> <code>str</code> <p>Name of the schema for the new table.</p> required <code>description</code> <code>str</code> <p>Human readable description for what is in the table. Should include information about who generated the table What data it covers, and how it should be interpreted. And who should you talk to if you want to use it. An Example: a manual synapse table to detect chandelier synapses on 81 PyC cells with complete AISs [created by Agnes - agnesb@alleninstitute.org, uploaded by Forrest]</p> required <code>voxel_resolution</code> <code>List[float]</code> <p>voxel resolution points will be uploaded in, typically nm, i.e [1,1,1] means nanometers [4,4,40] would be 4nm, 4nm, 40nm voxels</p> required <code>reference_table</code> <code>str</code> <p>If the schema you are using is a reference schema Meaning it is an annotation of another annotation. Then you need to specify what the target table those annotations are in.</p> <code>None</code> <code>track_target_id_updates</code> <code>bool</code> <p>Indicates whether to automatically update reference table's foreign key if target annotation table row is updated.</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>the source to a flat segmentation that corresponds to this table i.e. precomputed:\\gs:\\mybucket      his_tables_annotation</p> <code>None</code> <code>user_id</code> <code>int</code> <p>If you are uploading this schema on someone else's behalf and you want to link this table with their ID, you can specify it here Otherwise, the table will be created with your userID in the user_id column.</p> <code>None</code> <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table (DEFAULT) GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable</p> <code>'PRIVATE'</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data (DEFAULT)</p> <code>'PUBLIC'</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None, no text. If you want to remove text, send empty string.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p> <p>Examples:</p> <p>Basic annotation table:</p> <pre><code>description = \"Some description about the table\"\nvoxel_res = [4,4,40]\nclient.create_table(\"some_synapse_table\", \"synapse\", description, voxel_res)\n</code></pre>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.delete_annotation","title":"<code>delete_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Delete one or more annotations in a table. Annotations that are deleted are recorded as 'non-valid' but are not physically removed from the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>annotation_ids</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.delete_table","title":"<code>delete_table(table_name, aligned_volume_name=None)</code>","text":"<p>Marks a table for deletion requires super admin privileges</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.get_annotation","title":"<code>get_annotation(table_name, annotation_ids, aligned_volume_name=None)</code>","text":"<p>Retrieve an annotation or annotations by id(s) and table name.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table</p> required <code>annotation_ids</code> <code>int or iterable</code> <p>ID or IDS of the annotation to retreive</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>Annotation data</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.get_annotation_count","title":"<code>get_annotation_count(table_name, aligned_volume_name=None)</code>","text":"<p>Get number of annotations in a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>number of annotations</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.get_table_metadata","title":"<code>get_table_metadata(table_name, aligned_volume_name=None)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>aligned_volume_name</code> <code>str</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>metadata about table</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.get_tables","title":"<code>get_tables(aligned_volume_name=None)</code>","text":"<p>Gets a list of table names for a aligned_volume_name</p> <p>Parameters:</p> Name Type Description Default <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.post_annotation","title":"<code>post_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations refer to 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.post_annotation_df","title":"<code>post_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Post one or more new annotations to a table in the AnnotationEngine. All inserted annotations will be marked as 'valid'. To invalidate annotations see 'update_annotation', 'update_annotation_df' and 'delete_annotation' methods.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.process_position_columns","title":"<code>process_position_columns(df, position_columns)</code>  <code>staticmethod</code>","text":"<p>Process a dataframe into a list of dictionaries</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to process</p> required <code>position_columns</code> <code>Optional[Union[Iterable[str], Mapping[str, str]]]</code> <p>See <code>.post_annotation_df</code></p> required <p>Returns:</p> Type Description <code>dict</code> <p>Annotations ready for posting</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.stage_annotations","title":"<code>stage_annotations(table_name=None, schema_name=None, update=False, id_field=False, table_resolution=None, annotation_resolution=None)</code>","text":"<p>Get a StagedAnnotations object to help produce correctly formatted annotations for a given table or schema. StagedAnnotation objects can be uploaded directly with <code>upload_staged_annotations</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name to stage annotations for, by default None.</p> <code>None</code> <code>schema_name</code> <code>str</code> <p>Schema name to use to make annotations. Only needed if the table_name is not set, by default None</p> <code>None</code> <code>update</code> <code>bool</code> <p>Set to True if individual annotations are going to be updated, by default False.</p> <code>False</code> <code>id_field</code> <code>bool</code> <p>Set to True if id fields are to be specified. Not needed if update is True, which always needs id fields. Optional, by default False</p> <code>False</code> <code>table_resolution</code> <code>list - like or None</code> <p>Voxel resolution of spatial points in the table in nanometers. This is found automatically from the info service if a table name is provided, by default None. If annotation_resolution is also set, this allows points to be scaled correctly for the table.</p> <code>None</code> <code>annotation_resolution</code> <code>list - like</code> <p>Voxel resolution of spatial points provided by the user when creating annotations. If the table resolution is also available (manually or from the info service), annotations are correctly rescaled for the volume. By default, None.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.update_annotation","title":"<code>update_annotation(table_name, data, aligned_volume_name=None)</code>","text":"<p>Update one or more new annotations to a table in the AnnotationEngine. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>data</code> <code>(dict or list)</code> <p>A list of (or a single) dict of schematized annotation data matching the target table. each dict must contain an \"id\" field which is the ID of the annotation to update</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON: a list of new annotation IDs.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.update_annotation_df","title":"<code>update_annotation_df(table_name, df, position_columns, aligned_volume_name=None)</code>","text":"<p>Update one or more annotations to a table in the AnnotationEngine using a dataframe as format. Updating is implemented by invalidating the old annotation and inserting a new annotation row, which will receive a new primary key ID.</p> Notes <p>If annotations ids were user provided upon insertion the database will autoincrement from the current max id in the table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table where annotations will be added</p> required <code>df</code> <code>DataFrame</code> <p>A pandas dataframe containing the annotations. Columns should be fields in schema, position columns need to be called out in position_columns argument.</p> required <code>position_columns</code> <code>Iterable[str] or Mapping[str, str] or None</code> <p>if None, will look for all columns with 'X_position' in the name and assume they go in fields called \"X\". if Iterable assumes each column given ends in _position. (i.e. ['pt_position'] if 'pt' is the name of the position field in schema) if Mapping, keys are names of columns in dataframe, values are the names of the fields (i.e. {'pt_column': 'pt'} would be correct if you had one column named 'pt_column' which needed to go into a schema with a position column called 'pt')</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>json</code> <p>Response JSON</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.update_metadata","title":"<code>update_metadata(table_name, description=None, flat_segmentation_source=None, read_permission=None, write_permission=None, user_id=None, notice_text=None, aligned_volume_name=None)</code>","text":"<p>Update the metadata on an existing table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> required <code>description</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>flat_segmentation_source</code> <code>str</code> <p>Defaults to None (will not update).</p> <code>None</code> <code>read_permission</code> <code>str</code> <p>What permissions to give the table for reading. One of PRIVATE: only you can read this table. Intended to be used for sorting out bugs. GROUP: only members that share a group with you can read (intended for within group vetting) PUBLIC: anyone with permissions to read this datastack can read this data Defaults to None (will not update).</p> <code>None</code> <code>write_permission</code> <code>str</code> <p>What permissions to give the table for writing.  One of PRIVATE: only you can write to this table GROUP: only members that share a group with you can write (excluding some groups) PUBLIC: Anyone can write to this table. Note all data is logged, and deletes are done by marking rows as deleted, so all data is always recoverable Defaults to None (will not update).</p> <code>None</code> <code>user_id</code> <code>int</code> <p>Note, if you use this you will not be able to update the metadata on this table any longer and depending on permissions may not be able to read or write to it Defaults to None. (will not update)</p> <code>None</code> <code>notice_text</code> <code>str</code> <p>Text the user will see when querying this table. Can be used to warn users of flaws, and uncertainty in the data, or to advertise citations that should be used with this table. Defaults to None. (will not update)</p> <code>None</code> <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClientV2.upload_staged_annotations","title":"<code>upload_staged_annotations(staged_annos, aligned_volume_name=None)</code>","text":"<p>Upload annotations directly from an Annotation Guide object. This method uses the options specified in the object, including table name and if the annotation is an update or not.</p> <p>Parameters:</p> Name Type Description Default <code>staged_annos</code> <code>AnnotationGuide</code> <p>AnnotationGuide object with a specified table name and a collection of annotations already filled in.</p> required <code>aligned_volume_name</code> <code>str or None</code> <p>Name of the aligned_volume. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>List or dict</code> <p>If new annotations are posted, a list of ids. If annotations are being updated, a dictionary with the mapping from old ids to new ids.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclient","title":"<code>CAVEclient</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull","title":"<code>CAVEclientFull(datastack_name=None, server_address=None, auth_token_file=default_token_file, auth_token_key='token', auth_token=None, max_retries=DEFAULT_RETRIES, pool_maxsize=None, pool_block=None, desired_resolution=None, info_cache=None)</code>","text":"<p>               Bases: <code>CAVEclientGlobal</code></p> <p>A manager for all clients sharing common datastack and authentication information.</p> <p>This client wraps all the other clients and keeps track of the things that need to be consistent across them. To instantiate a client:</p> <pre><code>client = CAVEclient(datastack_name='my_datastack',\n                         server_address='www.myserver.com',\n                         auth_token_file='~/.mysecrets/secrets.json')\n</code></pre> <p>Then</p> <ul> <li><code>client.annotation</code> is an <code>AnnotationClient</code> (see client.annotation)</li> <li><code>client.auth</code> is an <code>AuthClient</code> (see client.auth)</li> <li><code>client.chunkedgraph</code> is a <code>ChunkedGraphClient</code> (see client.chunkedgraph)</li> <li><code>client.info</code> is an <code>InfoServiceClient</code> (see client.info)</li> <li><code>client.l2cache</code> is an <code>L2CacheClient</code> (see client.l2cache)</li> <li><code>client.materialize</code> is a <code>MaterializationClient</code> (see client.materialize)</li> <li><code>client.schema</code> is a <code>SchemaClient</code> (see client.schema)</li> <li><code>client.state</code> is a neuroglancer <code>JSONService</code> (see client.state)</li> </ul> <p>All subclients are loaded lazily and share the same datastack name, server address, and auth tokens where used.</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>Datastack name for the services. Almost all services need this and will not work if it is not passed.</p> <code>None</code> <code>server_address</code> <code>str or None</code> <p>URL of the framework server. If None, chooses the default server global.daf-apis.com. Optional, defaults to None.</p> <code>None</code> <code>auth_token_file</code> <code>str or None</code> <p>Path to a json file containing the auth token. If None, uses the default location. See Auth client documentation. Optional, defaults to None.</p> <code>default_token_file</code> <code>auth_token_key</code> <code>str</code> <p>Dictionary key for the token in the the JSON file. Optional, default is 'token'.</p> <code>'token'</code> <code>auth_token</code> <code>str or None</code> <p>Direct entry of an auth token. If None, uses the file arguments to find the token. Optional, default is None.</p> <code>None</code> <code>max_retries</code> <code>int or None</code> <p>Sets the default number of retries on failed requests. Optional, by default 2.</p> <code>DEFAULT_RETRIES</code> <code>pool_maxsize</code> <code>int or None</code> <p>Sets the max number of threads in a requests pool, although this value will be exceeded if pool_block is set to False. Optional, uses requests defaults if None.</p> <code>None</code> <code>pool_block</code> <p>If True, prevents the number of threads in a requests pool from exceeding the max size. Optional, uses requests defaults (False) if None.</p> <code>None</code> <code>desired_resolution</code> <code>Iterable[float] or None</code> <p>If given, should be a list or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <code>info_cache</code> <p>Pre-computed info cache, bypassing the lookup of datastack info from the info service. Should only be used in cases where this information is cached and thus repetitive lookups can be avoided.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.annotation","title":"<code>annotation: AnnotationClientV2</code>  <code>property</code>","text":"<p>A client for the annotation service. See client.annotation for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.auth","title":"<code>auth: AuthClient</code>  <code>property</code>","text":"<p>A client for the auth service. See client.auth for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.chunkedgraph","title":"<code>chunkedgraph: ChunkedGraphClientV1</code>  <code>property</code>","text":"<p>A client for the chunkedgraph service. See client.chunkedgraph for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.datastack_name","title":"<code>datastack_name: str</code>  <code>property</code>","text":"<p>The name of the datastack for the client.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.info","title":"<code>info: InfoServiceClientV2</code>  <code>property</code>","text":"<p>A client for the info service. See client.info for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.l2cache","title":"<code>l2cache: L2CacheClientLegacy</code>  <code>property</code>","text":"<p>A client for the L2 cache service. See client.l2cache for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.materialize","title":"<code>materialize: MaterializationClientType</code>  <code>property</code>","text":"<p>A client for the materialization service. See client.materialize for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.schema","title":"<code>schema: SchemaClientLegacy</code>  <code>property</code>","text":"<p>A client for the EM Annotation Schemas service. See client.schema for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.server_address","title":"<code>server_address</code>  <code>property</code>","text":"<p>The server address for the client.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.state","title":"<code>state: JSONServiceV1</code>  <code>property</code>","text":"<p>A client for the neuroglancer state service. See client.state for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientFull.change_auth","title":"<code>change_auth(auth_token_file=None, auth_token_key=None, auth_token=None)</code>","text":"<p>Change the authentication token and reset services.</p> <p>Parameters:</p> Name Type Description Default <code>auth_token_file</code> <code>str</code> <p>New auth token json file path, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token_key</code> <code>str</code> <p>New dictionary key under which the token is stored in the json file, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token</code> <code>str</code> <p>Direct entry of a new token, by default None.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal","title":"<code>CAVEclientGlobal(server_address=None, auth_token_file=None, auth_token_key=None, auth_token=None, max_retries=DEFAULT_RETRIES, pool_maxsize=None, pool_block=None, info_cache=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>A manager for all clients sharing common datastack and authentication information.</p> <p>This client wraps all the other clients and keeps track of the things that need to be consistent across them. To instantiate a client:</p> <pre><code>client = CAVEclient(datastack_name='my_datastack',\n                         server_address='www.myserver.com',\n                         auth_token_file='~/.mysecrets/secrets.json')\n</code></pre> <p>Then:</p> <ul> <li><code>client.auth</code> is an <code>AuthClient</code> (see client.auth)</li> <li><code>client.info</code> is an <code>InfoServiceClient</code> (see client.info)</li> <li><code>client.schema</code> is a <code>SchemaClient</code> (see client.schema)</li> <li><code>client.state</code> is a neuroglancer <code>JSONService</code> (see client.state)</li> </ul> <p>All subclients are loaded lazily and share the same datastack name, server address, and auth tokens (where used).</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str or None</code> <p>URL of the framework server. If None, chooses the default server global.daf-apis.com. Optional, defaults to None.</p> <code>None</code> <code>auth_token_file</code> <code>str or None</code> <p>Path to a json file containing the auth token. If None, uses the default location. See Auth client documentation. Optional, defaults to None.</p> <code>None</code> <code>auth_token_key</code> <code>str</code> <p>Dictionary key for the token in the the JSON file. Optional, default is 'token'.</p> <code>None</code> <code>auth_token</code> <code>str or None</code> <p>Direct entry of an auth token. If None, uses the file arguments to find the token. Optional, default is None.</p> <code>None</code> <code>max_retries</code> <code>int or None</code> <p>Sets the default number of retries on failed requests. Optional, by default 2.</p> <code>DEFAULT_RETRIES</code> <code>pool_maxsize</code> <code>int or None</code> <p>Sets the max number of threads in a requests pool, although this value will be exceeded if pool_block is set to False. Optional, uses requests defaults if None.</p> <code>None</code> <code>pool_block</code> <p>If True, prevents the number of threads in a requests pool from exceeding the max size. Optional, uses requests defaults (False) if None.</p> <code>None</code> <code>info_cache</code> <p>Pre-computed info cache, bypassing the lookup of datastack info from the info service. Should only be used in cases where this information is cached and thus repetitive lookups can be avoided.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.auth","title":"<code>auth: AuthClient</code>  <code>property</code>","text":"<p>A client for the auth service. See client.auth for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.info","title":"<code>info: InfoServiceClientV2</code>  <code>property</code>","text":"<p>A client for the info service. See client.info for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.schema","title":"<code>schema: SchemaClientLegacy</code>  <code>property</code>","text":"<p>A client for the EM Annotation Schemas service. See client.schema for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.server_address","title":"<code>server_address</code>  <code>property</code>","text":"<p>The server address for the client.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.state","title":"<code>state: JSONServiceV1</code>  <code>property</code>","text":"<p>A client for the neuroglancer state service. See client.state for more information.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.CAVEclientGlobal.change_auth","title":"<code>change_auth(auth_token_file=None, auth_token_key=None, auth_token=None)</code>","text":"<p>Change the authentication token and reset services.</p> <p>Parameters:</p> Name Type Description Default <code>auth_token_file</code> <code>str</code> <p>New auth token json file path, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token_key</code> <code>str</code> <p>New dictionary key under which the token is stored in the json file, by default None, which defaults to the existing state.</p> <code>None</code> <code>auth_token</code> <code>str</code> <p>Direct entry of a new token, by default None.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1","title":"<code>ChunkedGraphClientV1(server_address, auth_header, api_version, endpoints, server_key=SERVER_KEY, timestamp=None, table_name=None, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p> <p>ChunkedGraph Client for the v1 API</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.base_resolution","title":"<code>base_resolution</code>  <code>property</code>","text":"<p>MIP 0 resolution for voxels assumed by the ChunkedGraph</p> <p>Returns:</p> Type Description <code>list</code> <p>3-long list of x/y/z voxel dimensions in nm</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.segmentation_info","title":"<code>segmentation_info</code>  <code>property</code>","text":"<p>Complete segmentation metadata</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.do_merge","title":"<code>do_merge(supervoxels, coords, resolution=(4, 4, 40))</code>","text":"<p>Perform a merge on the chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxels</code> <code>iterable</code> <p>An N-long list of supervoxels to merge.</p> required <code>coords</code> <code>array</code> <p>An Nx3 array of coordinates of the supervoxels in units of <code>resolution</code>.</p> required <code>resolution</code> <code>tuple</code> <p>What to multiply <code>coords</code> by to get nanometers. Defaults to (4,4,40).</p> <code>(4, 4, 40)</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.execute_split","title":"<code>execute_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None)</code>","text":"<p>Execute a multicut split based on points or supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>operation_id</code> <code>int</code> <p>Unique ID of the split operation</p> <code>new_root_ids</code> <code>list of int</code> <p>List of new root IDs resulting from the split operation.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.find_path","title":"<code>find_path(root_id, src_pt, dst_pt, precision_mode=False)</code>","text":"<p>Find a path between two locations on a root ID using the level 2 chunked graph.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>src_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the source point.</p> required <code>dst_pt</code> <code>array</code> <p>3-element array of xyz coordinates in nm for the destination point.</p> required <code>precision_mode</code> <code>bool</code> <p>Whether to perform the search in precision mode. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>centroids_list</code> <code>array</code> <p>Array of centroids along the path.</p> <code>l2_path</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs along the path.</p> <code>failed_l2_ids</code> <code>np.array of int</code> <p>Array of level 2 chunk IDs that failed to find a path.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_change_log","title":"<code>get_change_log(root_id, filtered=True)</code>","text":"<p>Get the change log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query object <code>root_id</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary summarizing split and merge events in the object history, containing the following keys:</p> <ul> <li>\"n_merges\": int<ul> <li>Number of merges</li> </ul> </li> <li>\"n_splits\": int<ul> <li>Number of splits</li> </ul> </li> <li>\"operations_ids\": list of int<ul> <li>Identifiers for each operation</li> </ul> </li> <li>\"past_ids\": list of int<ul> <li>Previous root ids for this object</li> </ul> </li> <li>\"user_info\": dict of dict<ul> <li>Dictionary keyed by user (string) to a dictionary specifying how many   merges and splits that user performed on this object</li> </ul> </li> </ul>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_children","title":"<code>get_children(node_id)</code>","text":"<p>Get the children of a node in the chunked graph hierarchy.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>Node ID to query.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>IDs of child nodes.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_contact_sites","title":"<code>get_contact_sites(root_id, bounds, calc_partners=False)</code>","text":"<p>Get contacts for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>Bounds within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code> for which to find contacts. Running this query without bounds is too slow.</p> required <code>calc_partners</code> <code>bool</code> <p>If True, get partner root IDs. By default, False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict relating ids to contacts</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_delta_roots","title":"<code>get_delta_roots(timestamp_past, timestamp_future=datetime.datetime.now(datetime.timezone.utc))</code>","text":"<p>Get the list of roots that have changed between <code>timetamp_past</code> and <code>timestamp_future</code>.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp_past</code> <code>datetime</code> <p>Past timepoint to query</p> required <code>timestamp_future</code> <code>datetime</code> <p>Future timepoint to query. Defaults to <code>datetime.datetime.now(datetime.timezone.utc)</code>.</p> <code>now(utc)</code> <p>Returns:</p> Name Type Description <code>old_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that have expired in that interval.</p> <code>new_roots</code> <code>np.ndarray of np.int64</code> <p>Roots that are new in that interval.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_latest_roots","title":"<code>get_latest_roots(root_id, timestamp=None, timestamp_future=None)</code>","text":"<p>Returns root IDs that are related to the given <code>root_id</code> at a given timestamp. Can be used to find the \"latest\" root IDs associated with an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp</code> <code>datetime or None</code> <p>Timestamp of where to query IDs from. If None then will assume you want till now.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>DEPRECATED name, use <code>timestamp</code> instead. Timestamp to suggest IDs from (note can be in the past relative to the root). By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_leaves","title":"<code>get_leaves(root_id, bounds=None, stop_layer=None)</code>","text":"<p>Get all supervoxels for a root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID to query.</p> required <code>bounds</code> <p>If specified, returns supervoxels within a 3x2 numpy array of bounds <code>[[minx,maxx],[miny,maxy],[minz,maxz]]</code>. If None, finds all supervoxels.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>If specified, returns chunkedgraph nodes at layer <code>stop_layer</code> default will be <code>stop_layer=1</code> (supervoxels).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Array of supervoxel IDs (or node ids if <code>stop_layer&gt;1</code>).</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_lineage_graph","title":"<code>get_lineage_graph(root_id, timestamp_past=None, timestamp_future=None, as_nx_graph=False, exclude_links_to_future=False, exclude_links_to_past=False)</code>","text":"<p>Returns the lineage graph for a root ID, optionally cut off in the past or the future.</p> <p>Each change in the chunked graph creates a new root ID for the object after that change. This function returns a graph of all root IDs for a given object, tracing the history of the object in terms of merges and splits.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the lineage graph backwards in time. By default, None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Cutoff for the lineage graph going forwards in time. By default, None.</p> <code>None</code> <code>as_nx_graph</code> <p>If True, a NetworkX graph is returned.</p> <code>False</code> <code>exclude_links_to_future</code> <p>If True, links from nodes before <code>timestamp_future</code> to after <code>timestamp_future</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <code>exclude_links_to_past</code> <p>If True, links from nodes before <code>timestamp_past</code> to after <code>timestamp_past</code> are removed. If False, the link(s) which has one node before timestamp and one node after timestamp is kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary describing the lineage graph and operations for the root ID. Not returned if <code>as_nx_graph</code> is True. The dictionary contains the following keys:</p> <ul> <li>\"directed\" : bool<ul> <li>Whether the graph is directed.</li> </ul> </li> <li>\"graph\" : dict<ul> <li>Dictionary of graph attributes.</li> </ul> </li> <li>\"links\" : list of dict<ul> <li>Each element of the list is a dictionary describing an edge in the lineage graph as \"source\" and \"target\" keys.</li> </ul> </li> <li>\"multigraph\" : bool<ul> <li>Whether the graph is a multigraph.</li> </ul> </li> <li>\"nodes\" : list of dict<ul> <li>Each element of the list is a dictionary describing a node in the lineage graph, usually with \"id\", \"timestamp\", and \"operation_id\" keys.</li> </ul> </li> </ul> <code>DiGraph</code> <p>NetworkX directed graph of the lineage graph. Only returned if <code>as_nx_graph</code> is True.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_merge_log","title":"<code>get_merge_log(root_id)</code>","text":"<p>Get the merge log (splits and merges) for an object.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID to look up.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of merge events in the history of the object.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_oldest_timestamp","title":"<code>get_oldest_timestamp()</code>","text":"<p>Get the oldest timestamp in the database.</p> <p>Returns:</p> Type Description <code>datetime</code> <p>Oldest timestamp in the database.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_operation_details","title":"<code>get_operation_details(operation_ids)</code>","text":"<p>Get the details of a list of operations.</p> <p>Parameters:</p> Name Type Description Default <code>operation_ids</code> <code>Iterable[int]</code> <p>List/array of operation IDs.</p> required <p>Returns:</p> Type Description <code>dict of str to dict</code> <p>A dict of dicts of operation info, keys are operation IDs (as strings), values are a dictionary of operation info for the operation. These dictionaries contain the following keys:</p> <ul> <li>\"added_edges\"/\"removed_edges\": list of list of int<ul> <li>List of edges added (if a merge) or removed (if a split) by this operation. Each edge is a list of two supervoxel IDs (source and target).</li> </ul> </li> <li>\"roots\": list of int<ul> <li>List of root IDs that were created by this operation.</li> </ul> </li> <li>\"sink_coords\": list of list of int<ul> <li>List of sink coordinates for this operation. The sink is one of the points placed by the user when specifying the operation. Each sink coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"source_coords\": list of list of int<ul> <li>List of source coordinates for this operation. The source is one of the points placed by the user when specifying the operation. Each source coordinate is a list of three integers (x, y, z), corresponding to spatial coordinates in segmentation voxel space.</li> </ul> </li> <li>\"timestamp\": str<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user\": str<ul> <li>User ID number who performed the operation (as a string).</li> </ul> </li> </ul>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_original_roots","title":"<code>get_original_roots(root_id, timestamp_past=None)</code>","text":"<p>Returns root IDs that are the latest successors of a given root ID.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Object root ID.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Cutoff for the search going backwards in time. By default, None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>1d array with all latest successors.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_past_ids","title":"<code>get_past_ids(root_ids, timestamp_past=None, timestamp_future=None)</code>","text":"<p>For a set of root IDs, get the list of IDs at a past or future time point that could contain parts of the same object.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>Iterable of int</code> <p>Iterable of root IDs to query.</p> required <code>timestamp_past</code> <code>datetime or None</code> <p>Time of a point in the past for which to look up root ids. Default is None.</p> <code>None</code> <code>timestamp_future</code> <code>datetime or None</code> <p>Time of a point in the future for which to look up root ids. Not implemented on the server currently. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dict with keys \"future_id_map\" and \"past_id_map\". Each is a dict whose keys are the supplied <code>root_ids</code> and whose values are the list of related root IDs at <code>timestamp_past</code>/<code>timestamp_future</code>.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_root_id","title":"<code>get_root_id(supervoxel_id, timestamp=None, level2=False)</code>","text":"<p>Get the root ID for a specified supervoxel.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_id</code> <code>int</code> <p>Supervoxel id value</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <p>Returns:</p> Type Description <code>int64</code> <p>Root ID containing the supervoxel.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_root_timestamps","title":"<code>get_root_timestamps(root_ids)</code>","text":"<p>Retrieves timestamps when roots where created.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <p>Iterable of root IDs to query.</p> required <p>Returns:</p> Type Description <code>np.array of datetime.datetime</code> <p>Array of timestamps when <code>root_ids</code> were created.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_roots","title":"<code>get_roots(supervoxel_ids, timestamp=None, stop_layer=None)</code>","text":"<p>Get the root ID for a list of supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>supervoxel_ids</code> <code>list or np.array of int</code> <p>Supervoxel IDs to look up.</p> required <code>timestamp</code> <code>datetime</code> <p>UTC datetime to specify the state of the chunkedgraph at which to query, by default None. If None, uses the current time.</p> <code>None</code> <code>stop_layer</code> <code>int or None</code> <p>If True, looks up IDs only up to a given stop layer. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of np.uint64</code> <p>Root IDs containing each supervoxel.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_subgraph","title":"<code>get_subgraph(root_id, bounds)</code>","text":"<p>Get subgraph of root id within a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root (or any node ID) of chunked graph to query.</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates.</p> required <p>Returns:</p> Type Description <code>np.array of np.int64</code> <p>Node IDs in the subgraph.</p> <code>np.array of np.double</code> <p>Affinities of edges in the subgraph.</p> <code>np.array of np.int32</code> <p>Areas of nodes in the subgraph.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_tabular_change_log","title":"<code>get_tabular_change_log(root_ids, filtered=True)</code>","text":"<p>Get a detailed changelog for neurons.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>list of int</code> <p>Object root IDs to look up.</p> required <code>filtered</code> <code>bool</code> <p>Whether to filter the change log to only include splits and merges which affect the final state of the object (<code>filtered=True</code>), as opposed to including edit history for objects which as some point were split from the query objects in <code>root_ids</code> (<code>filtered=False</code>). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict of pd.DataFrame</code> <p>The keys are the root IDs, and the values are DataFrames with the following columns and datatypes:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": int<ul> <li>Timestamp of the operation, provided in milliseconds. To convert to datetime, use <code>datetime.datetime.utcfromtimestamp(timestamp/1000)</code>.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> <li>\"before_root_ids: list of int<ul> <li>Root IDs of objects that existed before the operation.</li> </ul> </li> <li>\"after_root_ids: list of int<ul> <li>Root IDs of objects created by the operation. Note that this only records the root id that was kept as part of the query object, so there will only be one in this list.</li> </ul> </li> <li>\"is_merge\": bool<ul> <li>Whether the operation was a merge.</li> </ul> </li> <li>\"user_name\": str<ul> <li>Name of the user who performed the operation.</li> </ul> </li> <li>\"user_affiliation\": str<ul> <li>Affiliation of the user who performed the operation.</li> </ul> </li> </ul>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.get_user_operations","title":"<code>get_user_operations(user_id, timestamp_start, include_undo=True, timestamp_end=None)</code>","text":"<p>Get operation details for a user ID. Currently, this is only available to admins.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>User ID to query (use 0 for all users (admin only)).</p> required <code>timestamp_start</code> <code>datetime</code> <p>Timestamp to start filter (UTC).</p> required <code>include_undo</code> <code>bool</code> <p>Whether to include undos. Defaults to True.</p> <code>True</code> <code>timestamp_end</code> <code>datetime</code> <p>Timestamp to end filter (UTC). Defaults to now.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame including the following columns:</p> <ul> <li>\"operation_id\": int<ul> <li>Identifier for the operation.</li> </ul> </li> <li>\"timestamp\": datetime.datetime<ul> <li>Timestamp of the operation.</li> </ul> </li> <li>\"user_id\": int<ul> <li>User who performed the operation.</li> </ul> </li> </ul>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.is_latest_roots","title":"<code>is_latest_roots(root_ids, timestamp=None)</code>","text":"<p>Check whether these root IDs are still a root at this timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>root_ids</code> <code>array-like of int</code> <p>Root IDs to check.</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs are valid root IDs in the chunked graph. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid root IDs.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.is_valid_nodes","title":"<code>is_valid_nodes(node_ids, start_timestamp=None, end_timestamp=None)</code>","text":"<p>Check whether nodes are valid for given timestamp range.</p> <p>Valid is defined as existing in the chunked graph. This makes no statement about these IDs being roots, supervoxel or anything in-between. It also does not take into account whether a root ID has since been edited.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>array-like of int</code> <p>Node IDs to check.</p> required <code>start_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid after this timestamp. Defaults to None (assumes now).</p> <code>None</code> <code>end_timestamp</code> <code>datetime</code> <p>Timestamp to check whether these IDs were valid before this timestamp. Defaults to None (assumes now).</p> <code>None</code> <p>Returns:</p> Type Description <code>np.array of bool</code> <p>Array of whether these are valid IDs.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.level2_chunk_graph","title":"<code>level2_chunk_graph(root_id, bounds=None)</code>","text":"<p>Get graph of level 2 chunks, the smallest agglomeration level above supervoxels.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root id of object</p> required <code>bounds</code> <code>array</code> <p>3x2 bounding box (x,y,z) x (min,max) in chunked graph coordinates (use <code>client.chunkedgraph.base_resolution</code> to view this default resolution for your chunkedgraph client). Note that the result will include any level 2 nodes which have chunk boundaries within some part of this bounding box, meaning that the representative point for a given level 2 node could still be slightly outside of these bounds. If None, returns all level 2 chunks for the root ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>list of list</code> <p>Edge list for level 2 chunked graph. Each element of the list is an edge, and each edge is a list of two node IDs (source and target).</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.preview_split","title":"<code>preview_split(source_points, sink_points, root_id, source_supervoxels=None, sink_supervoxels=None, return_additional_ccs=False)</code>","text":"<p>Get supervoxel connected components from a preview multicut split.</p> <p>Parameters:</p> Name Type Description Default <code>source_points</code> <code>array or list</code> <p>Nx3 list or array of 3d points in nm coordinates for source points (red).</p> required <code>sink_points</code> <code>array or list</code> <p>Mx3 list or array of 3d points in nm coordinates for sink points (blue).</p> required <code>root_id</code> <code>int</code> <p>Root ID of object to do split preview.</p> required <code>source_supervoxels</code> <code>(array, list or None)</code> <p>If providing source supervoxels, an N-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>sink_supervoxels</code> <code>(array, list or None)</code> <p>If providing sink supervoxels, an M-length array of supervoxel IDs or Nones matched to source points. If None, treats as a full array of Nones. By default None.</p> <code>None</code> <code>return_additional_ccs</code> <code>bool</code> <p>If True, returns any additional connected components beyond the ones with source and sink points. In most situations, this can be ignored. By default, False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>source_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most source points.</p> <code>sink_connected_component</code> <code>list</code> <p>Supervoxel IDs in the component with the most sink points.</p> <code>successful_split</code> <code>bool</code> <p>True if the split worked.</p> <code>other_connected_components (optional) : list of lists of int</code> <p>List of lists of supervoxel IDs for any other resulting connected components. Only returned if <code>return_additional_ccs</code> is True.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.remesh_level2_chunks","title":"<code>remesh_level2_chunks(chunk_ids)</code>","text":"<p>Submit specific level 2 chunks to be remeshed in case of a problem.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_ids</code> <code>list</code> <p>List of level 2 chunk IDs.</p> required"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.suggest_latest_roots","title":"<code>suggest_latest_roots(root_id, timestamp=None, stop_layer=None, return_all=False, return_fraction_overlap=False)</code>","text":"<p>Suggest latest roots for a given root id, based on overlap of component chunk IDs. Note that edits change chunk IDs, and so this effectively measures the fraction of unchanged chunks at a given chunk layer, which sets the size scale of chunks. Higher layers are coarser.</p> <p>Parameters:</p> Name Type Description Default <code>root_id</code> <code>int</code> <p>Root ID of the potentially outdated object.</p> required <code>timestamp</code> <code>datetime</code> <p>Datetime at which \"latest\" roots are being computed, by default None. If None, the current time is used. Note that this has to be a timestamp after the creation of the <code>root_id</code>.</p> <code>None</code> <code>stop_layer</code> <code>int</code> <p>Chunk level at which to compute overlap, by default None. No value will take the 4th from the top layer, which emphasizes speed and works well for larger objects. Lower values are slower but more fine-grained. Values under 2 (i.e. supervoxels) are not recommended except in extremely fine grained scenarios.</p> <code>None</code> <code>return_all</code> <code>bool</code> <p>If True, return all current IDs sorted from most overlap to least, by default False. If False, only the top is returned.</p> <code>False</code> <code>return_fraction_overlap</code> <code>bool</code> <p>If True, return all fractions sorted by most overlap to least, by default False. If False, only the top value is returned.</p> <code>False</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.ChunkedGraphClientV1.undo_operation","title":"<code>undo_operation(operation_id)</code>","text":"<p>Undo an operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation_id</code> <code>int</code> <p>Operation ID to undo.</p> required <p>Returns:</p> Type Description <code>dict</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2","title":"<code>InfoServiceClientV2(server_address, auth_header, api_version, endpoints, server_name, datastack_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, info_cache=None)</code>","text":"<p>               Bases: <code>ClientBaseWithDatastack</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.annotation_endpoint","title":"<code>annotation_endpoint(datastack_name=None, use_stored=True)</code>","text":"<p>AnnotationEngine endpoint for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Location of the AnnotationEngine</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.get_aligned_volume_info","title":"<code>get_aligned_volume_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a aligned_volume</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack_name to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that dataset, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the aligned_volume</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.get_datastack_info","title":"<code>get_datastack_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that datastack, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the datastack</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.get_datastacks","title":"<code>get_datastacks()</code>","text":"<p>Query which datastacks are available at the info service</p> <p>Returns:</p> Type Description <code>list</code> <p>List of datastack names</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.get_datastacks_by_aligned_volume","title":"<code>get_datastacks_by_aligned_volume(aligned_volume=None)</code>","text":"<p>Lookup what datastacks are associated with this aligned volume</p> <p>Args:     aligned_volume (str, optional): aligned volume to lookup. Defaults to None.</p> <p>Raises:     ValueError: if no aligned volume is specified</p> <p>Returns:     list: a list of datastack string</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.image_cloudvolume","title":"<code>image_cloudvolume(**kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the image source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.image_source","title":"<code>image_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the imagery for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the flat segmentation</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.refresh_stored_data","title":"<code>refresh_stored_data()</code>","text":"<p>Reload the stored info values from the server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.segmentation_cloudvolume","title":"<code>segmentation_cloudvolume(use_client_secret=True, **kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the segmentation source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.segmentation_source","title":"<code>segmentation_source(datastack_name=None, format_for='raw', use_stored=True)</code>","text":"<p>Cloud path to the chunkgraph-backed Graphene segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"graphene://https://\" type path is used If 'neuroglancer', a \"graphene://https://\" type path is used, as needed by Neuroglancer.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the Graphene segmentation</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.synapse_segmentation_source","title":"<code>synapse_segmentation_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the synapse segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the dataset to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the synapse segmentation</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.viewer_resolution","title":"<code>viewer_resolution(datastack_name=None, use_stored=True)</code>","text":"<p>Get the viewer resolution metadata for this datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <p>If None use the default one configured in the client</p> <code>None</code> <code>use_stored</code> <p>Use the cached value, if False go get a new value from server</p> <code>True</code> <p>Returns:</p> Type Description <code>array</code> <p>Voxel resolution as a len(3) np.array</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.InfoServiceClientV2.viewer_site","title":"<code>viewer_site(datastack_name=None, use_stored=True)</code>","text":"<p>Get the base Neuroglancer URL for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Base URL for the Neuroglancer viewer</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1","title":"<code>JSONServiceV1(server_address, auth_header, api_version, endpoints, server_name, ngl_url, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.state_service_endpoint","title":"<code>state_service_endpoint</code>  <code>property</code>","text":"<p>Endpoint URL for posting JSON state</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.build_neuroglancer_url","title":"<code>build_neuroglancer_url(state_id, ngl_url=None, target_site=None, static_url=False, format_propeties=False)</code>","text":"<p>Build a URL for a Neuroglancer deployment that will automatically retrieve specified state. If the datastack is specified, this is prepopulated from the info file field \"viewer_site\". If no ngl_url is specified in either the function or the client, a fallback neuroglancer deployment is used.</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>State id to retrieve</p> required <code>ngl_url</code> <code>str</code> <p>Base url of a neuroglancer deployment. If None, defaults to the value for the datastack or the client. As a fallback, a default deployment is used.</p> <code>None</code> <code>target_site</code> <code>seunglab or cave - explorer or mainline or None</code> <p>Set this to 'seunglab' for a seunglab deployment, or either 'cave-explorer'/'mainline' for a google main branch deployment. If None, checks the info field of the neuroglancer endpoint to determine which to use. Default is None.</p> <code>None</code> <code>static_url</code> <code>bool</code> <p>If True, treats \"state_id\" as a static URL directly to the JSON and does not use the state service.</p> <code>False</code> <code>format_propeties</code> <code>bool</code> <p>If True, formats the url as a segment_properties info file</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The full URL requested</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.get_neuroglancer_info","title":"<code>get_neuroglancer_info(ngl_url=None)</code>","text":"<p>Get the info field from a Neuroglancer deployment</p> <p>Parameters:</p> Name Type Description Default <code>ngl_url</code> <code>str(optional)</code> <p>URL to a Neuroglancer deployment. If None, defaults to the value for the datastack or the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON-formatted info field from the Neuroglancer deployment</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.get_property_json","title":"<code>get_property_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.get_state_json","title":"<code>get_state_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.save_state_json_local","title":"<code>save_state_json_local(json_state, filename, overwrite=False)</code>","text":"<p>Save a Neuroglancer JSON state to a JSON file locally.</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>filename</code> <code>str</code> <p>Filename to save the state to</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the file if it exists. Default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.upload_property_json","title":"<code>upload_property_json(property_json, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>propery_json</code> <code>dict</code> <p>Dict representation of a neuroglancer segment properties json</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONServiceV1.upload_state_json","title":"<code>upload_state_json(json_state, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy","title":"<code>L2CacheClientLegacy(server_address, auth_header, api_version, endpoints, server_name, table_name=None, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, verify=True)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.cache_metadata","title":"<code>cache_metadata()</code>","text":"<p>Retrieves the meta data for the cache</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are attribute names, values are datatypes</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.get_l2data","title":"<code>get_l2data(l2_ids, attributes=None)</code>","text":"<p>Gets the attributed statistics data for L2 ids.</p> <p>Parameters:</p> Name Type Description Default <code>l2_ids</code> <code>list or ndarray</code> <p>a list of level 2 ids</p> required <code>attributes</code> <code>list</code> <p>a list of attributes to retrieve. Defaults to None which will return all that are available. Available stats are ['area_nm2', 'chunk_intersect_count', 'max_dt_nm', 'mean_dt_nm', 'pca', 'pca_val', 'rep_coord_nm', 'size_nm3']. See docs for more description.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>keys are l2 ids, values are data</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.has_cache","title":"<code>has_cache(datastack_name=None)</code>","text":"<p>Checks if the l2 cache is available for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>The name of the datastack to check, by default None (if None, uses the client's datastack)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the l2 cache is available, False otherwise</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.L2CacheClientLegacy.table_mapping","title":"<code>table_mapping()</code>","text":"<p>Retrieves table mappings for l2 cache.</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are pcg table names, values are dicts with fields <code>l2cache_id</code> and <code>cv_path</code>.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy","title":"<code>SchemaClientLegacy(server_address, auth_header, api_version, endpoints, server_name, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.get_schemas","title":"<code>get_schemas()</code>","text":"<p>Get the available schema types</p> <p>Returns:</p> Type Description <code>list</code> <p>List of schema types available on the Schema service.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.schema_definition","title":"<code>schema_definition(schema_type)</code>","text":"<p>Get the definition of a specified schema_type</p> <p>Parameters:</p> Name Type Description Default <code>schema_type</code> <code>str</code> <p>Name of a schema_type</p> required <p>Returns:</p> Type Description <code>json</code> <p>Schema definition</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.schema_definition_all","title":"<code>schema_definition_all()</code>","text":"<p>Get the definition of all schema_types</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.SchemaClientLegacy.schema_definition_multi","title":"<code>schema_definition_multi(schema_types)</code>","text":"<p>Get the definition of multiple schema_types</p> <p>Parameters:</p> Name Type Description Default <code>schema_types</code> <code>list</code> <p>List of schema names</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of schema definitions. Keys are schema names, values are definitions.</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.AnnotationClient","title":"<code>AnnotationClient(server_address, dataset_name=None, aligned_volume_name=None, auth_client=None, api_version='latest', verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>Factory for returning AnnotationClient</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>server_address to use to connect to (i.e. https://minniev1.microns-daf.com)</p> required <code>dataset_name</code> <code>str</code> <p>Name of the datastack.</p> <code>None</code> <code>auth_client</code> <code>AuthClient or None</code> <p>Authentication client to use to connect to server. If None, do not use authentication.</p> <code>None</code> <code>api_version</code> <code>str or int (default: latest)</code> <p>What version of the api to use, 0: Legacy client (i.e www.dynamicannotationframework.com) 2: new api version, (i.e. minniev1.microns-daf.com) 'latest': default to the most recent (current 2)</p> <code>'latest'</code> <code>verify</code> <code>str (default : True)</code> <p>whether to verify https</p> <code>True</code> <code>max_retries</code> <code>Int or None</code> <p>Set the number of retries per request, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_block</code> <code>Bool or None</code> <p>If True, restricts pool of threads to max size, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_maxsize</code> <code>Int or None</code> <p>Sets the max number of threads in the pool, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>over_client</code> <p>client to overwrite configuration with</p> <code>None</code> <p>Returns:</p> Type Description <code>ClientBaseWithDatastack</code> <p>List of datastack names for available datastacks on the annotation engine</p>"},{"location":"extended_api/framework/#caveclient.frameworkclient.JSONService","title":"<code>JSONService(server_address=None, auth_client=None, api_version='latest', ngl_url=None, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>Client factory to interface with the JSON state service.</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>URL to the JSON state server. If None, set to the default global server address. By default None.</p> <code>None</code> <code>auth_client</code> <code>An Auth client</code> <p>An auth client with a token for the same global server, by default None</p> <code>None</code> <code>api_version</code> <code>int or latest</code> <p>Which endpoint API version to use or 'latest'. By default, 'latest' tries to ask the server for which versions are available, if such functionality exists, or if not it defaults to the latest version for which there is a client. By default 'latest'</p> <code>'latest'</code> <code>ngl_url</code> <code>str or None</code> <p>Default neuroglancer deployment URL. Only used for V1 and later.</p> <code>None</code>"},{"location":"extended_api/framework/#caveclient.frameworkclient.MaterializationClient","title":"<code>MaterializationClient(server_address, datastack_name=None, auth_client=None, cg_client=None, synapse_table=None, api_version='latest', version=None, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, desired_resolution=None, over_client=None)</code>","text":"<p>Factory for returning AnnotationClient</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>server_address to use to connect to (i.e. https://minniev1.microns-daf.com)</p> required <code>datastack_name</code> <code>str</code> <p>Name of the datastack.</p> <code>None</code> <code>auth_client</code> <code>AuthClient or None</code> <p>Authentication client to use to connect to server. If None, do not use authentication.</p> <code>None</code> <code>api_version</code> <code>str or int (default: latest)</code> <p>What version of the api to use, 0: Legacy client (i.e www.dynamicannotationframework.com) 2: new api version, (i.e. minniev1.microns-daf.com) 'latest': default to the most recent (current 2)</p> <code>'latest'</code> <code>cg_client</code> <p>chunkedgraph client for live materializations</p> <code>None</code> <code>synapse_table</code> <p>default synapse table for queries</p> <code>None</code> <code>version</code> <code>default version to query</code> <p>if None will default to latest version</p> <code>None</code> <code>desired_resolution</code> <code>Iterable[float] or None</code> <p>If given, should be a list or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <p>Returns:</p> Type Description <code>ClientBaseWithDatastack</code> <p>List of datastack names for available datastacks on the annotation engine</p>"},{"location":"extended_api/infoservice/","title":"infoservice","text":""},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/infoservice/#caveclient.infoservice.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2","title":"<code>InfoServiceClientV2(server_address, auth_header, api_version, endpoints, server_name, datastack_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, info_cache=None)</code>","text":"<p>               Bases: <code>ClientBaseWithDatastack</code></p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.annotation_endpoint","title":"<code>annotation_endpoint(datastack_name=None, use_stored=True)</code>","text":"<p>AnnotationEngine endpoint for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Location of the AnnotationEngine</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.get_aligned_volume_info","title":"<code>get_aligned_volume_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a aligned_volume</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack_name to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that dataset, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the aligned_volume</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.get_datastack_info","title":"<code>get_datastack_info(datastack_name=None, use_stored=True)</code>","text":"<p>Gets the info record for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>datastack to look up. If None, uses the one specified by the client. By default None</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True and the information has already been queried for that datastack, then uses the cached version. If False, re-queries the infromation. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>dict or None</code> <p>The complete info record for the datastack</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.get_datastacks","title":"<code>get_datastacks()</code>","text":"<p>Query which datastacks are available at the info service</p> <p>Returns:</p> Type Description <code>list</code> <p>List of datastack names</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.get_datastacks_by_aligned_volume","title":"<code>get_datastacks_by_aligned_volume(aligned_volume=None)</code>","text":"<p>Lookup what datastacks are associated with this aligned volume</p> <p>Args:     aligned_volume (str, optional): aligned volume to lookup. Defaults to None.</p> <p>Raises:     ValueError: if no aligned volume is specified</p> <p>Returns:     list: a list of datastack string</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.image_cloudvolume","title":"<code>image_cloudvolume(**kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the image source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.image_source","title":"<code>image_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the imagery for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the flat segmentation</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.refresh_stored_data","title":"<code>refresh_stored_data()</code>","text":"<p>Reload the stored info values from the server.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.segmentation_cloudvolume","title":"<code>segmentation_cloudvolume(use_client_secret=True, **kwargs)</code>","text":"<p>Generate a cloudvolume instance based on the segmentation source, using authentication if needed and sensible default values for reading CAVE resources. By default, fill_missing is True and bounded is False. All keyword arguments are passed onto the CloudVolume initialization function, and defaults can be overridden.</p> <p>Requires cloudvolume to be installed, which is not included by default.</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.segmentation_source","title":"<code>segmentation_source(datastack_name=None, format_for='raw', use_stored=True)</code>","text":"<p>Cloud path to the chunkgraph-backed Graphene segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"graphene://https://\" type path is used If 'neuroglancer', a \"graphene://https://\" type path is used, as needed by Neuroglancer.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the Graphene segmentation</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.synapse_segmentation_source","title":"<code>synapse_segmentation_source(datastack_name=None, use_stored=True, format_for='raw')</code>","text":"<p>Cloud path to the synapse segmentation for a dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the dataset to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <code>format_for</code> <code>'raw', 'cloudvolume', or 'neuroglancer'</code> <p>Formats the path for different uses. If 'raw' (default), the path in the InfoService is passed along. If 'cloudvolume', a \"precomputed://gs://\" type path is converted to a full https URL. If 'neuroglancer', a full https URL is converted to a \"precomputed://gs://\" type path.</p> <code>'raw'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted cloud path to the synapse segmentation</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.viewer_resolution","title":"<code>viewer_resolution(datastack_name=None, use_stored=True)</code>","text":"<p>Get the viewer resolution metadata for this datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <p>If None use the default one configured in the client</p> <code>None</code> <code>use_stored</code> <p>Use the cached value, if False go get a new value from server</p> <code>True</code> <p>Returns:</p> Type Description <code>array</code> <p>Voxel resolution as a len(3) np.array</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.InfoServiceClientV2.viewer_site","title":"<code>viewer_site(datastack_name=None, use_stored=True)</code>","text":"<p>Get the base Neuroglancer URL for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack to look up. If None, uses the value specified by the client. Default is None.</p> <code>None</code> <code>use_stored</code> <code>bool</code> <p>If True, uses the cached value if available. If False, re-queries the InfoService. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Base URL for the Neuroglancer viewer</p>"},{"location":"extended_api/infoservice/#caveclient.infoservice.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/jsonservice/","title":"jsonservice","text":""},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1","title":"<code>JSONServiceV1(server_address, auth_header, api_version, endpoints, server_name, ngl_url, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.state_service_endpoint","title":"<code>state_service_endpoint</code>  <code>property</code>","text":"<p>Endpoint URL for posting JSON state</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.build_neuroglancer_url","title":"<code>build_neuroglancer_url(state_id, ngl_url=None, target_site=None, static_url=False, format_propeties=False)</code>","text":"<p>Build a URL for a Neuroglancer deployment that will automatically retrieve specified state. If the datastack is specified, this is prepopulated from the info file field \"viewer_site\". If no ngl_url is specified in either the function or the client, a fallback neuroglancer deployment is used.</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>State id to retrieve</p> required <code>ngl_url</code> <code>str</code> <p>Base url of a neuroglancer deployment. If None, defaults to the value for the datastack or the client. As a fallback, a default deployment is used.</p> <code>None</code> <code>target_site</code> <code>seunglab or cave - explorer or mainline or None</code> <p>Set this to 'seunglab' for a seunglab deployment, or either 'cave-explorer'/'mainline' for a google main branch deployment. If None, checks the info field of the neuroglancer endpoint to determine which to use. Default is None.</p> <code>None</code> <code>static_url</code> <code>bool</code> <p>If True, treats \"state_id\" as a static URL directly to the JSON and does not use the state service.</p> <code>False</code> <code>format_propeties</code> <code>bool</code> <p>If True, formats the url as a segment_properties info file</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The full URL requested</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.get_neuroglancer_info","title":"<code>get_neuroglancer_info(ngl_url=None)</code>","text":"<p>Get the info field from a Neuroglancer deployment</p> <p>Parameters:</p> Name Type Description Default <code>ngl_url</code> <code>str(optional)</code> <p>URL to a Neuroglancer deployment. If None, defaults to the value for the datastack or the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON-formatted info field from the Neuroglancer deployment</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.get_property_json","title":"<code>get_property_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.get_state_json","title":"<code>get_state_json(state_id)</code>","text":"<p>Download a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>JSON specifying a Neuroglancer state.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.save_state_json_local","title":"<code>save_state_json_local(json_state, filename, overwrite=False)</code>","text":"<p>Save a Neuroglancer JSON state to a JSON file locally.</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>filename</code> <code>str</code> <p>Filename to save the state to</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the file if it exists. Default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.upload_property_json","title":"<code>upload_property_json(property_json, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>propery_json</code> <code>dict</code> <p>Dict representation of a neuroglancer segment properties json</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONServiceV1.upload_state_json","title":"<code>upload_state_json(json_state, state_id=None, timestamp=None)</code>","text":"<p>Upload a Neuroglancer JSON state</p> <p>Parameters:</p> Name Type Description Default <code>json_state</code> <code>dict</code> <p>Dict representation of a neuroglancer state</p> required <code>state_id</code> <code>int</code> <p>ID of a JSON state uploaded to the state service. Using a state_id is an admin feature.</p> <code>None</code> <code>timestamp</code> <p>Timestamp for json state date. Requires state_id.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>state_id of the uploaded JSON state</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.JSONService","title":"<code>JSONService(server_address=None, auth_client=None, api_version='latest', ngl_url=None, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>Client factory to interface with the JSON state service.</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>URL to the JSON state server. If None, set to the default global server address. By default None.</p> <code>None</code> <code>auth_client</code> <code>An Auth client</code> <p>An auth client with a token for the same global server, by default None</p> <code>None</code> <code>api_version</code> <code>int or latest</code> <p>Which endpoint API version to use or 'latest'. By default, 'latest' tries to ask the server for which versions are available, if such functionality exists, or if not it defaults to the latest version for which there is a client. By default 'latest'</p> <code>'latest'</code> <code>ngl_url</code> <code>str or None</code> <p>Default neuroglancer deployment URL. Only used for V1 and later.</p> <code>None</code>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/jsonservice/#caveclient.jsonservice.neuroglancer_json_encoder","title":"<code>neuroglancer_json_encoder(obj)</code>","text":"<p>JSON encoder for neuroglancer states. Differs from normal in that it expresses ints as strings</p>"},{"location":"extended_api/l2cache/","title":"l2cache","text":""},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/l2cache/#caveclient.l2cache.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/l2cache/#caveclient.l2cache.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy","title":"<code>L2CacheClientLegacy(server_address, auth_header, api_version, endpoints, server_name, table_name=None, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, verify=True)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.cache_metadata","title":"<code>cache_metadata()</code>","text":"<p>Retrieves the meta data for the cache</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are attribute names, values are datatypes</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.get_l2data","title":"<code>get_l2data(l2_ids, attributes=None)</code>","text":"<p>Gets the attributed statistics data for L2 ids.</p> <p>Parameters:</p> Name Type Description Default <code>l2_ids</code> <code>list or ndarray</code> <p>a list of level 2 ids</p> required <code>attributes</code> <code>list</code> <p>a list of attributes to retrieve. Defaults to None which will return all that are available. Available stats are ['area_nm2', 'chunk_intersect_count', 'max_dt_nm', 'mean_dt_nm', 'pca', 'pca_val', 'rep_coord_nm', 'size_nm3']. See docs for more description.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>keys are l2 ids, values are data</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.has_cache","title":"<code>has_cache(datastack_name=None)</code>","text":"<p>Checks if the l2 cache is available for the dataset</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str</code> <p>The name of the datastack to check, by default None (if None, uses the client's datastack)</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the l2 cache is available, False otherwise</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.L2CacheClientLegacy.table_mapping","title":"<code>table_mapping()</code>","text":"<p>Retrieves table mappings for l2 cache.</p> <p>Returns:</p> Type Description <code>dict</code> <p>keys are pcg table names, values are dicts with fields <code>l2cache_id</code> and <code>cv_path</code>.</p>"},{"location":"extended_api/l2cache/#caveclient.l2cache.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/materializationengine/","title":"materializationengine","text":""},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient","title":"<code>AuthClient(token_file=None, token_key=None, token=None, server_address=default_global_server_address)</code>","text":"<p>               Bases: <code>object</code></p> <p>Client to find and use auth tokens to access the dynamic annotation framework services.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> <p>Path to a JSON key:value file holding your auth token. By default, \"~/.cloudvolume/secrets/cave-secret.json\" (will check deprecated token name \"chunkedgraph-secret.json\" as well)</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file. By default, \"token\"</p> <code>None</code> <code>token</code> <code>str or None</code> <p>Direct entry of the token as a string. If provided, overrides the files. If None, attempts to use the file paths.</p> <code>None</code> <code>server_address</code> <code>(str, optional)</code> <p>URL to the auth server. By default, uses a default server address.</p> <code>default_global_server_address</code>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.request_header","title":"<code>request_header</code>  <code>property</code>","text":"<p>Formatted request header with the specified token</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.token","title":"<code>token</code>  <code>property</code> <code>writable</code>","text":"<p>Secret token used to authenticate yourself to the Connectome Annotation Versioning Engine services.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.get_group_users","title":"<code>get_group_users(group_id)</code>","text":"<p>Get users in a group</p> <p>Parameters:</p> Name Type Description Default <code>group_id</code> <code>int</code> <p>ID value for a given group</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dicts of user ids. Returns empty list if group does not exist.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.get_new_token","title":"<code>get_new_token(open=False)</code>","text":"<p>Currently, returns instructions for getting a new token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can generate a new token.</p> <code>False</code>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.get_token","title":"<code>get_token(token_key=None)</code>","text":"<p>Load a token with a given key the specified token file</p> <p>Parameters:</p> Name Type Description Default <code>token_key</code> <code>str or None</code> <p>key in the token file JSON, by default None. If None, uses 'token'.</p> <code>None</code>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.get_tokens","title":"<code>get_tokens()</code>","text":"<p>Get the tokens setup for this users</p> <p>Returns:</p> Type Description <code>list[dict]:</code> <p>a list of dictionary of tokens, each with the keys \"id\": the id of this token \"token\": the token (str) \"user_id\": the users id (should be your ID)</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.get_user_information","title":"<code>get_user_information(user_ids)</code>","text":"<p>Get user data.</p> <p>Parameters:</p> Name Type Description Default <code>user_ids</code> <code>list of int</code> <p>user_ids to look up</p> required"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.save_token","title":"<code>save_token(token=None, token_key=default_token_key, overwrite=False, token_file=None, switch_token=True, write_to_server_file=True)</code>","text":"<p>Conveniently save a token in the correct format.</p> <p>After getting a new token by following the instructions in <code>authclient.get_new_token()</code>, you can save it with a fully default configuration by running:</p> <p>token = 'my_shiny_new_token'</p> <p>authclient.save_token(token=token)</p> <p>Now on next load, authclient=AuthClient() will make an authclient instance using this token. If you would like to specify more information about the json file where the token will be stored, see the parameters below.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>New token to save, by default None</p> <code>None</code> <code>token_key</code> <code>str</code> <p>Key for the token in the token_file json, by default \"token\"</p> <code>default_token_key</code> <code>overwrite</code> <code>bool</code> <p>Allow an existing token to be changed, by default False</p> <code>False</code> <code>token_file</code> <code>str</code> <p>Path to the token file, by default None. If None, uses the default file location specified above.</p> <code>None</code> <code>switch_token</code> <code>bool</code> <p>If True, switch the auth client over into using the new token, by default True</p> <code>True</code> <code>write_to_server_file</code> <p>If True, will write token to a server specific file to support this machine interacting with multiple auth servers.</p> <code>True</code>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.AuthClient.setup_token","title":"<code>setup_token(make_new=True, open=True)</code>","text":"<p>Currently, returns instructions for getting your auth token based on the current settings and saving it to the local environment. New OAuth tokens are currently not able to be retrieved programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>make_new</code> <code>bool</code> <p>If True, will make a new token, else prompt you to open a page to retrieve an existing token.</p> <code>True</code> <code>open</code> <code>bool</code> <p>If True, opens a web browser to the web page where you can retrieve a token.</p> <code>True</code>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.ClientBase","title":"<code>ClientBase(server_address, auth_header, api_version, endpoints, server_name, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None)</code>","text":"<p>               Bases: <code>object</code></p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.ClientBase.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.ClientBase.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2","title":"<code>MaterializationClientV2(server_address, auth_header, api_version, endpoints, server_name, datastack_name, cg_client=None, synapse_table=None, version=None, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, over_client=None, desired_resolution=None)</code>","text":"<p>               Bases: <code>ClientBase</code></p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_table_metadata","title":"<code>get_table_metadata(table_name, datastack_name=None, version=None, log_warning=True)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack_name. If None, uses the one specified in the client.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version to get. If None, uses the one specified in the client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to print out warnings to the logger. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata dictionary for table</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_tables","title":"<code>get_tables(datastack_name=None, version=None)</code>","text":"<p>Gets a list of table names for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <code>version</code> <code>int or None</code> <p>the version to query, else get the tables in the most recent version</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_timestamp","title":"<code>get_timestamp(version=None, datastack_name=None)</code>","text":"<p>Get datetime.datetime timestamp for a materialization version.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>datetime</code> <p>Datetime when the materialization version was frozen.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_version_metadata","title":"<code>get_version_metadata(version=None, datastack_name=None)</code>","text":"<p>Get metadata about a version</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of metadata about the version</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_versions","title":"<code>get_versions(datastack_name=None, expired=False)</code>","text":"<p>Get the versions available</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of versions available</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.get_versions_metadata","title":"<code>get_versions_metadata(datastack_name=None, expired=False)</code>","text":"<p>Get the metadata for all the versions that are presently available and valid</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of metadata dictionaries</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.ingest_annotation_table","title":"<code>ingest_annotation_table(table_name, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookup and root ID lookup of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.join_query","title":"<code>join_query(tables, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, suffixes=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, metadata=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list of lists with length 2 or 'str'</code> <p>list of two lists: first entries are table names, second entries are the columns used for the join.</p> required <code>filter_in_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names, inner layer: keys are column names. Values are bounding boxes as [[min_x, min_y,min_z],[max_x, max_y, max_z]], expressed in units of the voxel_resolution of this dataset. Defaults to None.</p> <code>None</code> <code>filter_regex_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names. inner layer: keys are column names, values are regex strings. Defaults to None</p> <code>None</code> <code>select_columns</code> <code>dict of lists of str</code> <p>keys are table names,values are the list of columns from that table. Defaults to None, which will select all tables.  Will be passed to server as select_column_maps. Passing a list will be passed as select_columns which is deprecated.</p> <code>None</code> <code>offset</code> <code>int</code> <p>result offset to use. Defaults to None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>maximum results to return (server will set upper limit, see get_server_config)</p> <code>None</code> <code>suffixes</code> <code>dict</code> <p>suffixes to use for duplicate columns, keys are table names, values are the suffix</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>datastack to query. If None defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>whether to return as a dataframe default True, if False, data is returned as json (slower)</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>whether to break position columns into x,y,z columns default False, if False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>version to query. If None defaults to one specified in client.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>toggle to return metadata If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to. Defaults to None will use defaults.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>if given, will do a tablesample of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.live_live_query","title":"<code>live_live_query(table, timestamp, joins=None, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, metadata=True, suffixes=None, desired_resolution=None, allow_missing_lookups=False, random_sample=None)</code>","text":"<p>Beta method for querying cave annotation tables with rootIDs and annotations at a particular timestamp.  Note: this method requires more explicit mapping of filters and selection to table as its designed to test a more general endpoint that should eventually support complex joins.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Principle table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to query</p> required <code>joins</code> <p>List of joins, where each join is a list of [table1,column1, table2, column2]</p> <code>None</code> <code>filter_in_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to accept.</p> <code>None</code> <code>filter_out_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to reject.</p> <code>None</code> <code>filter_equal_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values to equate.</p> <code>None</code> <code>filter_spatial_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values of 2x3 list of bounds.</p> <code>None</code> <code>select_columns</code> <p>A dictionary with tables as keys, values are lists of columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Value to offset query by.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Limit of query.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. Defaults to set by client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe.</p> <code>True</code> <code>suffixes</code> <code>dict</code> <p>What suffixes to use on joins, keys are table_names, values are suffixes.</p> <code>None</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to.</p> <code>None</code> <code>allow_missing_lookups</code> <code>bool</code> <p>If there are annotations without supervoxels and root IDs yet, allow results.</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a table sample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <p>Results of query</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from caveclient import CAVEclient\n&gt;&gt;&gt; client = CAVEclient('minnie65_public_v117')\n&gt;&gt;&gt; live_live_query(\"table_name\", datetime.datetime.now(datetime.timezone.utc),\n&gt;&gt;&gt;    joins=[[table_name, table_column, joined_table, joined_column],\n&gt;&gt;&gt;             [joined_table, joincol2, third_table, joincol_third]]\n&gt;&gt;&gt;    suffixes={\n&gt;&gt;&gt;        \"table_name\":\"suffix1\",\n&gt;&gt;&gt;        \"joined_table\":\"suffix2\",\n&gt;&gt;&gt;        \"third_table\":\"suffix3\"\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    select_columns= {\n&gt;&gt;&gt;        \"table_name\":[ \"column\",\"names\"],\n&gt;&gt;&gt;        \"joined_table\":[\"joined_colum\"]\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_in_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[included,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_out_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[excluded,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_equal_dict\"={\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":value\n&gt;&gt;&gt;        },\n&gt;&gt;&gt;    filter_spatial_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": [[min_x, min_y, min_z], [max_x, max_y, max_z]]\n&gt;&gt;&gt;    }\n&gt;&gt;&gt;    filter_regex_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": \"regex_string\"\n&gt;&gt;&gt;     }\n</code></pre>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.live_query","title":"<code>live_query(table, timestamp, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, post_filter=True, metadata=True, merge_reference=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Time to materialize (in utc). Pass datetime.datetime.now(datetime.timezone.utc) for present time.</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries.</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries.</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry.</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]].</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings.</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Offset in query result.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config).</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. If None, defaults to one specified in client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns. If False data is returned as one column with [x,y,z] array (slower).</p> <code>False</code> <code>post_filter</code> <code>bool</code> <p>Whether to filter down the result based upon the filters specified. If False, it will return the query with present root_ids in the root_id columns, but the rows will reflect the filters translated into their past IDs. So if, for example, a cell had a false merger split off since the last materialization, those annotations on that incorrect portion of the cell will be included if this is False, but will be filtered down if this is True.</p> <code>True</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that table.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>Desired resolution you want all spatial points returned in. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.lookup_supervoxel_ids","title":"<code>lookup_supervoxel_ids(table_name, annotation_ids=None, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookups of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>annotation_ids</code> <code>list</code> <p>List of annotation ids to lookup. Default is None, which will trigger lookup of entire table.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.map_filters","title":"<code>map_filters(filters, timestamp, timestamp_past)</code>","text":"<p>Translate a list of filter dictionaries from a point in the future to a point in the past</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[dict]</code> <p>filter dictionaries with root_ids</p> required <code>timestamp</code> <code>datetime</code> <p>timestamp to query</p> required <code>timestamp_past</code> <code>datetime</code> <p>timestamp to query from</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>filter dictionaries with past root_ids</p> <code>dict</code> <p>mapping of future root_ids to past root_ids</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.most_recent_version","title":"<code>most_recent_version(datastack_name=None)</code>","text":"<p>Get the most recent version of materialization for this datastack name</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Most recent version of materialization for this datastack name</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.query_table","title":"<code>query_table(table, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, timestamp=None, metadata=True, merge_reference=True, desired_resolution=None, get_counts=False, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]], by default None</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings, by default None</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select, by default None</p> <code>None</code> <code>offset</code> <code>int</code> <p>Result offset to use, by default None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config), by default None</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return as a dataframe, by default True. If False, data is returned as json (slower).</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns, by default False. If False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>Version to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query, by default None. If passsed will do a live query. Error if also passing a materialization version</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata (default True), by default True. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table, by default True. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that</p> <code>True</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>Desired resolution you want all spatial points returned in, by default None. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata</p> <code>None</code> <code>get_counts</code> <code>bool</code> <p>Whether to get counts of the query, by default False</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV2.synapse_query","title":"<code>synapse_query(pre_ids=None, post_ids=None, bounding_box=None, bounding_box_column='post_pt_position', timestamp=None, remove_autapses=True, include_zeros=True, limit=None, offset=None, split_positions=False, desired_resolution=None, materialization_version=None, synapse_table=None, datastack_name=None, metadata=True)</code>","text":"<p>Convenience method for querying synapses.</p> <p>Will use the synapse table specified in the info service by default. It will also remove autapses by default. NOTE: This is not designed to allow querying of the entire synapse table. A query with no filters will return only a limited number of rows (configured by the server) and will do so in a non-deterministic fashion. Please contact your dataset administrator if you want access to the entire table.</p> <p>Parameters:</p> Name Type Description Default <code>pre_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Pre-synaptic cell(s) to query.</p> <code>None</code> <code>post_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Post-synaptic cell(s) to query.</p> <code>None</code> <code>bounding_box</code> <code>Optional[Union[list, ndarray]]</code> <p>[[min_x, min_y, min_z],[max_x, max_y, max_z]] bounding box to filter synapse locations. Expressed in units of the voxel_resolution of this dataset.</p> <code>None</code> <code>bounding_box_column</code> <code>str</code> <p>Which synapse location column to filter by.</p> <code>'post_pt_position'</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query. If passed recalculate query at timestamp, do not pass with materialization_version.</p> <code>None</code> <code>remove_autapses</code> <code>bool</code> <p>Whether to remove autapses from query results.</p> <code>True</code> <code>include_zeros</code> <code>bool</code> <p>Whether to include synapses to/from id=0 (out of segmentation).</p> <code>True</code> <code>limit</code> <code>int</code> <p>Number of synapses to limit. Server-side limit still applies.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of synapses to offset query.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>List or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <code>materialization_version</code> <code>int</code> <p>Version to query. If passed, do not pass timestamp. Defaults to <code>self.materialization_version</code> if not specified.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe in the df.attr dictionary.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Results of query.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3","title":"<code>MaterializationClientV3(*args, **kwargs)</code>","text":"<p>               Bases: <code>MaterializationClientV2</code></p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.server_version","title":"<code>server_version: Optional[Version]</code>  <code>property</code>","text":"<p>The version of the remote server.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_table_metadata","title":"<code>get_table_metadata(table_name, datastack_name=None, version=None, log_warning=True)</code>","text":"<p>Get metadata about a table</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>name of table to mark for deletion</p> required <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack_name. If None, uses the one specified in the client.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version to get. If None, uses the one specified in the client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to print out warnings to the logger. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata dictionary for table</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_tables","title":"<code>get_tables(datastack_name=None, version=None)</code>","text":"<p>Gets a list of table names for a datastack</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <code>version</code> <code>int or None</code> <p>the version to query, else get the tables in the most recent version</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of table names</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_tables_metadata","title":"<code>get_tables_metadata(datastack_name=None, version=None, log_warning=True)</code>","text":"<p>Get metadata about tables</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack_name. If None, uses the one specified in the client.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version to get. If None, uses the one specified in the client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to print out warnings to the logger. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata dictionary for table</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_timestamp","title":"<code>get_timestamp(version=None, datastack_name=None)</code>","text":"<p>Get datetime.datetime timestamp for a materialization version.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>datetime</code> <p>Datetime when the materialization version was frozen.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_unique_string_values","title":"<code>get_unique_string_values(table, datastack_name=None)</code>","text":"<p>Get unique string values for a table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>datastack_name</code> <code>Optional[str]</code> <p>Datastack to query. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str]</code> <p>A dictionary of column names and their unique values</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_version_metadata","title":"<code>get_version_metadata(version=None, datastack_name=None)</code>","text":"<p>Get metadata about a version</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int or None</code> <p>Materialization version, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of metadata about the version</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_versions","title":"<code>get_versions(datastack_name=None, expired=False)</code>","text":"<p>Get the versions available</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of versions available</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_versions_metadata","title":"<code>get_versions_metadata(datastack_name=None, expired=False)</code>","text":"<p>Get the metadata for all the versions that are presently available and valid</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Datastack name, by default None. If None, defaults to the value set in the client.</p> <code>None</code> <code>expired</code> <code>bool</code> <p>Whether to include expired versions, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of metadata dictionaries</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_view_metadata","title":"<code>get_view_metadata(view_name, materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get metadata for a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>Name of view to query.</p> required <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Metadata of view</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_view_schema","title":"<code>get_view_schema(view_name, materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get schema for a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>Name of view to query.</p> required <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Schema of view.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_view_schemas","title":"<code>get_view_schemas(materialization_version=None, datastack_name=None, log_warning=True)</code>","text":"<p>Get schema for a view</p> <p>Parameters:</p> Name Type Description Default <code>materialization_version</code> <code>int</code> <p>Version to query. If None, will use version set by client.</p> <code>None</code> <code>log_warning</code> <code>bool</code> <p>Whether to log warnings.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict</code> <p>Schema of view.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.get_views","title":"<code>get_views(version=None, datastack_name=None)</code>","text":"<p>Get all available views for a version</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>int</code> <p>Version to query. If None, uses the one specified in the client.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. If None, uses the one specified in the client.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of views</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.ingest_annotation_table","title":"<code>ingest_annotation_table(table_name, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookup and root ID lookup of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.join_query","title":"<code>join_query(tables, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, suffixes=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, metadata=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list of lists with length 2 or 'str'</code> <p>list of two lists: first entries are table names, second entries are the columns used for the join.</p> required <code>filter_in_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names inner layer: keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names, inner layer: keys are column names. Values are bounding boxes as [[min_x, min_y,min_z],[max_x, max_y, max_z]], expressed in units of the voxel_resolution of this dataset. Defaults to None.</p> <code>None</code> <code>filter_regex_dict</code> <code>dict of dicts</code> <p>outer layer: keys are table names. inner layer: keys are column names, values are regex strings. Defaults to None</p> <code>None</code> <code>select_columns</code> <code>dict of lists of str</code> <p>keys are table names,values are the list of columns from that table. Defaults to None, which will select all tables.  Will be passed to server as select_column_maps. Passing a list will be passed as select_columns which is deprecated.</p> <code>None</code> <code>offset</code> <code>int</code> <p>result offset to use. Defaults to None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>maximum results to return (server will set upper limit, see get_server_config)</p> <code>None</code> <code>suffixes</code> <code>dict</code> <p>suffixes to use for duplicate columns, keys are table names, values are the suffix</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>datastack to query. If None defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>whether to return as a dataframe default True, if False, data is returned as json (slower)</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>whether to break position columns into x,y,z columns default False, if False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>version to query. If None defaults to one specified in client.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>toggle to return metadata If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to. Defaults to None will use defaults.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>if given, will do a tablesample of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.live_live_query","title":"<code>live_live_query(table, timestamp, joins=None, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, metadata=True, suffixes=None, desired_resolution=None, allow_missing_lookups=False, allow_invalid_root_ids=False, random_sample=None)</code>","text":"<p>Beta method for querying cave annotation tables with root IDs and annotations at a particular timestamp.  Note: this method requires more explicit mapping of filters and selection to table as its designed to test a more general endpoint that should eventually support complex joins.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Principle table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp to query</p> required <code>joins</code> <p>List of joins, where each join is a list of [table1,column1, table2, column2]</p> <code>None</code> <code>filter_in_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to accept.</p> <code>None</code> <code>filter_out_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and list values to reject.</p> <code>None</code> <code>filter_equal_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values to equate.</p> <code>None</code> <code>filter_spatial_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values of 2x3 list of bounds.</p> <code>None</code> <code>filter_regex_dict</code> <p>A dictionary with tables as keys, values are dicts with column keys and values of regex strings.</p> <code>None</code> <code>select_columns</code> <p>A dictionary with tables as keys, values are lists of columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Value to offset query by.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Limit of query.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. Defaults to set by client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe.</p> <code>True</code> <code>suffixes</code> <code>dict</code> <p>What suffixes to use on joins, keys are table_names, values are suffixes.</p> <code>None</code> <code>desired_resolution</code> <code>Iterable</code> <p>What resolution to convert position columns to.</p> <code>None</code> <code>allow_missing_lookups</code> <code>bool</code> <p>If there are annotations without supervoxels and root IDs yet, allow results.</p> <code>False</code> <code>allow_invalid_root_ids</code> <code>bool</code> <p>If True, ignore root ids not valid at the given timestamp, otherwise raise an error.</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a table sample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <p>Results of query</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from caveclient import CAVEclient\n&gt;&gt;&gt; client = CAVEclient('minnie65_public_v117')\n&gt;&gt;&gt; live_live_query(\"table_name\", datetime.datetime.now(datetime.timezone.utc),\n&gt;&gt;&gt;    joins=[[table_name, table_column, joined_table, joined_column],\n&gt;&gt;&gt;             [joined_table, joincol2, third_table, joincol_third]]\n&gt;&gt;&gt;    suffixes={\n&gt;&gt;&gt;        \"table_name\":\"suffix1\",\n&gt;&gt;&gt;        \"joined_table\":\"suffix2\",\n&gt;&gt;&gt;        \"third_table\":\"suffix3\"\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    select_columns= {\n&gt;&gt;&gt;        \"table_name\":[ \"column\",\"names\"],\n&gt;&gt;&gt;        \"joined_table\":[\"joined_colum\"]\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_in_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[included,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_out_dict= {\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":[excluded,values]\n&gt;&gt;&gt;        }\n&gt;&gt;&gt;    },\n&gt;&gt;&gt;    filter_equal_dict\"={\n&gt;&gt;&gt;        \"table_name\":{\n&gt;&gt;&gt;            \"column_name\":value\n&gt;&gt;&gt;        },\n&gt;&gt;&gt;    filter_spatial_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": [[min_x, min_y, min_z], [max_x, max_y, max_z]]\n&gt;&gt;&gt;    }\n&gt;&gt;&gt;    filter_regex_dict\"= {\n&gt;&gt;&gt;        \"table_name\": {\n&gt;&gt;&gt;        \"column_name\": \"regex_string\"\n&gt;&gt;&gt;     }\n</code></pre>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.live_query","title":"<code>live_query(table, timestamp, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, split_positions=False, post_filter=True, metadata=True, merge_reference=True, desired_resolution=None, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>timestamp</code> <code>datetime</code> <p>Time to materialize (in utc). Pass datetime.datetime.now(datetime.timezone.utc) for present time.</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries.</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries.</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry.</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]].</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings.</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Offset in query result.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config).</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query. If None, defaults to one specified in client.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns. If False data is returned as one column with [x,y,z] array (slower).</p> <code>False</code> <code>post_filter</code> <code>bool</code> <p>Whether to filter down the result based upon the filters specified. If False, it will return the query with present root_ids in the root_id columns, but the rows will reflect the filters translated into their past IDs. So if, for example, a cell had a false merger split off since the last materialization, those annotations on that incorrect portion of the cell will be included if this is False, but will be filtered down if this is True.</p> <code>True</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that table.</p> <code>True</code> <code>desired_resolution</code> <code>Iterable</code> <p>Desired resolution you want all spatial points returned in. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata.</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the table to return that many annotations.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.lookup_supervoxel_ids","title":"<code>lookup_supervoxel_ids(table_name, annotation_ids=None, datastack_name=None)</code>","text":"<p>Trigger supervoxel lookups of new annotations in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table to trigger</p> required <code>annotation_ids</code> <code>list</code> <p>List of annotation ids to lookup. Default is None, which will trigger lookup of entire table.</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to trigger it. Defaults to what is set in client.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Status code of response from server</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.map_filters","title":"<code>map_filters(filters, timestamp, timestamp_past)</code>","text":"<p>Translate a list of filter dictionaries from a point in the future to a point in the past</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[dict]</code> <p>filter dictionaries with root_ids</p> required <code>timestamp</code> <code>datetime</code> <p>timestamp to query</p> required <code>timestamp_past</code> <code>datetime</code> <p>timestamp to query from</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>filter dictionaries with past root_ids</p> <code>dict</code> <p>mapping of future root_ids to past root_ids</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.most_recent_version","title":"<code>most_recent_version(datastack_name=None)</code>","text":"<p>Get the most recent version of materialization for this datastack name</p> <p>Parameters:</p> Name Type Description Default <code>datastack_name</code> <code>str or None</code> <p>Name of the datastack, by default None. If None, uses the one specified in the client. Will be set correctly if you are using the framework_client</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Most recent version of materialization for this datastack name</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.query_table","title":"<code>query_table(table, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, timestamp=None, metadata=True, merge_reference=True, desired_resolution=None, get_counts=False, random_sample=None)</code>","text":"<p>Generic query on materialization tables</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table to query</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]], by default None</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings, by default None</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select, by default None</p> <code>None</code> <code>offset</code> <code>int</code> <p>Result offset to use, by default None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config), by default None</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return as a dataframe, by default True. If False, data is returned as json (slower).</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns, by default False. If False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>Version to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query, by default None. If passsed will do a live query. Error if also passing a materialization version</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata (default True), by default True. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table, by default True. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that</p> <code>True</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>Desired resolution you want all spatial points returned in, by default None. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata</p> <code>None</code> <code>get_counts</code> <code>bool</code> <p>Whether to get counts of the query, by default False</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.query_view","title":"<code>query_view(view_name, filter_in_dict=None, filter_out_dict=None, filter_equal_dict=None, filter_spatial_dict=None, filter_regex_dict=None, select_columns=None, offset=None, limit=None, datastack_name=None, return_df=True, split_positions=False, materialization_version=None, metadata=True, merge_reference=True, desired_resolution=None, get_counts=False, random_sample=None)</code>","text":"<p>Generic query on a view</p> <p>Parameters:</p> Name Type Description Default <code>view_name</code> <code>str</code> <p>View to query</p> required <code>filter_in_dict</code> <code>dict</code> <p>Keys are column names, values are allowed entries, by default None</p> <code>None</code> <code>filter_out_dict</code> <code>dict</code> <p>Keys are column names, values are not allowed entries, by default None</p> <code>None</code> <code>filter_equal_dict</code> <code>dict</code> <p>Keys are column names, values are specified entry, by default None</p> <code>None</code> <code>filter_spatial_dict</code> <code>dict</code> <p>Keys are column names, values are bounding boxes expressed in units of the voxel_resolution of this dataset. Bounding box is [[min_x, min_y,min_z],[max_x, max_y, max_z]], by default None</p> <code>None</code> <code>filter_regex_dict</code> <code>dict</code> <p>Keys are column names, values are regex strings, by default None</p> <code>None</code> <code>select_columns</code> <code>list of str</code> <p>Columns to select, by default None</p> <code>None</code> <code>offset</code> <code>int</code> <p>Result offset to use, by default None. Will only return top K results.</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum results to return (server will set upper limit, see get_server_config), by default None</p> <code>None</code> <code>datastack_name</code> <code>str</code> <p>Datastack to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return as a dataframe, by default True. If False, data is returned as json (slower).</p> <code>True</code> <code>split_positions</code> <code>bool</code> <p>Whether to break position columns into x,y,z columns, by default False. If False data is returned as one column with [x,y,z] array (slower)</p> <code>False</code> <code>materialization_version</code> <code>int</code> <p>Version to query, by default None. If None, defaults to one specified in client.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Toggle to return metadata (default True), by default True. If True (and return_df is also True), return table and query metadata in the df.attr dictionary.</p> <code>True</code> <code>merge_reference</code> <code>bool</code> <p>Toggle to automatically join reference table, by default True. If True, metadata will be queries and if its a reference table it will perform a join on the reference table to return the rows of that</p> <code>True</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>Desired resolution you want all spatial points returned in, by default None. If None, defaults to one specified in client, if that is None then points are returned as stored in the table and should be in the resolution specified in the table metadata</p> <code>None</code> <code>get_counts</code> <code>bool</code> <p>Whether to get counts of the query, by default False</p> <code>False</code> <code>random_sample</code> <code>int</code> <p>If given, will do a tablesample of the of the table to return that many annotations</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe of results of query</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.raise_for_status","title":"<code>raise_for_status(r, log_warning=True)</code>  <code>staticmethod</code>","text":"<p>Raises requests.HTTPError, if one occurred.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClientV3.synapse_query","title":"<code>synapse_query(pre_ids=None, post_ids=None, bounding_box=None, bounding_box_column='post_pt_position', timestamp=None, remove_autapses=True, include_zeros=True, limit=None, offset=None, split_positions=False, desired_resolution=None, materialization_version=None, synapse_table=None, datastack_name=None, metadata=True)</code>","text":"<p>Convenience method for querying synapses.</p> <p>Will use the synapse table specified in the info service by default. It will also remove autapses by default. NOTE: This is not designed to allow querying of the entire synapse table. A query with no filters will return only a limited number of rows (configured by the server) and will do so in a non-deterministic fashion. Please contact your dataset administrator if you want access to the entire table.</p> <p>Parameters:</p> Name Type Description Default <code>pre_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Pre-synaptic cell(s) to query.</p> <code>None</code> <code>post_ids</code> <code>Union[int, Iterable, ndarray]</code> <p>Post-synaptic cell(s) to query.</p> <code>None</code> <code>bounding_box</code> <code>Optional[Union[list, ndarray]]</code> <p>[[min_x, min_y, min_z],[max_x, max_y, max_z]] bounding box to filter synapse locations. Expressed in units of the voxel_resolution of this dataset.</p> <code>None</code> <code>bounding_box_column</code> <code>str</code> <p>Which synapse location column to filter by.</p> <code>'post_pt_position'</code> <code>timestamp</code> <code>datetime</code> <p>Timestamp to query. If passed recalculate query at timestamp, do not pass with materialization_version.</p> <code>None</code> <code>remove_autapses</code> <code>bool</code> <p>Whether to remove autapses from query results.</p> <code>True</code> <code>include_zeros</code> <code>bool</code> <p>Whether to include synapses to/from id=0 (out of segmentation).</p> <code>True</code> <code>limit</code> <code>int</code> <p>Number of synapses to limit. Server-side limit still applies.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of synapses to offset query.</p> <code>None</code> <code>split_positions</code> <code>bool</code> <p>Whether to split positions into separate columns, True is faster.</p> <code>False</code> <code>desired_resolution</code> <code>Iterable[float]</code> <p>List or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <code>materialization_version</code> <code>int</code> <p>Version to query. If passed, do not pass timestamp. Defaults to <code>self.materialization_version</code> if not specified.</p> <code>None</code> <code>metadata</code> <code>bool</code> <p>Whether to attach metadata to dataframe in the df.attr dictionary.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Results of query.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.TableManager","title":"<code>TableManager(client, metadata=None, schema=None)</code>","text":"<p>               Bases: <code>object</code></p> <p>Use schema definitions to generate query filters for each table.</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.MaterializationClient","title":"<code>MaterializationClient(server_address, datastack_name=None, auth_client=None, cg_client=None, synapse_table=None, api_version='latest', version=None, verify=True, max_retries=None, pool_maxsize=None, pool_block=None, desired_resolution=None, over_client=None)</code>","text":"<p>Factory for returning AnnotationClient</p> <p>Parameters:</p> Name Type Description Default <code>server_address</code> <code>str</code> <p>server_address to use to connect to (i.e. https://minniev1.microns-daf.com)</p> required <code>datastack_name</code> <code>str</code> <p>Name of the datastack.</p> <code>None</code> <code>auth_client</code> <code>AuthClient or None</code> <p>Authentication client to use to connect to server. If None, do not use authentication.</p> <code>None</code> <code>api_version</code> <code>str or int (default: latest)</code> <p>What version of the api to use, 0: Legacy client (i.e www.dynamicannotationframework.com) 2: new api version, (i.e. minniev1.microns-daf.com) 'latest': default to the most recent (current 2)</p> <code>'latest'</code> <code>cg_client</code> <p>chunkedgraph client for live materializations</p> <code>None</code> <code>synapse_table</code> <p>default synapse table for queries</p> <code>None</code> <code>version</code> <code>default version to query</code> <p>if None will default to latest version</p> <code>None</code> <code>desired_resolution</code> <code>Iterable[float] or None</code> <p>If given, should be a list or array of the desired resolution you want queries returned in useful for materialization queries.</p> <code>None</code> <p>Returns:</p> Type Description <code>ClientBaseWithDatastack</code> <p>List of datastack names for available datastacks on the annotation engine</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.concatenate_position_columns","title":"<code>concatenate_position_columns(df, inplace=False)</code>","text":"<p>function to take a dataframe with x,y,z position columns and replace them with one column per position with an xyz numpy array.  Edits occur</p> <p>Args:     df (pd.DataFrame): dataframe to alter     inplace (bool): whether to perform edits in place</p> <p>Returns:     pd.DataFrame: [description]</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.convert_position_columns","title":"<code>convert_position_columns(df, given_resolution, desired_resolution)</code>","text":"<p>function to take a dataframe with x,y,z position columns and convert them to the desired resolution from the given resolution</p> <p>Args:     df (pd.DataFrame): dataframe to alter     given_resolution (Iterable[float]): what the given resolution is     desired_resoultion (Iterable[float]): what the desired resolution is</p> <p>Returns:     pd.DataFrame: [description]</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.deserialize_query_response","title":"<code>deserialize_query_response(response)</code>","text":"<p>Deserialize pyarrow responses</p>"},{"location":"extended_api/materializationengine/#caveclient.materializationengine.handle_response","title":"<code>handle_response(response, as_json=True, log_warning=True)</code>","text":"<p>Deal with potential errors in endpoint response and return json for default case</p>"},{"location":"extended_api/session_config/","title":"session_config","text":""},{"location":"extended_api/session_config/#caveclient.session_config.patch_session","title":"<code>patch_session(session, max_retries=None, pool_block=None, pool_maxsize=None)</code>","text":"<p>Patch session to configure retry and poolsize options</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>requests session</code> <p>Session to modify</p> required <code>max_retries</code> <code>Int or None</code> <p>Set the number of retries per request, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_block</code> <code>Bool or None</code> <p>If True, restricts pool of threads to max size, by default None. If None, defaults to requests package default.</p> <code>None</code> <code>pool_maxsize</code> <code>Int or None</code> <p>Sets the max number of threads in the pool, by default None. If None, defaults to requests package default.</p> <code>None</code>"},{"location":"tutorials/","title":"Getting Started","text":"<p>AnnotationFramework client is a package for simplifying interactions with HTML services associated with the CAVE (Connectome Annotation Versioning Engine).</p> <p>For a larger introduction to CAVE and its services, see the main github organization site https://github.com/CAVEconnectome</p>"},{"location":"tutorials/#installation","title":"Installation","text":"<p>The CAVEclient can be installed with pip:</p> <pre><code>$ pip install caveclient\n</code></pre>"},{"location":"tutorials/#assumptions","title":"Assumptions","text":"<p>The code is setup to work flexibly with any deployment of these services, but you need to specify the server_address if that address is not https://globalv1.daf-apis.com/ for each client when initializing it. Similarly, the clients can query the info service for metadata to simplify the interaction with a datastack, but you have to specify a datastack name.</p>"},{"location":"tutorials/annotation/","title":"Annotation","text":"<p>The AnnotationClient is used to interact with the AnnotationEngine service to create tables from existing schema, upload new data, and download existing annotations. Note that annotations in the AnnotationEngine are not linked to any particular segmentation, and thus do not include any root ids. An annotation client is accessed with <code>client.annotation</code>.</p>"},{"location":"tutorials/annotation/#getting-existing-tables","title":"Getting existing tables","text":"<p>A list of the existing tables for the datastack can be found with get_tables().</p> <pre><code>all_tables = client.annotation.get_tables()\nall_tables[0]\n</code></pre> <p>Each table has three main properties that can be useful to know:</p> <ul> <li><code>table_name</code> : The table name, used to refer to it when uploading or   downloading annotations. This is also passed through to the table in   the Materialized database.</li> <li><code>schema_name</code> : The name of the table's schema from   EMAnnotationSchemas (see below).</li> <li><code>max_annotation_id</code> : An upper limit on the number of annotations   already contained in the table.</li> </ul>"},{"location":"tutorials/annotation/#downloading-annotations","title":"Downloading annotations","text":"<p>You can download the JSON representation of a data point through the get_annotation() method. This can be useful if you need to look up information on unmaterialized data, or to see what a properly templated annotation looks like.</p> <pre><code>table_name = all_tables[0]['table_name']      # 'ais_analysis_soma'\nannotation_id = 100\nclient.annotation.get_annotation(annotation_ids=annotation_id, table_name=table_name)\n</code></pre>"},{"location":"tutorials/annotation/#create-a-new-table","title":"Create a new table","text":"<p>One can create a new table with a specified schema with the create_table() method:</p> <pre><code>client.annotation.create_table(table_name='test_table',\n                               schema_name='microns_func_coreg',\n                               voxel_resolution = [1,1,1],\n                               description=\"some text to describe your table\")\n</code></pre> <p>The voxel resolution is the units your position columns will be uploaded in [1,1,1] would imply a nm location, where as [4,4,40] would correspond to voxels of that size. If you are uploading points from a neuroglancer session, you want this to match the units of that neuroglancer view.</p> <p>Note there are some optional metadata parameters to create_table()</p> <ul> <li><code>notice_text</code> : This is text that will show up to users who access   this data as a warning. This could be used to warn users that the   data is not complete or checked yet, or to advertise that a   particular publication should be cited when using this table.</li> <li><code>read_permission</code> : one of \"PRIVATE\" which means only you can read   data in this table. \"PUBLIC\" (default) which means anyone can read   this table that has read permissions to this dataset. So if and only   if you can read the segmentation results of this data, you can read   this table. \"GROUP\" which means that you must share a common group   with this user for them to be able to read. We need to make a way to   discover what groups you are in and who you share groups with.</li> <li><code>write_permission</code>: one of \"PRIVATE\" (default), which means only   you can write to this table. \"PUBLIC\" which means anyone can write   to this table that has write permissions to this dataset. Note   although this means anyone can add data, no annotations are ever   truly overwritten. \"GROUP\" which means that you must share a   common group with this user for them to be able to write. We need to   make a way to discover what groups you are in and who you share   groups with.</li> </ul> <p>If you change your mind about what you want for metadata, some but not all fields can be updated with update_metadata(). This includes the description, the notice_text, and the permissions, but not the name, schema or voxel resolution.</p> <pre><code># to update description\nclient.annotation.update_metadata(table_name='test_table',\n                                  description=\"a new description for my table\")\n\n# to make your table readable by anybody who can read this dataset\nclient.annotation.update_metadata(table_name='test_table',\n                                  notice_text=\"This table isn't done yet, don't trust it. Contact me\")\n\n# to make your table readable by anybody who can read this dataset\nclient.annotation.update_metadata(table_name='test_table',\n                                  read_permisison=\"PUBLIC\")\n</code></pre> <p>New data can be generated as a dict or list of dicts following the schema and uploaded with <code>post_annotation</code>. For example, a <code>microns_func_coreg</code> point needs to have:</p> <ul> <li><code>type</code> set to <code>microns_func_coreg</code></li> <li><code>pt</code> set to a dict with <code>position</code> as a key and   the xyz location as a value.</li> <li><code>func_id</code> set to an integer.</li> </ul> <p>The following could would create a new annotation and then upload it to the service. Note that you get back the annotation id(s) of what you uploaded.</p> <pre><code>new_data = {'type': 'microns_func_coreg',\n            'pt': {'position': [1,2,3]},\n            'func_id': 0}\nclient.annotation.post_annotation(table_name='test_table', data=[new_data])\n</code></pre> <p>There are methods to simplify annotation uploads if you have a pandas dataframe whose structure mirrors the struction of the annotation schema you want to upload</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame([{'id':0,\n         'type': 'microns_func_coreg',\n         'pt_position': [1,2,3]},\n         'func_id': 0},\n        {'id':1,\n        'type': 'microns_func_coreg',\n        'pt_position': [3,2,1]},\n        'func_id': 2}])\nclient.annotation.post_annotation_df('test_table', df)\n</code></pre> <p>Note that here I specified the IDs of my annotations, which you can do, but then its up to you to assure that the IDs don't collide with other IDs. If you leave them blank then the service will assign the IDs for you.</p> <p>There is a similar method for updating update_annotation_df()</p>"},{"location":"tutorials/annotation/#staged-annotations","title":"Staged Annotations","text":"<p>Staged annotations help ensure that the annotations you post follow the appropriate schema, both by providing guides to the field names and locally validating against a schema before uploading. The most common use case for staged annotations is to create a StagedAnnotation object for a given table, then add annotations to it individually or as a group, and finally upload to the annotation table.</p> <p>To get a StagedAnnotation object, you can start with either a table name or a schema name. Here, we'll assume that there's already a table called \"my_table\" that is running a \"cell_type_local\" schema. If we want to add new annotations to the table, we simply use the table name with stage_annotations().</p> <pre><code>stage = client.annotation.stage_annotations(\"my_table\")\n</code></pre> <p>This <code>stage</code> object retrieves the schema for the table and hosts a local collection of annotations. Every time you add an annotation, it is immediately validated against the schema. To add an annotation, use the <code>add</code> method:</p> <pre><code>stage.add(\n    cell_type = \"pyramidal_cell\",\n    classification_system=\"excitatory\",\n    pt_position=[100,100,10],\n)\n</code></pre> <p>The argument names derive from fields in the schema and you must provide all required fields. Any number of annotations can be added to the stage. A dataframe of annotations can also be added with <code>stage.add_dataframe</code>, and requires an exact match between column names and schema fields. The key difference between this and posting a dataframe directly is that annotations added to a StagedAnnotations are validated locally, allowing any issues to be caught before uploading.</p> <p>You can see the annotations as a list of dictionary records with <code>stage.annotation_list</code> or as a Pandas dataframe with <code>stage.annotation_dataframe</code>. Finally, if you initialized the stage with a table name, this information is stored in the <code>stage</code> and you can simply upload it from the client.</p> <pre><code>client.annotation.upload_staged_annotations(stage)\n</code></pre> <p>Updating annotations requires knowing the annotation id of the annotation you are updating, which is not required in the schema otherwise. In order to stage updated annotations, set the <code>update</code> parameter to <code>True</code> when creating the stage.</p> <pre><code>update_stage = client.annotation.stage_annotations(\"my_table\", update=True)\nupdate_stage.add(\n    id=1,\n    cell_type = \"stellate_cell\",\n    classification_system=\"excitatory\",\n    pt_position=[100,100,10],\n)\n</code></pre> <p>The <code>update</code> also informs the framework client to treat the annotations as an update and it will use the appropriate methods automatically when uploading <code>client.annotation.upload_staged_annotations</code>.</p> <p>If you want to specify ids when posting new annotations, <code>id_field</code> can be set to True when creating the StagedAnnotation object. This will enforce an <code>id</code> column but still post the data as new annotations.</p> <p>If you might be adding spatial data in coordinates that might be different than the resolution for the table, you can also set the <code>annotation_resolution</code> when creating the stage. The stage will convert between the resolution you specify for your own annotations and the resolution that the table expects.</p> <pre><code>stage = client.annotation.stage_annotations(\"my_table\", annotation_resolution=[8,8,40])\nstage.add(\n    cell_type='pyramidal_cell',\n    classification_system=\"excitatory\",\n    pt_position=[50,50,10],\n)\n</code></pre>"},{"location":"tutorials/authentication/","title":"Authentication","text":"<p>Authentication tokens are generally needed for programmatic access to our services. The AuthClient handles storing and loading your token or tokens and inserting it into requests in other clients.</p> <p>We can access the auth client from <code>client.auth</code>. Once you have saved a token, you probably won't interact with this client very often, however it has some convenient features for saving new tokens the first time. Let's see if you have a token already. Probably not.</p> <pre><code>client = CAVEclient()\nauth = client.auth\nprint(f\"My current token is: {auth.token}\")\n</code></pre>"},{"location":"tutorials/authentication/#getting-a-new-token","title":"Getting a new token","text":"<p>To get a new token, you will need to manually acquire it. For convenience, the function client.auth.get_new_token() provides instructions for how to get and save the token.</p> <p>By default, the token is saved to <code>~/.cloudvolume/secrets/cave-secret.json</code> as a string under the key <code>token</code>. This makes it compatible by default with Cloudvolume projects, which can come in handy. The following steps will save a token to the default location.</p> <pre><code>auth.get_new_token()\n</code></pre> <pre><code>new_token = 'abcdef1234567890' #This is the text you see after you visit the website.\nauth.save_token(token=new_token)\nprint(f\"My token is now: {auth.token}\")\n</code></pre> <p>Note that requesting a new token will invalidate your previous token on the same project. If you want to use the same token across different computers, you will need to share the same token information.</p>"},{"location":"tutorials/authentication/#loading-saved-tokens","title":"Loading saved tokens","text":"<p>Try opening <code>~/.cloudvolume/secrets/cave-secret.json</code> to see what we just created.</p> <p>If we had wanted to use a different file or a different json key, we could have specified that in auth.save_token.</p> <p>Because we used the default values, this token is used automatically when we initialize a new CAVEclient. If we wanted to use a different token file, token key, or even directly specify a token we could do so here.</p> <pre><code>client = CAVEclient(datastack_name)\nprint(f\"Now my basic token is: {client.auth.token}\")\n\nclient_direct = CAVEclient(datastack_name, auth_token='another_fake_token_678')\nprint(f\"A directly specified token is: {client_direct.auth.token}\")\n</code></pre> <p>If you use a CAVEclient, the AuthClient and its token will be automatically applied to any other services without further use.</p>"},{"location":"tutorials/chunkedgraph/","title":"Chunked Graph","text":"<p>The chunkedgraph is a dynamic oct-tree connected components supervoxel graph.</p> <p></p> <p>A visual representation of an oct-tree (Wikipedia (WhiteTimberwolf) CC BY-SA 3.0)</p> <p>As with any oct-tree, it is organized in hierarchical levels, with the bottom level 1 corresponding to the supervoxels of the segmentations, and the top level being the unique connected components of the supervoxel graph.</p> <p></p> <p>A figure illustrating the spatial chunking and editing of a the chunkedgraph. From Dorkenwald et. al 2021</p> <p>The ChunkedGraph client allows one to interact with the ChunkedGraph service, which stores and updates the supervoxel agglomeration graph. This is most often useful for looking up an object root id of a supervoxel or looking up supervoxels belonging to a root id. The ChunkedGraph client is at <code>client.chunkedgraph</code>.</p>"},{"location":"tutorials/chunkedgraph/#look-up-a-supervoxel","title":"Look up a supervoxel","text":"<p>Usually in Neuroglancer, one never notices supervoxel ids, but they are important for programmatic work. In order to look up the root id for a location in space, one needs to use the supervoxel segmentation to get the associated supervoxel id. The ChunkedGraph client makes this easy using the client.chunkedgraph.get_root_id() method.</p> <pre><code>sv_id = 104200755619042523\nclient.chunkedgraph.get_root_id(supervoxel_id=sv_id)\n</code></pre> <p>However, as proofreading occurs, the root id that a supervoxel belongs to can change. By default, this function returns the current state, however one can also provide a UTC timestamp to get the root id at a particular moment in history. This can be useful for reproducible analysis. Note below that the root id for the same supervoxel is different than it is now.</p> <pre><code>import datetime\n\n# I looked up the UTC POSIX timestamp from a day in early 2019.\ntimestamp = datetime.datetime.utcfromtimestamp(1546595253)\n\nsv_id = 104200755619042523\nclient.chunkedgraph.get_root_id(supervoxel_id=sv_id, timestamp=timestamp)\n</code></pre> <p>If you are doing this across lots of supervoxels (or any nodes) then you can do it more efficiently in one request with client.chunkedgraph.get_roots()</p> <pre><code>node_ids = [104200755619042523, 104200755619042524,104200755619042525]\nroot_ids = client.chunkedgraph.get_roots(node_ids)\n</code></pre>"},{"location":"tutorials/chunkedgraph/#getting-supervoxels-for-a-root-id","title":"Getting supervoxels for a root id","text":"<p>A root id is associated with a particular agglomeration of supervoxels, which can be found with the client.chunkedgraph.get_leaves() method. A new root id is generated for every new change in the chunkedgraph, so time stamps do not apply.</p> <pre><code>root_id = 648518346349541252\nclient.chunkedgraph.get_leaves(root_id)\n</code></pre> <p>You can also query the chunkedgraph not all the way to the bottom, using the stop_layer option</p> <pre><code>root_id = 648518346349541252\nclient.chunkedgraph.get_leaves(root_id,stop_layer=2)\n</code></pre> <p>This will get all the level 2 IDs for this root, which correspond to the lowest chunk of the hierarchy. An analogous option exists for client.chunkedgraph.get_roots(). This is useful to help find nodes to query within the <code>l2cache</code>, amongst other things.</p>"},{"location":"tutorials/chunkedgraph/#other-functions","title":"Other functions","text":"<p>There are a variety of other interesting functions to explore in client.chunkedgraph.</p>"},{"location":"tutorials/framework/","title":"Introduction","text":""},{"location":"tutorials/framework/#caveclient-one-client-for-all-services","title":"CAVEclient: one client for all services","text":"<p>The CAVE Framework consists of a number of different services, each with a specific set of tasks that it can perform through REST endpoints. The CAVEclient is designed to ease programmatic interaction with all of the various endpoints. In addition, most programmatic access requires the use of authentication tokens. In order to collect a given server, datastack name, and user token together into a coherent package that can be used on multiple endpoints, the CAVEclient builds appropriately configured clients for each of the specific services. Each of the individual services has their own specific documentation as well.</p>"},{"location":"tutorials/framework/#global-and-local-services","title":"Global and Local Services","text":"<p>There are two categories of data in CAVE: Global and local. Local services are associated with a single so-called datastack, which refers to a precise collection of imagery and segmentation data that function together. For example, EM imagery and a specific pychunkedgraph segmentation would be one datastack, while the same EM imagery but an initial static segmentation would be another. Datastacks are referred to by a short name, for instance <code>pinky100_public_flat_v185</code>.</p> <p>Global services are those that are potentially shared across multiple different specific datastacks. These include the info service, which can describe the properties of all available datastacks, the authentication service, and the state service that hosts neuroglancer states. Global services are associated with a particular URL (by default <code>http://globalv1.daf-apis.com</code>), but not a single datastack.</p>"},{"location":"tutorials/framework/#initializing-a-caveclient","title":"Initializing a CAVEclient","text":"<p>Assuming that the services are on <code>http://globalv1.daf-apis.com</code> and authentication tokens are either not being used or set up with default values (see Authentication), a simple CAVEclient that can only access global services can be initialized:</p> <pre><code>from caveclient import CAVEclient\n\nclient = CAVEclient()\n</code></pre> <p>Just to confirm that this works, let's see if we can get the EM image source from the InfoService. If you get a list of names of datastacks, all is good. If you have not yet set up an authentication token or you get an authentication error, look at Getting a new token for information about how to set up your auth token.</p> <pre><code>client.info.get_datastacks()\n</code></pre> <p>If you have a specific datastack you want to use, you can initialize your CAVEclient with it. This gives you access to the full range of client functions.</p> <pre><code>client = CAVEclient(datastack_name='my_datastack')\n</code></pre>"},{"location":"tutorials/framework/#using-other-server-addresses","title":"Using Other Server Addresses","text":"<p>If your data is hosted by a different global server, you specify its address when initializing the client.</p> <pre><code>client = CAVEclient(datastack_name='my_datastack', server_address='http://global.myserver.com')\n</code></pre> <p>By default, if you pass both a server address and a datastack, the client will store the mapping from datastack to server address in the same location as the default for authentication tokens. Once stored, the client will automatically use the correct server address for the datastack if none is provided. You can override storing the server address by passing <code>write_server_address=False</code>. Datastacks can be removed from the cache using</p> <p>caveclient.datastack_lookup.reset_server_address_cache(datastack_name).</p>"},{"location":"tutorials/framework/#accessing-specific-clients","title":"Accessing specific clients","text":"<p>Each client can be accessed as a property of the main client. See the documentation at left for the capabilities of each. Assuming your client is named <code>client</code>, the subclients for each service are:</p> <ul> <li>Authentication Service : <code>client.auth</code></li> <li>AnnotationEngine : <code>client.annotation</code></li> <li>PyChunkedGraph : <code>client.chunkedgraph</code></li> <li>InfoService : <code>client.info</code></li> <li>EM Annotation Schemas : <code>client.schemas</code></li> <li>JSON Neuroglancer State Service : <code>client.state</code></li> </ul>"},{"location":"tutorials/info/","title":"Info Service","text":"<p>A datastack has a number of complex paths to various data sources that together comprise a datastack. Rather than hardcode these paths, the InfoService allows one to query the location of each data source. This is also convenient in case data sources change.</p> <p>An InfoClient is accessed at <code>client.info</code>.</p> <pre><code>client = CAVEclient(datastack_name)\nprint(f\"This is an info client for {client.info.datastack_name} on {client.info.server_address}\")\n</code></pre>"},{"location":"tutorials/info/#accessing-datastack-information","title":"Accessing datastack information","text":"<p>All of the information accessible for the datastack can be seen as a dict using <code>get_datastack_info()</code>.</p> <pre><code>info.get_datastack_info()\n</code></pre> <p>Individual entries can be found as well. Use tab autocomplete to see the various possibilities.</p> <pre><code>info.graphene_source()\n</code></pre>"},{"location":"tutorials/info/#adjusting-formatting","title":"Adjusting formatting","text":"<p>Because of the way neuroglancer looks up data versus cloudvolume, sometimes one needs to convert between <code>gs://</code> style paths to <code>https://storage.googleapis.com/</code> stype paths. All of the path sources in the info client accept a <code>format_for</code> argument that can handle this, and correctly adapts to graphene vs precomputed data sources.</p> <pre><code>neuroglancer_style_source = info.image_source(format_for='neuroglancer')\nprint(f\"With gs-style: { neuroglancer_style_source }\")\n\ncloudvolume_style_source = info.image_source(format_for='cloudvolume')\nprint(f\"With https-style: { cloudvolume_style_source }\")\n</code></pre>"},{"location":"tutorials/l2cache/","title":"Level 2 Cache","text":"<p>To understand the level 2 cache, you must understand the structure of the chunkedgraph so see the chunkedgraph tutorial.</p> <p>Nodes on the second level or layer of the graph, corresponds to all the supervoxels that are locally connected to one another within a single level 2 spatial \"chunk\" of the data. The Level 2 Cache, is a service whose job it is to track and update relevant statistics about every level 2 node within the a chunkedgraph. The source code of this service can be found here.</p>"},{"location":"tutorials/l2cache/#finding-level-2-nodes","title":"Finding Level 2 Nodes","text":"<p>The chunkedgraph can be used to find the level2 nodes of a rootID using a <code>stop_layer=2</code> keyword argument on the client.chunkedgraph.get_leaves(). Conversely the level 2 node of a supervoxel can be found using the same keyword argument of client.chunkedgraph.get_roots(). Note if you don't specify a timestamp it will give you the level2 node that is presently associated with the object.</p>"},{"location":"tutorials/l2cache/#statistics","title":"Statistics","text":"<p>The statistics that are available are:</p> <ul> <li>area_nm2: The surface area of the object in square nanometers. Does not include border touching voxels</li> <li>size_nm3: The volume of the object in cubic nanometers,   based on counting voxels in the object.</li> <li>max_dt_nm: The maximum edge distance transform of that   object in nanometers. Meant to capture the   maximum \"thickness\" of the voxels in the   node.</li> <li>mean_dt_nm: The average edge distance transform of that   object in nanometers. Meant to capture the   average \"thickness\" of voxels in that node.</li> <li>rep_coord_nm: A list of x,y,z coordinates in nanometers that   represent a point within the object that is   designed to be close to the \"center\" of the   object. This is the location of the max_dt_nm   value.</li> <li>chunk_intersect_count: A 2 x 3 matrix representing the 6 sides of the   chunk, and whose values represent how many   voxels border that side of the chunk. Meant to   help understand significant the borders with   other chunks are. Ordering is the [[x_bottom,   y_bottom, z_bottom],[x_top, y_top, z_top]]   where {xyz}_bottom refers to the face which   has the smallest values for that dimension, and   {xyz}_top refers to the face which has the   largest.</li> <li>pca A 3x3 matrix representing the principal   components of the xyz point cloud of voxels for   this object. Ordering is NxD where N is the   components and D are the xyz dimensions. Meant   to help desribe the orientation of the level 2   chunk. Note that this is not calculated for   very small objects and so might not be present   for all level 2 nodes. You will see that its   availability correlates strongly with size_nm3.</li> <li>pca_val The 3 principal component values for the PCA   components.</li> </ul>"},{"location":"tutorials/l2cache/#retrieving-level-2-statistics","title":"Retrieving Level 2 Statistics","text":"<p>Level 2 stats about nodes can be retreived using the client.l2cache.get_l2data() method. It simply takes a list of level 2 nodes you want to retrieve. Optionally you can specify only the attributes that you are interested in retrieving which will speed up the request.</p>"},{"location":"tutorials/l2cache/#missing-data","title":"Missing Data","text":"<p>The service is constantly watching for changes made to objects and recalculating stats on new level2 nodes that are created, in order to keep its database of statistics current. This however takes some time, and is subject to sporadic rare failures. If you request stats on a level 2 node which are not in the database, you will receive an empty dictionary for that node. This will immediately trigger the system to recalculate the statistics of that missing data, and so it should be available shortly (on the order of seconds) if systems are operational. Please note that PCA is not calculated for very small objects because it is not meaningful. So if you are interested in differentiating whether PCA is not available because it hasn't been calculated, vs when its not available because it is not possible to calculate, you should ask for at least one other non PCA statistic as well. You will see that its availability correlates strongly with <code>size_nm3</code>.</p>"},{"location":"tutorials/l2cache/#use-cases","title":"Use Cases","text":""},{"location":"tutorials/l2cache/#calculate-total-area-and-volume-of-cells","title":"Calculate Total Area and Volume of Cells","text":"<p>Say you want to calculate the total surface area and volume of a object in the dataset. The areas and volume of each component can simply be added together to do this.</p> <pre><code>import pandas as pd\nroot_id = 648518346349541252\nlvl2nodes = client.chunkedgraph.get_leaves(root_id,stop_layer=2)\nl2stats = client.l2cache.get_l2data(lvl2nodes, attributes=['size_nm3','area_nm2'])\nl2df = pd.DataFrame(l2stats).T\ntotal_area_um2=l2df.area_nm2.sum()/(1000*1000)\ntotal_volume_um3 = l2df.size_nm3.sum()/(1000*1000*1000)\n</code></pre> <p>By utilizing the bounds argument of get_leaves, you can also do simple spatially restricted analysis of objects. In fact, because you have data on each level2 node individually, you can segregate the neuron using any labelling of its topology.</p>"},{"location":"tutorials/l2cache/#skeletonization","title":"Skeletonization","text":"<p>Level 2 nodes have \"cross chunk\" edges within the chunkedgraph which represent what level 2 nodes that object is locally connected to. This forms a graph between the level 2 nodes of the object that can be retrieved using the chunkedgraph function client.chunkedgraph. This graph represents a topological representation of the neuron at the resolution of individual chunks, and is guaranteed to be fully connected, unlike a voxel or mesh representation of the neuron which can have gaps where there are defects in the segmentation volume or incorrectly inferred edges at self contact locations.</p> <p>The level 2 graph can be turned into a skeleton representation of a neuron using a graph based TEASAR like algorithm as described for skeletonizing meshes in this MeshParty Documentation. There is an implementation of this approach that utilizes the chunkedgraph and the L2cache if available here and on pypi as <code>pcg-skel</code>. In this implementation the l2cache is used to more accurately place the level 2 nodes in space using the <code>rep_coord_nm</code> value.</p>"},{"location":"tutorials/l2cache/#trajectory-distributions","title":"Trajectory Distributions","text":"<p>If one is interested in the bulk direction of processes in a region of the brain, one can start with supervoxels in a region, find level 2 nodes that correspond to them, filter out components based on size, (or other criteria such as whether they are part of objects that have components in some other brain area) and look at the distribution of PCA components to understand the directions that those processes are moving within that region of space.</p>"},{"location":"tutorials/materialization/","title":"Materialization","text":"<p>The Materialization client allows one to interact with the materialized annotation tables, that were posted to the annotation service (the annotations tutorial).</p> <p>To see the entire class visit the API doc.</p> <p>The service regularly looks up all annotations and the segids underneath all the boundspatialpoints. You can then query these tables to find out the IDs that underlie the annotations, or the annotations that now intersect with certain IDs.</p> <p>For example, one common pattern is that you have identified a cell based on the location of its cell body, and you have an annotation there.</p> <p>You want to know what are the inputs onto the cell, so you first query the annotation table with your soma annotation, asking for the current ID underneath that soma. Then you query a synapse table for all synapse annotations that have a post-synaptic ID equal to the ID from your soma annotation.</p> <p>In this way your code stays the same, as the proofreading changes and you can track the connectivity of your cell over time.</p>"},{"location":"tutorials/materialization/#initializing-the-client","title":"Initializing the client","text":"<p>By default when you initialize the overall client, it will choose the most recent materialization version available. This may or may not be desirable depending on your use case. If your code involves using specific IDs then you should be using a specific version that is tied to a timepoint where those IDs are valid.</p> <p>To see what versions are available, use the client.materialize.get_versions() function.</p> <pre><code>client.materialize.get_versions()\n</code></pre> <p>Each version has a timestamp it was run on as well as a date when it will expire. You can query all this metadata for a specific version using client.materialize.get_version_metadata() or all versions using client.materialize.get_versions_metadata().</p> <p>To change the default version, alter the .version property of the materialization client.</p> <pre><code>client.materialize.version = 9\n</code></pre> <p>or specify the version when making a particular call.</p>"},{"location":"tutorials/materialization/#browsing-versions","title":"Browsing versions","text":"<p>To see what tables are available in a version you can use client.materialize.get_tables().</p> <p>If you want to read about the description of what that table is, use the annotationengine client client.materialize.get_table_metadata().</p> <p>If you want to read more about the schema for the annotation table use the schema service caveclient.emannotationschemas.SchemaClientLegacy.schema_definition().</p> <p>Note, the materialization service has a human readable webpage that links to the other services that might be more convenient for you to browse, to get a link there in ipython display <code>client.materialize.homepage</code></p> <p>for some important tables, the info service has a pointer to which table you should use in the metadata for the datastack. <code>client.info.get_datastack_info()['synapse_table']</code> and <code>client.info.get_datastack_info()['soma_table']</code>.</p> <p>To see how many annotations are in a particular table use</p> <pre><code>nannotations=client.materialize.get_annotation_count('my_table')\n</code></pre>"},{"location":"tutorials/materialization/#querying-tables","title":"Querying tables","text":"<p>To query a small table, you can just download the whole thing using client.materialize.query_table() which will return a dataframe of the table.</p> <p>Note however, some tables, such as the synapse table might be very large 200-300 million rows and the service will only return the first 200,000 results, and not in a deterministic manner. NOTE! This API is not designed to enable enmass downloading of the entire synapse table there are more efficient ways of doing this. Contact your dataset administrator for more information if this is what you are looking to do.</p> <p>To just get a preview, use the limit argument (but note again that this won't be a reproducible set)</p> <pre><code>df=client.materialize.query_table('my_table', limit=10)\n</code></pre> <p>For most applications, you will want to filter the query in some way.</p> <p>We offer three kinds of filters you can apply: <code>filter_equal_dict</code>, <code>filter_in_dict</code> and <code>filter_out_dict</code>. For query_table each is specified as a dictionary where the keys are column names, and the values are a list of values (or single value in the case of filter_equal).</p> <p>So for example to query a synapse table for all synapses onto a neuron in flywire you would use</p> <pre><code>synapse_table = client.info.get_datastack_info()['synapse_table']\ndf=client.materialize.query_table(synapse_table,\n                                  filter_equal_dict = {'post_pt_root_id': MYID})\n</code></pre> <p>The speed of querying is affected by a number of factors, including the size of the data. To improve the performance of results, you can reduce the number of columns returned using <code>select_columns</code>.</p> <p>So for example, if you are only interested in the root_ids and locations of pre_synaptic terminals you might limit the query with select_columns. Also, it is convenient to return the with positions as a column of <code>np.array([x,y,z])</code> coordinates for many purposes. However, sometimes you might prefer to have them split out as separate x, y, z columns. To enable this option use <code>split_columns=True</code>. split_columns=True is faster, as combining them is an extra step. You can recombine split-out position columns using caveclient.materializationengine.concatenate_position_columns()</p> <pre><code>synapse_table = client.info.get_datastack_info()['synapse_table']\ndf=client.materialize.query_table(synapse_table,\n                                  filter_equal_dict = {'post_pt_root_id': MYID},\n                                  select_columns=['id','pre_pt_root_id', 'pre_pt_position'],\n                                  split_columns=True)\n</code></pre>"},{"location":"tutorials/materialization/#desired-resolution","title":"Desired Resolution","text":"<p>Often you want to have position information in different units. For example, to consider synapse locations or soma locations, you might want to have positions in nanometers or microns.</p> <p>To create neuroglancer views, you might want positions in integer voxels of a size that aligns with the resolution you are used to using Neuroglancer at.</p> <p>Annotation tables can be created and uploaded in varying resolutions according to whatever the user of the table felt was natural. This information is available in the metadata for that table. In addition, you may pass desired_resolution as a keyword argument which will automatically convert all spatial positions into voxels of that size in nanometers.</p> <p>So if you want positions in nanometers, you would pass <code>desired_resolution=[1,1,1]</code>. If you want positions in microns you would pass <code>desired_resolution=[1000,1000,1000]</code>. If you want positions in 4,4,40nm voxel coordinates to use with cloud-volume or neuroglancer you would pass <code>desired_resolution=[4,4,40]</code>.</p>"},{"location":"tutorials/materialization/#spatial-filters","title":"Spatial Filters","text":"<p>You can also filter columns that are associated with spatial locations based upon being within a 3d bounding box.</p> <p>This is done by adding a filter_spatial_dict argument to query_table. The units of the bounding box should be in the units of the voxel_resolution of the table (which can be obtained from client.materialize.get_table_metadata()).</p> <pre><code>bounding_box = [[min_x, min_y, min_z], [max_x, max_y, max_z]]\nsynapse_table = client.info.get_datastack_info('synapse_table')\ndf=client.materialize.query_table(synapse_table,\n                                  filter_equal_dict = {'post_pt_root_id': MYID},\n                                  filter_spatial_dict = {'post_pt_position': bounding_box})\n</code></pre>"},{"location":"tutorials/materialization/#synapse-query","title":"Synapse Query","text":"<p>For synapses in particular, we have a simplified method for querying them with a reduced syntax. client.materialize.synapse_query() lets you specify pre and post synaptic partners as keyword arguments and bounding boxes. The defaults make reasonable assumptions about what you want to query, namely that the synapse_table is the table that the info service advertises, and that if you specify a bounding box, that you want the post_pt_position. These can be overridden of course, but the above bounding box query is simplified to.</p> <p>NOTE! This API is not designed to enable enmass downloading of the entire synapse table there are more efficient ways of doing this. Contact your dataset administrator for more information if this is what you are looking to do.</p> <pre><code>bounding_box = [[min_x, min_y, min_z], [max_x, max_y, max_z]]\ndf=client.materialize.query_table(post_ids = MYID,\n                                  bounding_box=bounding_box)\n</code></pre>"},{"location":"tutorials/materialization/#live-query","title":"Live Query","text":"<p>In order to query the materialized tables above you can only use IDs that were present at the timestamp of the materialization. If you query the tables with an ID that is not valid during the time of the materialization you will get empty results.</p> <p>To check if root_ids are valid at your materialization's timestamp, you can use client.chunkedgraph.is_latest_roots()</p> <pre><code>import numpy as np\nmat_time = client.materialize.get_timestamp()\nis_latest = client.chunkedgraph.is_latest_roots([MYID], timestamp=mat_time)\nassert(np.all(is_latest))\n</code></pre> <p>If you need to lookup what happened to that ID, you can use the chunkedgraph lineage tree, to look into the future or the past, depending on your application you can use client.chunkedgraph.get_lineage_graph().</p> <p>Again, the ideal situation is that you have an annotation in the database which refers to your objects of interest, and querying that table by the id column will return the object in the most recent materialization.</p> <p>However, sometimes you might be browsing and proofreadding the data and get an ID that is more recent that the most recent version available. For convenience, you can use client.materialize.live_query().</p> <p>to automatically update the results of your query to a time in the future, such as now. For example, to pass now, use <code>datetime.datetime.now(datetime.timezone.utc)</code>. Note all timestamps are in UTC throughout the codebase.</p> <pre><code>import datetime\nsynapse_table = client.info.get_datastack_info()['synapse_table']\ndf=client.materialize.live_query(synapse_table,\n                                  datetime.datetime.now(datetime.timezone.utc),\n                                  filter_equal_dict = {'post_pt_root_id': MYID})\n</code></pre> <p>This will raise an ValueError exception if the IDs passed in your filters are not valid at the timestamp given</p> <p>You can also pass a timestamp directly to query_table and it will call live_query automatically.</p> <pre><code>import datetime\nsynapse_table = client.info.get_datastack_info()['synapse_table']\ndf=client.materialize.query_table(synapse_table,\n                                  timestamp=datetime.datetime.now(datetime.timezone.utc),\n                                  filter_equal_dict = {'post_pt_root_id': MYID})\n</code></pre> <p>Also, keep in mind if you run multiple queries and at each time pass <code>datetime.datetime.now(datetime.timezone.utc)</code>, there is no guarantee that the IDs will be consistent from query to query, as proofreading might be happening at any time. For larger scale analysis constraining oneself to a materialized version will ensure consistent results.</p> <p>Versions have varying expiration times in order to support the tradeoff between recency and consistency, so before undertaking an analysis project consider what version you want to query and what your plan will be to update your analysis to future versions.</p>"},{"location":"tutorials/materialization/#content-aware-interface-experimental","title":"Content-aware Interface (Experimental)","text":"<p>As of version 5.8.0, we have introduced a new interface to query tables and views. This interface might have small but breaking changes in the near future. :::</p> <p>In order to make the querying interface more consistent across tables, we have introduced an additional alternative interface to filtering and querying data via the <code>client.materialize.tables</code> object. When you instantiate this object, this object finds all of the existing tables and the list of their columns and lets you filter the tables as arguments in the function with suggestions. Moreover, the filtering arguments and the querying arguments are separated into two.</p> <p>Let's see how this works with a simplest example --- downloading a table called <code>nucleus_detection_v0</code>. First, we reference the table as a function and then we run the query --- this is exactly the same as <code>client.materialize.query_table('nucleus_detection_v0')</code>.</p> <pre><code>client = CAVEclient('minnie65_public')\nnuc_df = client.materialize.tables.nucleus_detection_v0().query()\n</code></pre> <p>Where things differ is when we add filters. If we want to query based on a set of values for the field \"id\", for example, we add that as an argument:</p> <pre><code>my_ids = [373879, 111162]\nnuc_df = client.materialize.tables.nucleus_detection_v0(id=my_ids).query()\n</code></pre> <p>Where in this example the <code>id=</code> queries the column <code>id</code> based on the schema. These values can be either individual elements (i.e. an integer or a string) or a list/array of elements, and any field can be used. The tooling will automatically sort out how to format the filtering appropriately when running the query. Importantly, the filtering is identical between querying all types of tables and queries. To see the complete list of fields that can be queried, you can tab-autocomplete or in Jupyter or IPython glance at the docstring with <code>client.materialize.tables.nucleus_detection_v0?</code>.</p> <p>If you need to specify the table programmatically, you can also use a dictionary-style approach to getting the table filtering function. For example, an equivalent version of the above line would be:</p> <pre><code>my_ids = [373879, 111162]\nmy_table = 'nucleus_detection_v0'\nnuc_df = client.materialize.tables[my_table](id=my_ids).query()\n</code></pre> <p>The <code>query</code> function can also take arguments relating to timestamps or formatting where they act just like in the other query method. In particular, the arguments that apply to <code>query</code> are: <code>select_columns</code>, <code>offset</code>, <code>limit</code>, <code>split_positions</code>, <code>materialization_version</code>, <code>timestamp</code>, <code>metadata</code>, <code>desired_resolution</code>, and <code>get_counts</code>. For example, to add a desired resolution and split positions in the above query, it would look like:</p> <pre><code>my_ids = [373879, 111162]\nnuc_df = client.materialize.tables.nucleus_detection_v0(\n    id=my_ids\n).query(\n    split_positions=True,\n    desired_resolution=[1,1,1],\n)\n</code></pre> <p>If you want to do a live query instead of a materialized query, the filtering remains identical but we use the <code>live_query</code> function instead. The one required argument for <code>live_query</code> is the timestamp.</p> <pre><code>my_ids = [373879, 111162]\nnuc_df = client.materialize.tables.nucleus_detection_v0(\n    id=my_ids\n).live_query(\n    timestamp=datetime.datetime.now(datetime.timezone.utc),\n)\n</code></pre> <p>The live query functions have similar but slightly different arguments: <code>timestamp</code> (required), <code>offset</code>, <code>limit</code>, <code>split_positions</code>, <code>metadata</code>, <code>desired_resolution</code>, and <code>allow_missing_lookups</code>.</p> <p>Note that way that IPython handles docstrings means that while you can use <code>?</code> to get the docstring of the filtering part of the function, you can't simply do something like <code>client.materialize.tables.nucleus_detection_v0().query?</code>. It will tell you the function can't be found, because technically the <code>query</code> function does not yet exist until the table filtering function is called.</p> <p>Instead, if you want to glimpse the docstring of the query or live_query functions, you need to split it into two lines:</p> <pre><code>qry_func = client.materialize.tables.nucleus_detection_v0().query\nqry_func?\n</code></pre> <p>Finally, if the project you are working with has views, a similar interface is available to them via <code>client.materialize.views</code>. Currently views are not compatible with live query, and so only the <code>.query</code> function is available.</p>"},{"location":"tutorials/schemas/","title":"EM Annotation Schemas","text":"<p>The EMAnnotationSchemas client lets one look up the available schemas and how they are defined. This is mostly used for programmatic interactions between services, but can be useful when looking up schema definitions for new tables.</p>"},{"location":"tutorials/schemas/#get-the-list-of-schema","title":"Get the list of schema","text":"<p>One can get the list of all available schema with the <code>schema</code> method. Currently, new schema have to be generated on the server side, although we aim to have a generic set available to use.</p> <pre><code>client.schema.get_schemas()\n</code></pre>"},{"location":"tutorials/schemas/#view-a-specific-schema","title":"View a specific schema","text":"<p>The details of each schema can be viewed with the <code>schema_definition</code> method, formatted as per JSONSchema.</p> <pre><code>example_schema = client.schema.schema_definition('microns_func_coreg')\nexample_schema\n</code></pre> <p>This is mostly useful for programmatic interaction between services at the moment, but can also be used to inspect the expected form of an annotation by digging into the format.</p> <pre><code>example_schema['definitions']['FunctionalCoregistration']\n</code></pre>"},{"location":"tutorials/state/","title":"JSON Neuroglancer State Service","text":"<p>We store the JSON description of a Neuroglancer state in a simple database at the JSON Service. This is a convenient way to build states to distribute to people, or pull states to parse work by individuals. The JSON Client is at <code>client.state</code></p> <pre><code>client.state\n</code></pre>"},{"location":"tutorials/state/#retrieving-a-state","title":"Retrieving a state","text":"<p>JSON states are found simply by their ID, which you get when uploading a state. You can download a state with <code>get_state_json</code>.</p> <pre><code>example_id = 4845531975188480\nexample_state = client.state.get_state_json(test_id)\nexample_state['layers'][0]\n</code></pre>"},{"location":"tutorials/state/#uploading-a-state","title":"Uploading a state","text":"<p>You can also upload states with <code>upload_state_json</code>. If you do this, the state id is returned by the function. Note that there is no easy way to query what you uploaded later, so be VERY CAREFUL with this state id if you wish to see it again.</p> <p>Note: If you are working with a Neuroglancer Viewer object or similar, in order to upload, use viewer.state.to_json() to generate this representation.</p> <pre><code>example_state['layers'][0]['name'] = 'example_name'\nnew_id = client.state.upload_state_json(example_state)\n</code></pre> <pre><code>test_state = client.state.get_state_json(new_id)\ntest_state['layers'][0]['name']\n</code></pre>"},{"location":"tutorials/state/#generating-a-neuroglancer-url","title":"Generating a Neuroglancer URL","text":"<p>Once you have a state ID, you want to turn it into a well-formatted link. So you don\\'t have to remember all the endpoints, we can do this from the state client.</p> <pre><code>ngl_base = 'neuromancer-seung-import.appspot.com'\nclient.state.build_neuroglancer_url(new_id, ngl_base)\n</code></pre> <p>Note that the neuroglancer base can be found in the info service under <code>client.info.viewer_site()</code>.</p>"}]}